total 0
[vagrant@app1 ~]$ hostnamectl
   Static hostname: app1.dev
         Icon name: computer-vm
           Chassis: vm
        Machine ID: da6bdda2775a49119e0742e275e0cef1
           Boot ID: ab3ad3ad33b44f9a8ef3fd1adb52de03
    Virtualization: kvm
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-957.12.2.el7.x86_64
      Architecture: x86-64
[vagrant@app1 ~]$ ll ~/.ssh/
total 16
-rw-r--r--. 1 vagrant vagrant  398 Feb  3 05:08 id_rsa.pub
-rw-------. 1 vagrant vagrant 1675 Feb  3 05:08 id_rsa
-rw-------. 1 vagrant vagrant 2006 Feb  3 05:10 authorized_keys
-rw-r--r--. 1 vagrant vagrant  346 Feb  3 05:13 known_hosts
[vagrant@app1 ~]$ 
 2020-02-03 15:07:42 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant ssh app1
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
Last login: Mon Feb  3 06:53:55 2020 from 192.168.3.1
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[vagrant@app1 ~]$ cl

















total 0
[vagrant@app1 ~]$ ansible-doc service
> SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/system/service.py)

        Controls services on remote hosts. Supported init systems include BSD init,
        OpenRC, SysV, Solaris SMF, systemd, upstart. For Windows targets, use the
        [win_service] module instead.

  * This module is maintained by The Ansible Core Team
  * note: This module has a corresponding action plugin.

OPTIONS (= is mandatory):

- arguments
        Additional arguments provided on the command line.
        (Aliases: args)[Default: (null)]
        type: str

- enabled
        Whether the service should start on boot.
        *At least one of state and enabled are required.*
        [Default: (null)]
        type: bool

= name
        Name of the service.

        type: str

- pattern
        If the service does not respond to the status command, name a substring to
        look for as would be found in the output of the `ps' command as a stand-in for
        a status result.
        If the string is found, the service will be assumed to be started.
        [Default: (null)]
        type: str
        version_added: 0.7

- runlevel
        For OpenRC init scripts (e.g. Gentoo) only.
        The runlevel that this service belongs to.
        [Default: default]
        type: str

...skipping...
EXAMPLES:

- name: Start service httpd, if not started
  service:
    name: httpd
    state: started

- name: Stop service httpd, if started
  service:
    name: httpd
    state: stopped

- name: Restart service httpd, in all cases
  service:
    name: httpd
    state: restarted

- name: Reload service httpd, in all cases
  service:
    name: httpd
    state: reloaded

- name: Enable service httpd, and not touch the state
  service:
    name: httpd
    enabled: yes

- name: Start service foo, based on running process /usr/bin/foo
  service:
    name: foo
    pattern: /usr/bin/foo
    state: started

- name: Restart network service for interface eth0
  service:
    name: network
    state: restarted
    args: eth0


~
~
[vagrant@app1 ~]$ ansible-doc yum
> YUM    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/yum.py)

        Installs, upgrade, downgrades, removes, and lists packages and groups with the
        `yum' package manager. This module only works on Python 2. If you require
        Python 3 support see the [dnf] module.

  * This module is maintained by The Ansible Core Team
  * note: This module has a corresponding action plugin.

OPTIONS (= is mandatory):

- allow_downgrade
        Specify if the named package and version is allowed to downgrade a maybe
        already installed higher version of that package. Note that setting
        allow_downgrade=True can make this module behave in a non-idempotent way. The
        task could end up with a set of packages that does not match the complete list
        of specified packages to install (because dependencies between the downgraded
        package and others can cause changes to the packages which were in the earlier
        transaction).
        [Default: no]
        type: bool
        version_added: 2.4

- autoremove
        If `yes', removes all "leaf" packages from the system that were originally
        installed as dependencies of user-installed packages but which are no longer
        required by any such package. Should be used alone or when state is `absent'
        NOTE: This feature requires yum >= 3.4.3 (RHEL/CentOS 7+)
        [Default: no]
        type: bool
        version_added: 2.7

- bugfix
        If set to `yes', and `state=latest' then only installs updates that have been
        marked bugfix related.
        [Default: no]
        version_added: 2.6

- conf_file
        The remote yum configuration file to use for the transaction.
        [Default: (null)]
        version_added: 0.6
...skipping...
EXAMPLES:

- name: install the latest version of Apache
  yum:
    name: httpd
    state: latest

- name: ensure a list of packages installed
  yum:
    name: "{{ packages }}"
  vars:
    packages:
    - httpd
    - httpd-tools

- name: remove the Apache package
  yum:
    name: httpd
    state: absent

- name: install the latest version of Apache from the testing repo
  yum:
    name: httpd
    enablerepo: testing
    state: present

- name: install one specific version of Apache
  yum:
    name: httpd-2.2.29-1.4.amzn1
    state: present

- name: upgrade all packages
  yum:
    name: '*'
    state: latest

- name: upgrade all packages, excluding kernel & foo related packages
  yum:
    name: '*'
    state: latest
    exclude: kernel*,foo*

[vagrant@app1 ~]$ ansible-doc firewalld
> FIREWALLD    (/usr/lib/python2.7/site-packages/ansible/modules/system/firewalld.py)

        This module allows for addition or deletion of services and ports (either TCP
        or UDP) in either running or permanent firewalld rules.

  * This module is maintained by The Ansible Community
OPTIONS (= is mandatory):

- icmp_block
        The ICMP block you would like to add/remove to/from a zone in firewalld.
        [Default: (null)]
        type: str
        version_added: 2.8

- icmp_block_inversion
        Enable/Disable inversion of ICMP blocks for a zone in firewalld.
        [Default: (null)]
        type: str
        version_added: 2.8

- immediate
        Should this configuration be applied immediately, if set as permanent.
        [Default: False]
        type: bool
        version_added: 1.9

- interface
        The interface you would like to add/remove to/from a zone in firewalld.
        [Default: (null)]
        type: str
        version_added: 2.1

- masquerade
        The masquerade setting you would like to enable/disable to/from zones within
        firewalld.
        [Default: (null)]
        type: str
        version_added: 2.1

- offline
        Whether to run this module even when firewalld is offline.
        [Default: (null)]
...skipping...
EXAMPLES:

- firewalld:
    service: https
    permanent: yes
    state: enabled

- firewalld:
    port: 8081/tcp
    permanent: yes
    state: disabled

- firewalld:
    port: 161-162/udp
    permanent: yes
    state: enabled

- firewalld:
    zone: dmz
    service: http
    permanent: yes
    state: enabled

- firewalld:
    rich_rule: rule service name="ftp" audit limit value="1/m" accept
    permanent: yes
    state: enabled

- firewalld:
    source: 192.0.2.0/24
    zone: internal
    state: enabled

- firewalld:
    zone: trusted
    interface: eth2
    permanent: yes
    state: enabled

- firewalld:
    masquerade: yes
    state: enabled
[vagrant@app1 ~]$ ansible-doc httpd
[WARNING]: module httpd not found in:
/home/vagrant/.ansible/plugins/modules:/usr/share/ansible/plugins/modules:/usr/lib/python2.7/site-
packages/ansible/modules

[vagrant@app1 ~]$ ll
total 0
[vagrant@app1 ~]$ 
 2020-02-04 08:37:03 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → ssh vagrant@192.168.3.5
^C

 2020-02-04 09:35:27 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant ssh app1
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
Last login: Mon Feb  3 10:45:26 2020 from 10.0.2.2
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[vagrant@app1 ~]$ ssh vagrant@192.168.3.7
Last login: Tue Feb  4 04:07:20 2020 from 10.0.2.2
[vagrant@app3 ~]$ exit
logout
Connection to 192.168.3.7 closed.
[vagrant@app1 ~]$ ssh vagrant@192.168.3.6
Last login: Tue Feb  4 04:07:24 2020 from 10.0.2.2
[vagrant@app2 ~]$ exit
logout
Connection to 192.168.3.6 closed.
[vagrant@app1 ~]$ ping 192.168.3.7
PING 192.168.3.7 (192.168.3.7) 56(84) bytes of data.
64 bytes from 192.168.3.7: icmp_seq=1 ttl=64 time=0.303 ms
64 bytes from 192.168.3.7: icmp_seq=2 ttl=64 time=0.317 ms
64 bytes from 192.168.3.7: icmp_seq=3 ttl=64 time=0.477 ms
^C
--- 192.168.3.7 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 0.303/0.365/0.477/0.081 ms
[vagrant@app1 ~]$ ping 8.8.8.8
PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=63 time=8.60 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=63 time=8.23 ms
^C
--- 8.8.8.8 ping statistics ---
3 packets transmitted, 2 received, 33% packet loss, time 2004ms
rtt min/avg/max/mdev = 8.231/8.417/8.604/0.207 ms
[vagrant@app1 ~]$ vi /etc/ansible/ansible.cfg 
[vagrant@app1 ~]$ ansible all -m ping
192.168.3.6 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
192.168.3.7 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[vagrant@app1 ~]$ ll
total 0
[vagrant@app1 ~]$ ll
total 0
[vagrant@app1 ~]$ vi vars.yml
[vagrant@app1 ~]$ vim vars.yml
[vagrant@app1 ~]$ ls -altr
total 28
-rw-r--r--. 1 vagrant vagrant  231 Oct 30  2018 .bashrc
-rw-r--r--. 1 vagrant vagrant  193 Oct 30  2018 .bash_profile
-rw-r--r--. 1 vagrant vagrant   18 Oct 30  2018 .bash_logout
drwx------. 2 vagrant vagrant   80 Feb  3 05:12 .ssh
drwxr-xr-x. 4 root    root      35 Feb  3 07:14 ..
-rw-------. 1 vagrant vagrant   44 Feb  3 10:46 .lesshst
-rw-------. 1 vagrant vagrant 1051 Feb  4 04:10 .bash_history
drwx------. 4 vagrant vagrant   27 Feb  4 04:24 .ansible
-rw-rw-r--. 1 vagrant vagrant    4 Feb  4 04:33 vars.yml
-rw-------. 1 vagrant vagrant 1011 Feb  4 04:33 .viminfo
drwx------. 4 vagrant vagrant  159 Feb  4 04:33 .
[vagrant@app1 ~]$ vi ~/.vimrc 
[vagrant@app1 ~]$ . ~/.vimrc 
[vagrant@app1 ~]$ vim vars.yml
[vagrant@app1 ~]$ ansible-playbook vars.yml --syntax-check
[WARNING]: Could not match supplied host pattern, ignoring: webserver


playbook: vars.yml
[vagrant@app1 ~]$ sudo -iu devops
[devops@app1 ~]$ exit
logout
[vagrant@app1 ~]$ cp vars.yml /tmp/
[vagrant@app1 ~]$ sudo -iu devops
[devops@app1 ~]$ cd project/
[devops@app1 project]$ ll
total 16
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
[devops@app1 project]$ cp /tmp/vars.yml .
[devops@app1 project]$ ll
total 20
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops 532 Feb  4 04:49 vars.yml
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
changed: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat vars.yml 
---
- name: Play1
  hosts: webserver
  vars:
    pkg: httpd
    srv: httpd
    rule: http
    ## a-z | _ | 0-9 var1 var_1 >> _vars  1var
  tasks:
    - name: Installing {{ pkg }} Package
      yum:
        name: "{{ pkg }}"
        state: latest

    - name: Starting {{ srv }} Service
      service:
        name: "{{ srv }}"
        state: started
        enabled: true

    - name: Allow {{ rule }} in Firewall
      firewalld:
        service: "{{ rule }}"
        state: enabled
        permanent: true
        immediate: true
[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
remote_user=devops
ask_pass=False

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ ansible-playbook var_file.yml --syntax-check
ERROR! A playbook must be a list of plays, got a <class 'ansible.parsing.yaml.objects.AnsibleMapping'> instead

The error appears to be in '/home/devops/project/var_file.yml': line 2, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
pkg:
^ here

[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ ansible-playbook var_file.yml --syntax-check
ERROR! A playbook must be a list of plays, got a <class 'ansible.parsing.yaml.objects.AnsibleMapping'> instead

The error appears to be in '/home/devops/project/var_file.yml': line 2, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
pkg:
^ here

[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ cat var_file.yml
---
pkg:
  - httpd
  - firewalld
  - vim
  - elinks
  - top
  - git

srv: httpd
rule: http
[devops@app1 project]$ #vi 
[devops@app1 project]$ ll
total 24
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops 584 Feb  4 05:04 vars.yml
-rw-rw-r--. 1 devops devops  91 Feb  4 05:08 var_file.yml
[devops@app1 project]$ vi vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'httpd', u'firewalld', u'vim', u'elinks', u'top', u'git'] Package] ********
fatal: [192.168.3.6]: FAILED! => {"changed": false, "msg": "No package matching 'top' found available, installed or updated", "rc": 126, "results": ["All packages providing httpd are up to date", "All packages providing firewalld are up to date", "No package matching 'top' found available, installed or updated"]}

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'httpd', u'firewalld', u'vim', u'elinks', u'git'] Package] ****************
changed: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat vars.yml 
---
- name: Play1
  hosts: webserver
  become: true
  vars_files:
    - var_file.yml
  #vars:
    #pkg: httpd
    #srv: httpd
    #rule: http
    ## a-z | _ | 0-9 var1 var_1 >> _vars  1var
  tasks:
    - name: Installing {{ pkg }} Package
      yum:
        name: "{{ pkg }}"
        state: latest

    - name: Starting {{ srv }} Service
      service:
        name: "{{ srv }}"
        state: started
        enabled: true

    - name: Allow {{ rule }} in Firewall
      firewalld:
        service: "{{ rule }}"
        state: enabled
        permanent: true
        immediate: true
[devops@app1 project]$ cat var_file.yml 
---
pkg:
  - httpd
  - firewalld
  - vim
  - elinks
  - git

srv: httpd
rule: http
[devops@app1 project]$ ll
total 24
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops 584 Feb  4 05:04 vars.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ cat hosts 
[webserver]
192.168.3.6   pkg=vsftpd srv=vsftpd rule=ftp

[dbserver]
192.168.3.7

[servers:children]
webserver
dbserver

[webserver:vars]
pkg=mariadb-server
srv=mariadb
rule=mysql
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ vi vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'httpd', u'firewalld', u'vim', u'elinks', u'git'] Package] ****************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing vsftpd Package] *************************************************************
changed: [192.168.3.6]

TASK [Starting vsftpd Service] ***************************************************************
changed: [192.168.3.6]

TASK [Allow ftp in Firewall] *****************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ls
ansible.cfg  hosts  index.html  playbook.yml  var_file.yml  vars.yml
[devops@app1 project]$ mkdir host_vars
[devops@app1 project]$ mkdir group_vars
[devops@app1 project]$ vim group_vars/webserver
[devops@app1 project]$ cat group_vars/webserver
---
pkg:
  - maria-server
  - mariadb

srv: mariadb
rule: mysql
[devops@app1 project]$ vim hosts 
[devops@app1 project]$ sudo yum install -y tree
Failed to set locale, defaulting to C
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
Could not get metalink https://mirrors.fedoraproject.org/metalink?repo=epel-7&arch=x86_64 error was
14: curl#6 - "Could not resolve host: mirrors.fedoraproject.org; Unknown error"
 * base: centos.excellmedia.net
 * epel: epel.mirror.angkasa.id
 * extras: centos.excellmedia.net
 * updates: centos.excellmedia.net
base                                                                   | 3.6 kB  00:00:00     
extras                                                                 | 2.9 kB  00:00:00     
updates                                                                | 2.9 kB  00:00:00     
Resolving Dependencies
--> Running transaction check
---> Package tree.x86_64 0:1.6.0-10.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

==============================================================================================
 Package            Arch                 Version                     Repository          Size
==============================================================================================
Installing:
 tree               x86_64               1.6.0-10.el7                base                46 k

Transaction Summary
==============================================================================================
Install  1 Package

Total download size: 46 k
Installed size: 87 k
Downloading packages:
tree-1.6.0-10.el7.x86_64.rpm                                           |  46 kB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : tree-1.6.0-10.el7.x86_64                                                   1/1 
  Verifying  : tree-1.6.0-10.el7.x86_64                                                   1/1 

Installed:
  tree.x86_64 0:1.6.0-10.el7                                                                  

Complete!
[devops@app1 project]$ tree
.
|-- ansible.cfg
|-- group_vars
|   `-- webserver
|-- hosts
|-- host_vars
|-- index.html
|-- playbook.yml
|-- var_file.yml
`-- vars.yml

2 directories, 7 files
[devops@app1 project]$ ll
total 24
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
-rw-rw-r--. 1 devops devops 180 Feb  4 05:33 hosts
-rw-rw-r--. 1 devops devops 586 Feb  4 05:35 vars.yml
drwxrwxr-x. 2 devops devops   6 Feb  4 06:09 host_vars
drwxrwxr-x. 2 devops devops  23 Feb  4 06:14 group_vars
[devops@app1 project]$ vi group_vars/webserver 
[devops@app1 project]$ cat group_vars/webserver 
---
pkg:
  - mariadb-server
  - mariadb

srv: mariadb
rule: mysql
[devops@app1 project]$ vim hosts 
[devops@app1 project]$ cat hosts 
[webserver]
192.168.3.6

[dbserver]
192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'mariadb-server', u'mariadb'] Package] ************************************
changed: [192.168.3.6]

TASK [Starting mariadb Service] **************************************************************
changed: [192.168.3.6]

TASK [Allow mysql in Firewall] ***************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim host_vars/192.168.3.6
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing mariadb Package] ************************************************************
ok: [192.168.3.6]

TASK [Starting mariadb Service] **************************************************************
ok: [192.168.3.6]

TASK [Allow mysql in Firewall] ***************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ tree
.
|-- ansible.cfg
|-- group_vars
|   `-- webserver
|-- hosts
|-- host_vars
|   `-- 192.168.3.6
|-- index.html
|-- playbook.yml
|-- var_file.yml
`-- vars.yml

2 directories, 8 files
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ #vi hosts 
[devops@app1 project]$ ansible webserver -m yum -a "name=vsftpd state=absent" -u root --ask-pass
SSH password: 
192.168.3.6 | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).", 
    "unreachable": true
}
[devops@app1 project]$ ^Ci hosts 
[devops@app1 project]$ 
[devops@app1 project]$ ansible webserver -m yum -a "name=vsftpd state=absent" 
192.168.3.6 | CHANGED => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": true, 
    "changes": {
        "removed": [
            "vsftpd"
        ]
    }, 
    "msg": "", 
    "rc": 0, 
    "results": [
        "Loaded plugins: fastestmirror\nResolving Dependencies\n--> Running transaction check\n---> Package vsftpd.x86_64 0:3.0.2-25.el7 will be erased\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package          Arch             Version                Repository       Size\n================================================================================\nRemoving:\n vsftpd           x86_64           3.0.2-25.el7           @base           353 k\n\nTransaction Summary\n================================================================================\nRemove  1 Package\n\nInstalled size: 353 k\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Erasing    : vsftpd-3.0.2-25.el7.x86_64                                   1/1 \n  Verifying  : vsftpd-3.0.2-25.el7.x86_64                                   1/1 \n\nRemoved:\n  vsftpd.x86_64 0:3.0.2-25.el7                                                  \n\nComplete!\n"
    ]
}
[devops@app1 project]$ ansible dbserver -m setup | less
[devops@app1 project]$ ansible dbserver -m setup | less
[devops@app1 project]$ vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  0  33172  71056      0 116096    0    1    69    16   42   51  1  0 99  0  0
[devops@app1 project]$ ansible dbserver -m setup -a filter=swap
192.168.3.7 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ ansible dbserver -m setup | grep swap
            "swap": {
        "ansible_swapfree_mb": 2024, 
        "ansible_swaptotal_mb": 2047, 
[devops@app1 project]$ ansible dbserver -m setup | less
[devops@app1 project]$ !
[devops@app1 project]$ ansible dbserver -m setup -a filter=ansible_memory_mb
192.168.3.7 | SUCCESS => {
    "ansible_facts": {
        "ansible_memory_mb": {
            "nocache": {
                "free": 101, 
                "used": 134
            }, 
            "real": {
                "free": 5, 
                "total": 235, 
                "used": 230
            }, 
            "swap": {
                "cached": 11, 
                "free": 2024, 
                "total": 2047, 
                "used": 23
            }
        }, 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/facts.yml': line 3, column 8, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name:collecting facts of ansible
  hosts: dbserver
       ^ here

[devops@app1 project]$ ansible-playbook facts.yml
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/facts.yml': line 3, column 8, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name:collecting facts of ansible
  hosts: dbserver
       ^ here

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ cat host
cat: host: No such file or directory
[devops@app1 project]$ cat hosts 
[webserver]
192.168.3.6

[dbserver]
192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        var: ansible_facts
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_facts": {
        "_facts_gathered": true, 
        "all_ipv4_addresses": [
            "10.0.2.15", 
            "192.168.3.7"
        ], 
        "all_ipv6_addresses": [
            "fe80::5054:ff:fe8a:fee6", 
            "fe80::a00:27ff:fe14:135f"
        ], 
        "ansible_local": {}, 
        "apparmor": {
            "status": "disabled"
        }, 
        "architecture": "x86_64", 
        "bios_date": "12/01/2006", 
        "bios_version": "VirtualBox", 
        "cmdline": {
            "BOOT_IMAGE": "/boot/vmlinuz-3.10.0-957.12.2.el7.x86_64", 
            "LANG": "en_US.UTF-8", 
            "biosdevname": "0", 
            "console": "ttyS0,115200n8", 
            "crashkernel": "auto", 
            "elevator": "noop", 
            "net.ifnames": "0", 
            "no_timer_check": true, 
            "ro": true, 
            "root": "UUID=8ac075e3-1124-4bb6-bef7-a6811bf8b870"
        }, 
        "date_time": {
            "date": "2020-02-04", 
            "day": "04", 
            "epoch": "1580799993", 
            "hour": "07", 
            "iso8601": "2020-02-04T07:06:33Z", 
            "iso8601_basic": "20200204T070633444334", 
            "iso8601_basic_short": "20200204T070633", 
            "iso8601_micro": "2020-02-04T07:06:33.444458Z", 
            "minute": "06", 
            "month": "02", 
            "second": "33", 
            "time": "07:06:33", 
            "tz": "UTC", 
            "tz_offset": "+0000", 
            "weekday": "Tuesday", 
            "weekday_number": "2", 
            "weeknumber": "05", 
            "year": "2020"
        }, 
        "default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }, 
        "default_ipv6": {}, 
        "device_links": {
            "ids": {
                "sda": [
                    "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6"
                ], 
                "sda1": [
                    "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6-part1"
                ]
            }, 
            "labels": {}, 
            "masters": {}, 
            "uuids": {
                "sda1": [
                    "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
                ]
            }
        }, 
        "devices": {
            "loop0": {
                "holders": [], 
                "host": "", 
                "links": {
                    "ids": [], 
                    "labels": [], 
                    "masters": [], 
                    "uuids": []
                }, 
                "model": null, 
                "partitions": {}, 
                "removable": "0", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "", 
                "sectors": "0", 
                "sectorsize": "512", 
                "size": "0.00 Bytes", 
                "support_discard": "4096", 
                "vendor": null, 
                "virtual": 1
            }, 
            "sda": {
                "holders": [], 
                "host": "IDE interface: Intel Corporation 82371AB/EB/MB PIIX4 IDE (rev 01)", 
                "links": {
                    "ids": [
                        "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6"
                    ], 
                    "labels": [], 
                    "masters": [], 
                    "uuids": []
                }, 
                "model": "VBOX HARDDISK", 
                "partitions": {
                    "sda1": {
                        "holders": [], 
                        "links": {
                            "ids": [
                                "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6-part1"
                            ], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
                            ]
                        }, 
                        "sectors": "83884032", 
                        "sectorsize": 512, 
                        "size": "40.00 GB", 
                        "start": "2048", 
                        "uuid": "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
                    }
                }, 
                "removable": "0", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "noop", 
                "sectors": "83886080", 
                "sectorsize": "512", 
                "serial": "VBfab860fe", 
                "size": "40.00 GB", 
                "support_discard": "0", 
                "vendor": "ATA", 
                "virtual": 1
            }
        }, 
        "discovered_interpreter_python": "/usr/bin/python", 
        "distribution": "CentOS", 
        "distribution_file_parsed": true, 
        "distribution_file_path": "/etc/redhat-release", 
        "distribution_file_variety": "RedHat", 
        "distribution_major_version": "7", 
        "distribution_release": "Core", 
        "distribution_version": "7.7", 
        "dns": {
            "nameservers": [
                "10.0.2.3"
            ], 
            "search": [
                "dev"
            ]
        }, 
        "domain": "dev", 
        "effective_group_id": 0, 
        "effective_user_id": 0, 
        "env": {
            "HOME": "/root", 
            "LANG": "C", 
            "LC_ALL": "C", 
            "LC_CTYPE": "UTF-8", 
            "LC_MESSAGES": "C", 
            "LOGNAME": "root", 
            "LS_COLORS": "rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:", 
            "MAIL": "/var/mail/devops", 
            "PATH": "/sbin:/bin:/usr/sbin:/usr/bin", 
            "PWD": "/home/devops", 
            "SHELL": "/bin/bash", 
            "SHLVL": "1", 
            "SUDO_COMMAND": "/bin/sh -c echo BECOME-SUCCESS-wjderyeodbqdqvmoivfkggfjkokaqatm ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580799991.0-132614975966941/AnsiballZ_setup.py", 
            "SUDO_GID": "1001", 
            "SUDO_UID": "1001", 
            "SUDO_USER": "devops", 
            "TERM": "xterm-256color", 
            "USER": "root", 
            "USERNAME": "root", 
            "XDG_SESSION_ID": "34", 
            "_": "/usr/bin/python"
        }, 
        "eth0": {
            "active": true, 
            "device": "eth0", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "10.0.2.15", 
                "broadcast": "10.0.2.255", 
                "netmask": "255.255.255.0", 
                "network": "10.0.2.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::5054:ff:fe8a:fee6", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "52:54:00:8a:fe:e6", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:03.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "eth1": {
            "active": true, 
            "device": "eth1", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "192.168.3.7", 
                "broadcast": "192.168.3.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.3.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::a00:27ff:fe14:135f", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "08:00:27:14:13:5f", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:08.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "fibre_channel_wwn": [], 
        "fips": false, 
        "form_factor": "Other", 
        "fqdn": "app3.dev", 
        "gather_subset": [
            "all"
        ], 
        "hostname": "app3", 
        "hostnqn": "", 
        "interfaces": [
            "lo", 
            "eth1", 
            "eth0"
        ], 
        "is_chroot": false, 
        "iscsi_iqn": "", 
        "kernel": "3.10.0-957.12.2.el7.x86_64", 
        "kernel_version": "#1 SMP Tue May 14 21:24:32 UTC 2019", 
        "lo": {
            "active": true, 
            "device": "lo", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "on [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "on [fixed]", 
                "netns_local": "on [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "on [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on [fixed]", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "on [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "on [fixed]", 
                "tx_nocache_copy": "off [fixed]", 
                "tx_scatter_gather": "on [fixed]", 
                "tx_scatter_gather_fraglist": "on [fixed]", 
                "tx_sctp_segmentation": "on", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "on", 
                "tx_tcp_ecn_segmentation": "on", 
                "tx_tcp_mangleid_segmentation": "on", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "off [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "on", 
                "vlan_challenged": "on [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "127.0.0.1", 
                "broadcast": "host", 
                "netmask": "255.0.0.0", 
                "network": "127.0.0.0"
            }, 
            "ipv6": [
                {
                    "address": "::1", 
                    "prefix": "128", 
                    "scope": "host"
                }
            ], 
            "mtu": 65536, 
            "promisc": false, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "loopback"
        }, 
        "lsb": {}, 
        "machine": "x86_64", 
        "machine_id": "4a3369a823a64378a8ed4fa5e1225aa2", 
        "memfree_mb": 5, 
        "memory_mb": {
            "nocache": {
                "free": 101, 
                "used": 134
            }, 
            "real": {
                "free": 5, 
                "total": 235, 
                "used": 230
            }, 
            "swap": {
                "cached": 11, 
                "free": 2024, 
                "total": 2047, 
                "used": 23
            }
        }, 
        "memtotal_mb": 235, 
        "module_setup": true, 
        "mounts": [
            {
                "block_available": 9506952, 
                "block_size": 4096, 
                "block_total": 10480385, 
                "block_used": 973433, 
                "device": "/dev/sda1", 
                "fstype": "xfs", 
                "inode_available": 20922845, 
                "inode_total": 20971008, 
                "inode_used": 48163, 
                "mount": "/", 
                "options": "rw,seclabel,relatime,attr2,inode64,noquota", 
                "size_available": 38940475392, 
                "size_total": 42927656960, 
                "uuid": "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
            }
        ], 
        "nodename": "app3.dev", 
        "os_family": "RedHat", 
        "pkg_mgr": "yum", 
        "proc_cmdline": {
            "BOOT_IMAGE": "/boot/vmlinuz-3.10.0-957.12.2.el7.x86_64", 
            "LANG": "en_US.UTF-8", 
            "biosdevname": "0", 
            "console": [
                "tty0", 
                "ttyS0,115200n8"
            ], 
            "crashkernel": "auto", 
            "elevator": "noop", 
            "net.ifnames": "0", 
            "no_timer_check": true, 
            "ro": true, 
            "root": "UUID=8ac075e3-1124-4bb6-bef7-a6811bf8b870"
        }, 
        "processor": [
            "0", 
            "GenuineIntel", 
            "Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz"
        ], 
        "processor_cores": 1, 
        "processor_count": 1, 
        "processor_threads_per_core": 1, 
        "processor_vcpus": 1, 
        "product_name": "VirtualBox", 
        "product_serial": "0", 
        "product_uuid": "4A3369A8-23A6-4378-A8ED-4FA5E1225AA2", 
        "product_version": "1.2", 
        "python": {
            "executable": "/usr/bin/python", 
            "has_sslcontext": true, 
            "type": "CPython", 
            "version": {
                "major": 2, 
                "micro": 5, 
                "minor": 7, 
                "releaselevel": "final", 
                "serial": 0
            }, 
            "version_info": [
                2, 
                7, 
                5, 
                "final", 
                0
            ]
        }, 
        "python_version": "2.7.5", 
        "real_group_id": 0, 
        "real_user_id": 0, 
        "selinux": {
            "config_mode": "enforcing", 
            "mode": "enforcing", 
            "policyvers": 31, 
            "status": "enabled", 
            "type": "targeted"
        }, 
        "selinux_python_present": true, 
        "service_mgr": "systemd", 
        "ssh_host_key_ecdsa_public": "AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBOQE9XPbQGYJdSKxBEVsTdN0u7LQ8llahIVxHWtJL+tZacEEkqlFslhB3AUfAeOIPYKwOLwZdZp/uRP6UH81zCs=", 
        "ssh_host_key_ed25519_public": "AAAAC3NzaC1lZDI1NTE5AAAAIANPg/KM4UU4a4m2Fsv0ZJ8GyV+kpukz5wbpfnWOfMqd", 
        "ssh_host_key_rsa_public": "AAAAB3NzaC1yc2EAAAADAQABAAABAQC1pbAglNeLryKsQRpGQobN9j1ee+nt+0INeu7OHcCUl22ar771H4mdhFZl4giVHELiAYVUSPfrZzzi0iH+9B36brNtn9eLS3Ew4VjDYcqrtZEB/x4GDIJe9giL0dhPeKtjlLVe6u+eGCSotZO/Rrr489vb1DIDbzd0XLI18hgz4b9cRUMurczOeIQEPKGW3dmRfoRSQThA6nNzvLTRLBSnVJxhzD5j9oNtaqUARE6Nem4E6ykIcKvxnSMLJ/gTGFoiaXRUAB8hPpNfFaGuoEffznHf5sHQmwPbjWBljL0kJRKIovrYIL97HMesO8vRv/x6xCvFQKuci0ysq0HDI+eJ", 
        "swapfree_mb": 2024, 
        "swaptotal_mb": 2047, 
        "system": "Linux", 
        "system_capabilities": [
            "cap_chown", 
            "cap_dac_override", 
            "cap_dac_read_search", 
            "cap_fowner", 
            "cap_fsetid", 
            "cap_kill", 
            "cap_setgid", 
            "cap_setuid", 
            "cap_setpcap", 
            "cap_linux_immutable", 
            "cap_net_bind_service", 
            "cap_net_broadcast", 
            "cap_net_admin", 
            "cap_net_raw", 
            "cap_ipc_lock", 
            "cap_ipc_owner", 
            "cap_sys_module", 
            "cap_sys_rawio", 
            "cap_sys_chroot", 
            "cap_sys_ptrace", 
            "cap_sys_pacct", 
            "cap_sys_admin", 
            "cap_sys_boot", 
            "cap_sys_nice", 
            "cap_sys_resource", 
            "cap_sys_time", 
            "cap_sys_tty_config", 
            "cap_mknod", 
            "cap_lease", 
            "cap_audit_write", 
            "cap_audit_control", 
            "cap_setfcap", 
            "cap_mac_override", 
            "cap_mac_admin", 
            "cap_syslog", 
            "35", 
            "36+ep"
        ], 
        "system_capabilities_enforced": "True", 
        "system_vendor": "innotek GmbH", 
        "uptime_seconds": 42617, 
        "user_dir": "/root", 
        "user_gecos": "root", 
        "user_gid": 0, 
        "user_id": "root", 
        "user_shell": "/bin/bash", 
        "user_uid": 0, 
        "userspace_architecture": "x86_64", 
        "userspace_bits": "64", 
        "virtualization_role": "guest", 
        "virtualization_type": "virtualbox"
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        var: ansible_facts
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_memory_mb": {
        "nocache": {
            "free": 101, 
            "used": 134
        }, 
        "real": {
            "free": 5, 
            "total": 235, 
            "used": 230
        }, 
        "swap": {
            "cached": 11, 
            "free": 2024, 
            "total": 2047, 
            "used": 23
        }
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        #var: ansible_facts
        var: ansible_memory_mb
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_memory_mb.swap": {
        "cached": 11, 
        "free": 2024, 
        "total": 2047, 
        "used": 23
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        #var: ansible_facts
        var: ansible_memory_mb.swap
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_facts.memory_mb": {
        "nocache": {
            "free": 101, 
            "used": 134
        }, 
        "real": {
            "free": 5, 
            "total": 235, 
            "used": 230
        }, 
        "swap": {
            "cached": 11, 
            "free": 2024, 
            "total": 2047, 
            "used": 23
        }
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        #var: ansible_facts
        #var: ansible_memory_mb.swap
        var: ansible_facts.memory_mb
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
fatal: [192.168.3.7]: FAILED! => {"msg": "Invalid options for debug: var1,var2"}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
fatal: [192.168.3.7]: FAILED! => {"msg": "Invalid options for debug: var2"}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_facts.hostname": "app3"
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "msg": "Hostname = app3 IPADDR = 10.0.2.2"
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

TASK [Creating index.html file] **************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=5    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ curl http://192.168.3.6/facts.html
Hello from app2 and my IP is 10.0.2.15[devops@app1 project]$ 
[devops@app1 project]$ 
[devops@app1 project]$ ansible webserver -a "cat /var/www/html/facts.html"
192.168.3.6 | CHANGED | rc=0 >>
Hello from app2 and my IP is 10.0.2.15

[devops@app1 project]$ cat vars.yml 
---
- name: Play1
  hosts: webserver
  become: true
  #vars_files:
    #- var_file.yml
  vars:
    pkg: httpd
    srv: httpd
    rule: http
    ## a-z | _ | 0-9 var1 var_1 >> _vars  1var
  tasks:
    - name: Installing {{ pkg }} Package
      yum:
        name: "{{ pkg }}"
        state: latest

    - name: Starting {{ srv }} Service
      service:
        name: "{{ srv }}"
        state: started
        enabled: true

    - name: Allow {{ rule }} in Firewall
      firewalld:
        service: "{{ rule }}"
        state: enabled
        permanent: true
        immediate: true

    - name: Creating index.html file
      copy:
        content: "Hello from {{ ansible_facts.hostname }} and my IP is {{ ansible_default_ipv4.address }}"
        dest: /var/www/html/facts.html
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

TASK [Creating index.html file] **************************************************************
fatal: [192.168.3.6]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'hostname'\n\nThe error appears to be in '/home/devops/project/vars.yml': line 32, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n    - name: Creating index.html file\n      ^ here\n"}

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible-playbook vars.yml  --syntax-check

playbook: vars.yml
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

TASK [Creating index.html file] **************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ll
total 28
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
-rw-rw-r--. 1 devops devops  87 Feb  4 06:22 hosts
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ ansible-playbook copy_facts.yml

PLAY [Copy ansible_facts in a file] **********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Saving Facts under /tmp firectory] *****************************************************
fatal: [192.168.3.7]: FAILED! => {"msg": "template error while templating string: no filter named 'to_pretty_json'. String: {{ ansible_facts | to_pretty_json }}"}
fatal: [192.168.3.6]: FAILED! => {"msg": "template error while templating string: no filter named 'to_pretty_json'. String: {{ ansible_facts | to_pretty_json }}"}

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ ansible-playbook copy_facts.yml
[WARNING]: While constructing a mapping from /home/devops/project/copy_facts.yml, line 7,
column 9, found a duplicate dict key (content). Using last defined value only.


PLAY [Copy ansible_facts in a file] **********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Saving Facts under /tmp firectory] *****************************************************
changed: [192.168.3.6 -> localhost]
changed: [192.168.3.7 -> localhost]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi /tmp/
ansible.cfg
app2.json
app3.json
devops
.font-unix/
.ICE-unix/
systemd-private-5aceaa79014746659fc5385d2fe80f4a-chronyd.service-iNQp8q/
systemd-private-ab3ad3ad33b44f9a8ef3fd1adb52de03-chronyd.service-enUMfn/
.Test-unix/
vars.yml
vboxguest-Module.symvers
.X11-unix/
.XIM-unix/
[devops@app1 project]$ vi /tmp/app2.json 
[devops@app1 project]$ vi /tmp/app3.json 
[devops@app1 project]$ vi /tmp/devops 
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ cat copy_facts.yml
---
- name: Copy ansible_facts in a file
  hosts: all
  tasks:
    - name: Saving Facts under /tmp firectory
      copy:
        content: "{{ ansible_facts | to_nice_json }}"
        dest: "/tmp/{{ ansible_hostname }}.json"
      delegate_to: localhost
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ ansible-playbook copy_facts.yml

PLAY [Copy ansible_facts in a file] **********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [localhost]

TASK [Saving Facts under /tmp firectory] *****************************************************
changed: [localhost -> localhost]

PLAY RECAP ***********************************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi /tmp/
ansible.cfg
app1.json
app2.json
app3.json
devops
.font-unix/
.ICE-unix/
systemd-private-5aceaa79014746659fc5385d2fe80f4a-chronyd.service-iNQp8q/
systemd-private-ab3ad3ad33b44f9a8ef3fd1adb52de03-chronyd.service-enUMfn/
.Test-unix/
vars.yml
vboxguest-Module.symvers
.X11-unix/
.XIM-unix/
[devops@app1 project]$ vi /tmp/app1.json 
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ cat copy_facts.yml
---
- name: Copy ansible_facts in a file
  hosts: all
  ##hosts: localhost
  tasks:
    - name: Saving Facts under /tmp firectory
      copy:
        content: "{{ ansible_facts | to_nice_json }}"
        dest: "/tmp/{{ ansible_hostname }}.json"
      delegate_to: localhost
[devops@app1 project]$ ls -ltr /tmp/app*json
-rw-r--r--. 1 root root 21247 Feb  4 08:55 /tmp/app2.json
-rw-r--r--. 1 root root 21893 Feb  4 08:55 /tmp/app3.json
-rw-r--r--. 1 root root 21285 Feb  4 08:59 /tmp/app1.json
[devops@app1 project]$ vim users.yml
[devops@app1 project]$ ansible-playbook users.yml --syntax-check
ERROR! vars file pass.yml was not found
Could not find file on the Ansible Controller.
If you are using a module and expect the file to exist on the remote, see the remote_src option
[devops@app1 project]$ ansible-playbook users.yml  --syntax-check
ERROR! vars file pass.yml was not found
Could not find file on the Ansible Controller.
If you are using a module and expect the file to exist on the remote, see the remote_src option
[devops@app1 project]$ vim pass.yml
[devops@app1 project]$ cat pass.yml
---
user_pass: AjjuR0ck$
[devops@app1 project]$ cat users.yml 
---
- name: Playbook for User Accounts
  hosts: all
  vars_files:
    - pass.yml
  tasks:
    - name: Adding a User Account
      user: 
        name: ajju
        state: present
        uid: 1010
        shell: /bin/sh
        groups: wheel
        password: "{{ user_pass }}"
[devops@app1 project]$ ansible-playbook users.yml  --syntax-check

playbook: users.yml
[devops@app1 project]$ ansible-vault
usage: ansible-vault [-h] [--version] [-v]
                     {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
                     ...
ansible-vault: error: too few arguments
[devops@app1 project]$ ansible-vault -h
usage: ansible-vault [-h] [--version] [-v]
                     {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
                     ...

encryption/decryption utility for Ansible data files

positional arguments:
  {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
    create              Create new vault encrypted file
    decrypt             Decrypt vault encrypted file
    edit                Edit vault encrypted file
    view                View vault encrypted file
    encrypt             Encrypt YAML file
    encrypt_string      Encrypt a string
    rekey               Re-key a vault encrypted file

optional arguments:
  --version             show program's version number, config file location,
                        configured module search path, module location,
                        executable location and exit
  -h, --help            show this help message and exit
  -v, --verbose         verbose mode (-vvv for more, -vvvv to enable
                        connection debugging)

See 'ansible-vault <command> --help' for more information on a specific
command.
[devops@app1 project]$ ansible-
ansible-2             ansible-console-2.7   ansible-galaxy-2.7    ansible-pull-2
ansible-2.7           ansible-doc           ansible-inventory     ansible-pull-2.7
ansible-config        ansible-doc-2         ansible-playbook      ansible-test
ansible-connection    ansible-doc-2.7       ansible-playbook-2    ansible-vault
ansible-console       ansible-galaxy        ansible-playbook-2.7  ansible-vault-2
ansible-console-2     ansible-galaxy-2      ansible-pull          ansible-vault-2.7
[devops@app1 project]$ ansible-vault encrypt pass.yml 
New Vault password: 
Confirm New Vault password: 
Encryption successful
[devops@app1 project]$ cat pass.yml 
$ANSIBLE_VAULT;1.1;AES256
66636137656235353464336337393137393866393364623434303139326537636363303464653933
6135656338663932386464633765666236626530336530650a303861353830653631376335626163
61326565343033343861643361623232376238376331393831323533623461636663393838326163
3832386438656139360a326466346564623233303232613064313662626263306333633161396465
65306538356137366132646366313465303232303736353935303637316631333238
[devops@app1 project]$ ansible-vault dencrypt pass.yml 
usage: ansible-vault [-h] [--version] [-v]
                     {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
                     ...
ansible-vault: error: argument action: invalid choice: u'dencrypt' (choose from 'create', 'decrypt', 'edit', 'view', 'encrypt', 'encrypt_string', 'rekey')
[devops@app1 project]$ ansible-vault decrypt pass.yml 
Vault password: 
Decryption successful
[devops@app1 project]$ cat pass.yml 
---
user_pass: AjjuR0ck$
[devops@app1 project]$ ansible-vault encrypt pass.yml 
New Vault password: 
Confirm New Vault password: 
Encryption successful
[devops@app1 project]$ ansible-vault view pass.yml 
Vault password: 
---
user_pass: AjjuR0ck$
[devops@app1 project]$ cat pass.yml 
$ANSIBLE_VAULT;1.1;AES256
63616532353035376233316639646161343763663038376139666637323366316131386363633264
3131366461393031623639633865666238336364353136330a353633643037316264356135343734
35363361636465343930373966633361663265663762303238376437323162663264376437343166
3238383837623535650a643935366363623038316237313966666461376463643063633838323430
32396262623036653166663165333138346665303933373731343033343933656337
[devops@app1 project]$ ansible-playbook users.yml 
ERROR! Attempting to decrypt but no vault secrets found
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass --syntax-check
Vault password: 

playbook: users.yml
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass 
Vault password: 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass 
Vault password: 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
[WARNING]: The input password appears not to have been hashed. The 'password' argument must
be encrypted for this module to work properly.

changed: [192.168.3.6]
changed: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 project]$ vim pass.yml 
[devops@app1 project]$ vim users.yml 
[devops@app1 project]$ ansible-playbook users.yml 
ERROR! Attempting to decrypt but no vault secrets found
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass
Vault password: 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
changed: [192.168.3.7]
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat users.yml
---
- name: Playbook for User Accounts
  hosts: all
  vars_files:
    - pass.yml
  tasks:
    - name: Adding a User Account
      user: 
        name: ajju
        state: present
        uid: 1010
        shell: /bin/sh
        groups: wheel
        password: "{{ user_pass | password_hash('sha512') }}"
[devops@app1 project]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 project]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 project]$ exit
logout
[vagrant@app1 ~]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[vagrant@app1 ~]$ vi /etc/ssh/
moduli                    ssh_host_ecdsa_key        ssh_host_ed25519_key.pub
ssh_config                ssh_host_ecdsa_key.pub    ssh_host_rsa_key
sshd_config               ssh_host_ed25519_key      ssh_host_rsa_key.pub
[vagrant@app1 ~]$ vi /etc/ssh/sshd_config 
[vagrant@app1 ~]$ sudo vi /etc/ssh/sshd_config 
[vagrant@app1 ~]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[vagrant@app1 ~]$ sudo vi /etc/ssh/sshd_config 
[vagrant@app1 ~]$ sudo -iu devops
[devops@app1 ~]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 ~]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 ~]$ ssh ajju@192.168.3.6
ajju@192.168.3.6's password: 
Permission denied, please try again.
ajju@192.168.3.6's password: 
Last failed login: Tue Feb  4 09:39:30 UTC 2020 from 192.168.3.5 on ssh:notty
There was 1 failed login attempt since the last successful login.
-sh-4.2$ exit
logout
Connection to 192.168.3.6 closed.
[devops@app1 ~]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 ~]$ vim users.yml
[devops@app1 ~]$ pwd
/home/devops
[devops@app1 ~]$ cd project/
group_vars/ host_vars/  
[devops@app1 ~]$ cd project/
[devops@app1 project]$ ll
total 40
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
-rw-rw-r--. 1 devops devops  87 Feb  4 06:22 hosts
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 304 Feb  4 09:26 users.yml
[devops@app1 project]$ vim users.yml
[devops@app1 project]$ ansibe-playbook users.yml
-bash: ansibe-playbook: command not found
[devops@app1 project]$ ansible-playbook users.yml
ERROR! Syntax Error while loading YAML.
  found unexpected end of stream

The error appears to be in '/home/devops/project/users.yml': line 22, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

(specified line no longer in file, maybe it changed?)
[devops@app1 project]$ vim users.yml
[devops@app1 project]$ ansible-playbook users.yml
ERROR! Attempting to decrypt but no vault secrets found
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass
Vault password: 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [SSH Copy Public Key] *******************************************************************
changed: [192.168.3.7]
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ssh ajju@192.168.3.6
Last login: Tue Feb  4 09:40:16 2020 from 192.168.3.5
-sh-4.2$ whoami
ajju
-sh-4.2$ exit
logout
Connection to 192.168.3.6 closed.
[devops@app1 project]$ ssh ajju@192.168.3.7
-sh-4.2$ whoami
ajju
-sh-4.2$ hostname
app3.dev
-sh-4.2$ exit
logout
Connection to 192.168.3.7 closed.
[devops@app1 project]$ vim .myvaultpassword.txt
[devops@app1 project]$ ansible-playbook users.yml --ask-password-file .myvaultpassword.txt 
usage: ansible-playbook [-h] [--version] [-v] [-k]
                        [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
                        [-c CONNECTION] [-T TIMEOUT]
                        [--ssh-common-args SSH_COMMON_ARGS]
                        [--sftp-extra-args SFTP_EXTRA_ARGS]
                        [--scp-extra-args SCP_EXTRA_ARGS]
                        [--ssh-extra-args SSH_EXTRA_ARGS] [--force-handlers]
                        [--flush-cache] [-b] [--become-method BECOME_METHOD]
                        [--become-user BECOME_USER] [-K] [-t TAGS]
                        [--skip-tags SKIP_TAGS] [-C] [--syntax-check] [-D]
                        [-i INVENTORY] [--list-hosts] [-l SUBSET]
                        [-e EXTRA_VARS] [--vault-id VAULT_IDS]
                        [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
                        [-f FORKS] [-M MODULE_PATH] [--list-tasks]
                        [--list-tags] [--step] [--start-at-task START_AT_TASK]
                        playbook [playbook ...]
ansible-playbook: error: unrecognized arguments: --ask-password-file .myvaultpassword.txt
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ cat .myvaultpassword.txt 
AjjuR0ck$
[devops@app1 project]$ vim .myvaultpassword.txt 
[devops@app1 project]$ cat .myvaultpassword.txt 
AjjuR0ck$
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ cat .myvaultpassword.txt 
AjjuR0ck$
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass
Vault password:  [ERROR]: User interrupted execution

[devops@app1 project]$ vim .myvaultpassword.txt 
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [SSH Copy Public Key] *******************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat .myvaultpassword.txt 
Acc1234$$
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ vim ansible.cfg 
[devops@app1 project]$ ansible-playbook users.yml 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]
ok: [192.168.3.7]

TASK [Adding a User Account] *****************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [SSH Copy Public Key] *******************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
remote_user=devops
ask_pass=False
vault_password_file=.myvaultpassword.txt

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ vim loops.yml
[devops@app1 project]$ ansible-playbook loops.yml --syntax-check

playbook: loops.yml
[devops@app1 project]$ ansible-playbook loops.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Install rpms] **************************************************************************
changed: [192.168.3.6]

TASK [Starting Service] **********************************************************************
ok: [192.168.3.6] => (item=httpd)
changed: [192.168.3.6] => (item=vsftpd)
ok: [192.168.3.6] => (item=mariadb)

TASK [Adding Users] **************************************************************************
changed: [192.168.3.6] => (item=user1)
changed: [192.168.3.6] => (item=user2)
changed: [192.168.3.6] => (item=user3)

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim loops.yml
[devops@app1 project]$ ansible-playbook loops.yml 
ERROR! Vars in a Play must be specified as a dictionary, or a list of dictionaries

The error appears to be in '/home/devops/project/loops.yml': line 5, column 5, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  vars:
    - httpd
    ^ here

[devops@app1 project]$ vim loops.yml
[devops@app1 project]$ ansible-playbook loops.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Install rpms] **************************************************************************
ok: [192.168.3.6]

TASK [Starting Service] **********************************************************************
ok: [192.168.3.6] => (item=httpd)
ok: [192.168.3.6] => (item=vsftpd)
ok: [192.168.3.6] => (item=mariadb)

TASK [Adding Users] **************************************************************************
ok: [192.168.3.6] => (item=user1)
ok: [192.168.3.6] => (item=user2)
ok: [192.168.3.6] => (item=user3)

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat loops.yml 
---
- name: Play1
  hosts: webserver
  vars:
    pkg:
    - httpd
    - vsftpd
    - mariadb
  tasks:
    - name: Install rpms
      yum:
        name:
          - elinks
          - git 
          - tree
          - httpd
          - vsftpd
          - mariadb
        state: latest

    - name: Starting Service
      service:
        name: "{{ item }}"
        state: started
      loop: "{{ pkg }}"

    - name: Adding Users
      user:
        name: "{{ item }}"
        state: present
      loop:
        - user1
        - user2
        - user3
[devops@app1 project]$ vim loops.yml 
[devops@app1 project]$ ansible-playbook loops.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Install rpms] **************************************************************************
ok: [192.168.3.6]

TASK [Starting Service] **********************************************************************
ok: [192.168.3.6] => (item=httpd)
ok: [192.168.3.6] => (item=vsftpd)
ok: [192.168.3.6] => (item=mariadb)

TASK [Adding Users] **************************************************************************
ok: [192.168.3.6] => (item=user1)
ok: [192.168.3.6] => (item=user2)
ok: [192.168.3.6] => (item=user3)

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat loops.yml 
---
- name: Play1
  hosts: webserver
  vars:
    pkg:
    - httpd
    - vsftpd
    - mariadb
  tasks:
    - name: Install rpms
      yum:
        name:
          - elinks
          - git 
          - tree
          - httpd
          - vsftpd
          - mariadb
        state: latest

    - name: Starting Service
      service:
        name: "{{ item }}"
        state: started
      loop: "{{ pkg }}"

    - name: Adding Users
      user:
        name: "{{ item }}"
        state: present
      with_items:
        - user1
        - user2
        - user3
[devops@app1 project]$ vim play.yml
[devops@app1 project]$ ansible-playbook play.yml --syntax-check
ERROR! Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/home/devops/project/play.yml': line 9, column 4, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

      - Fedora
   tasks:
   ^ here

[devops@app1 project]$ vim play.yml
[devops@app1 project]$ ansible-playbook play.yml --syntax-check
ERROR! Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/home/devops/project/play.yml': line 9, column 4, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

      - Fedora
   - tasks:
   ^ here

[devops@app1 project]$ vim play.yml
[devops@app1 project]$ ansible-playbook play.yml --syntax-check

playbook: play.yml
[devops@app1 project]$ ansible-playbook play.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is EL] ********************************************************
ok: [192.168.3.6]
changed: [192.168.3.7]

TASK [Install Apache PKG if OS is Ubuntu] ****************************************************
skipping: [192.168.3.6]
skipping: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat play.yml
---
- name: Play2
  hosts: all
  vars:
    supported_distros:
      - CentOS
      - RedHat
      - Fedora

  tasks:
    - name: Install Apache PKG if OS is EL
      yum:
        name: httpd
        state: present
      when: ansible_distribution == "CentOS"

    - name: Install Apache PKG if OS is Ubuntu
      apt:
        name: apache2
        state: present
      when: ansible_distribution == "Ubuntu"
[devops@app1 project]$ mv play.yml [devops@app1 project]$ cat play.yml
mv: target 'play.yml' is not a directory
[devops@app1 project]$ ---
-bash: ---: command not found
[devops@app1 project]$ - name: Play2
-bash: -: command not found
[devops@app1 project]$   hosts: all
-bash: hosts:: command not found
[devops@app1 project]$   vars:
-bash: vars:: command not found
[devops@app1 project]$     supported_distros:
-bash: supported_distros:: command not found
[devops@app1 project]$       - CentOS
-bash: -: command not found
[devops@app1 project]$       - RedHat
-bash: -: command not found
[devops@app1 project]$       - Fedora
-bash: -: command not found
[devops@app1 project]$ 
[devops@app1 project]$   tasks:
-bash: tasks:: command not found
[devops@app1 project]$     - name: Install Apache PKG if OS is EL
-bash: -: command not found
[devops@app1 project]$       yum:
-bash: yum:: command not found
[devops@app1 project]$         name: httpd
-bash: name:: command not found
[devops@app1 project]$         state: present
-bash: state:: command not found
[devops@app1 project]$       when: ansible_distribution == "CentOS"
-bash: when:: command not found
[devops@app1 project]$ 
[devops@app1 project]$     - name: Install Apache PKG if OS is Ubuntu
-bash: -: command not found
[devops@app1 project]$       apt:
-bash: apt:: command not found
[devops@app1 project]$         name: apache2
-bash: name:: command not found
[devops@app1 project]$         state: present
-bash: state:: command not found
[devops@app1 project]$       when: ansible_distribution == "Ubuntu"^C
[devops@app1 project]$ ^C
[devops@app1 project]$ ll
total 48
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
-rw-rw-r--. 1 devops devops  87 Feb  4 06:22 hosts
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops 198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops 557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops 408 Feb  4 10:58 play.yml
[devops@app1 project]$ mv play.yml conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]
ok: [192.168.3.7]

TASK [Install Apache PKG if OS is EL] ********************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is Ubuntu] ****************************************************
skipping: [192.168.3.6]
skipping: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is EL] ********************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is Ubuntu] ****************************************************
skipping: [192.168.3.6]
skipping: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ cat hosts 
[webserver]
node1 ansible_host=192.168.3.6

[dbserver]
node2 ansible_host=192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ ansible node1 -m ping
node1 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ ansible node2 -m ping
node2 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [node2]
ok: [node1]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [node2]
skipping: [node1]

TASK [Installing Database Package] ***********************************************************
skipping: [node1]
skipping: [node2]

PLAY RECAP ***********************************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   

[devops@app1 project]$ vi hosts 
[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [app3]
ok: [app2]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [app3]
ok: [app2]

TASK [Installing Database Package] ***********************************************************
skipping: [app2]
changed: [app3]

PLAY RECAP ***********************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat hosts 
[webserver]
app2 ansible_host=192.168.3.6

[dbserver]
app3 ansible_host=192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ cat conditions.yml
---
- name: Play2
  hosts: all
  vars:
    supported_distros:
      - CentOS
      - RedHat
      - Fedora

  tasks:
    - name: Install Apache PKG if OS is EL
      yum:
        name: httpd
        state: present
      #when: ansible_distribution == "CentOS"
      #when: ansible_distribution in supported_distros
      when: ansible_hostname in groups['webserver']

    #- name: Install Apache PKG if OS is Ubuntu
    #  apt:
    #    name: apache2
    #    state: present
    #  when: ansible_distribution == "Ubuntu"

    - name: Installing Database Package
      yum:
        name: mariadb-server
        state: latest
      when: ansible_hostname in groups['dbserver']
[devops@app1 project]$ ansible all -m setup -a filter=ansible_hostname
app2 | SUCCESS => {
    "ansible_facts": {
        "ansible_hostname": "app2", 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
app3 | SUCCESS => {
    "ansible_facts": {
        "ansible_hostname": "app3", 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ ansible all -a "hostnamectl"
app3 | CHANGED | rc=0 >>
   Static hostname: app3.dev
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 4a3369a823a64378a8ed4fa5e1225aa2
           Boot ID: 48b1b765568c4a3fad4af05bd9056577
    Virtualization: kvm
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-957.12.2.el7.x86_64
      Architecture: x86-64

app2 | CHANGED | rc=0 >>
   Static hostname: app2.dev
         Icon name: computer-vm
           Chassis: vm
        Machine ID: e6367a4627964527b496be84d8dfee8e
           Boot ID: 60112875e7334263805b5524d2ca597d
    Virtualization: kvm
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-957.12.2.el7.x86_64
      Architecture: x86-64

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [app3]
ok: [app2]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [app3]
ok: [app2]

TASK [Installing Database Package] ***********************************************************
skipping: [app2]
ok: [app3]

PLAY RECAP ***********************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [app2]
ok: [app3]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [app3]
ok: [app2]

TASK [Installing Database Package] ***********************************************************
skipping: [app2]
ok: [app3]

PLAY RECAP ***********************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat conditions.yml
---
- name: Play2
  hosts: all
  vars:
    supported_distros:
      - CentOS
      - RedHat
      - Fedora

  tasks:
    - name: Install Apache PKG if OS is EL
      yum:
        name: httpd
        state: present
      #when: ansible_distribution == "CentOS"
      #when: ansible_distribution in supported_distros
      when: ansible_hostname in groups['webserver'] and ansible_distribution in supported_distros

    #- name: Install Apache PKG if OS is Ubuntu
    #  apt:
    #    name: apache2
    #    state: present
    #  when: ansible_distribution == "Ubuntu"

    - name: Installing Database Package
      yum:
        name: mariadb-server
        state: latest
      when: inventory_hostname in groups['dbserver'] or ansible_distribution == "Ubuntu"
[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ 
[devops@app1 project]$ vi /etc/ansible/ansible.cfg 
[devops@app1 project]$ ll
total 48
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops 198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops 557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops 123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 836 Feb  4 11:31 conditions.yml
[devops@app1 project]$ ll
total 48
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops 198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops 557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops 123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 836 Feb  4 11:31 conditions.yml
[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ ll ~/.vim
.viminfo  .vimrc    
[devops@app1 project]$ ll ~/.vimrc 
-rw-rw-r--. 1 devops devops 28 Feb  3 10:29 /home/devops/.vimrc
[devops@app1 project]$ cat ~/.vimrc 
set ai et ts=2 cursorcolumn
[devops@app1 project]$ unset ai et ts=2 cursorcolumn
-bash: unset: `ts=2': not a valid identifier
[devops@app1 project]$ unset ai et 
[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ ansible-playbook conditions.yml 
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/conditions.yml': line 2, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---A
- name: Play2
      ^ here

[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ ansible-playbook conditions.yml 
[WARNING]: While constructing a mapping from /home/devops/project/conditions.yml, line 11, column 7, found a duplicate
dict key (when). Using last defined value only.


PLAY [Play2] **********************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************
ok: [app2]
ok: [app3]

TASK [Install Apache PKG if OS is EL] *********************************************************************************
fatal: [app3]: FAILED! => {"msg": "The conditional check 'ansible_total_mem != 15000' failed. The error was: error while evaluating conditional (ansible_total_mem != 15000): 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/conditions.yml': line 11, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Install Apache PKG if OS is EL\n      ^ here\n"}
fatal: [app2]: FAILED! => {"msg": "The conditional check 'ansible_total_mem != 15000' failed. The error was: error while evaluating conditional (ansible_total_mem != 15000): 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/conditions.yml': line 11, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Install Apache PKG if OS is EL\n      ^ here\n"}

PLAY RECAP ************************************************************************************************************
app2                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
app3                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cp conditions.yml  test.yml
[devops@app1 project]$ vim test.yml 
[devops@app1 project]$ ansible-playbook test.yml 

PLAY [Play2] **********************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************
ok: [app2]
ok: [app3]

TASK [Facts Find | Debug facts] ***************************************************************************************
fatal: [app2]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/test.yml': line 5, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Facts Find | Debug facts\n      ^ here\n"}
fatal: [app3]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/test.yml': line 5, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Facts Find | Debug facts\n      ^ here\n"}

PLAY RECAP ************************************************************************************************************
app2                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
app3                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim test.yml 
[devops@app1 project]$ ls -ltr
total 52
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  215 Feb  4 23:32 test.yml
[devops@app1 project]$ vi users.yml 
[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ vim test.yml 
[devops@app1 project]$ ansible-playbook test.yml 

PLAY [Play2] **********************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************
ok: [app3]
ok: [app2]

TASK [Facts Find | Debug facts] ***************************************************************************************
ok: [app2] => {
    "msg": [
        "ansible_distribution: CentOS", 
        "ansible_hostname: app2"
    ]
}
ok: [app3] => {
    "msg": [
        "ansible_distribution: CentOS", 
        "ansible_hostname: app3"
    ]
}

PLAY RECAP ************************************************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi conditions.yml 
[devops@app1 project]$ vi users.yml 
[devops@app1 project]$ pwd
/home/devops/project
[devops@app1 project]$ ll
total 52
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check
ERROR! 'var' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/apache.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Play for WebServer
  ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible node2 -m ping
[WARNING]: Could not match supplied host pattern, ignoring: node2

[WARNING]: No hosts matched, nothing to do

[devops@app1 project]$ ansible all -m ping -v
Using /home/devops/project/ansible.cfg as config file
app3 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
app2 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check
ERROR! conflicting action statements: dest, copy

The error appears to be in '/home/devops/project/apache.yml': line 36, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


    - name: Create Documnet root for WebServer
      ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check
ERROR! conflicting action statements: dest, copy

The error appears to be in '/home/devops/project/apache.yml': line 36, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


    - name: Create Document root for WebServer
      ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check

playbook: apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
changed: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
changed: [app2]

TASK [Make config changes] ***************************************************************************
changed: [app2]

RUNNING HANDLER [Restart Apache] *********************************************************************
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=7    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat apache.yml
---
- name: Play for WebServer
  hosts: webserver
  become: true
  remote_user: devops
  vars:
    web_pkg: httpd
    fw_pkg: firewalld
    web_srv: httpd
    fw_srv: firewalld
    fw_rule: http

  tasks:
    - name: Install Packages
      yum: 
        name: "{{ item }}"
        state: latest
      loop:
        - "{{ web_pkg }}"
        - "{{ fw_pkg }}"

    - name: Starting Services
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      loop:
        - "{{ web_srv }}"
        - "{{ fw_srv }}"

    - name: allow {{ fw_rule }} in firewalld
      firewalld:
        service: "{{ fw_rule }}"
        state: enabled

    - name: Create Document root for WebServer
      copy: 
        content: "<h1>Hey Azher Khan You are a Rock Star, I am {{ ansible_fqdn }}</h1>"
        dest: /var/www/html/custom.html

    - name: Make config changes
      replace:
        path: /etc/httpd/conf/httpd.conf
        regexp: "index.html"
        replace: "custom.html"
      notify: Restart Apache

  handlers:
    - name: Restart Apache
      service:
        name: "{{ web_srv }}"
        state: restarted


[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

PLAY RECAP *******************************************************************************************
app2                       : ok=7    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=1   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/apache.yml': line 56, column 12, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

    - debug: Output of the Install hello Pkg Task
        var: output
           ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "output": {
        "changed": false, 
        "failed": true, 
        "msg": "No package matching 'hello' found available, installed or updated", 
        "rc": 126, 
        "results": [
            "No package matching 'hello' found available, installed or updated"
        ]
    }
}

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=1   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [Print the Output message] **********************************************************************
ok: [app2] => {
    "msg": "Setting up a Repo"
}

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=1   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "output": {
        "changed": false, 
        "failed": true, 
        "msg": "No package matching 'hello' found available, installed or updated", 
        "rc": 126, 
        "results": [
            "No package matching 'hello' found available, installed or updated"
        ]
    }
}

TASK [Print the Output message] **********************************************************************
skipping: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=1   

[devops@app1 project]$ cat apache.yml
---
- name: Play for WebServer
  hosts: webserver
  become: true
  remote_user: devops
  vars:
    web_pkg: httpd
    fw_pkg: firewalld
    web_srv: httpd
    fw_srv: firewalld
    fw_rule: http

  tasks:
    - name: Install Packages
      yum: 
        name: "{{ item }}"
        state: latest
      loop:
        - "{{ web_pkg }}"
        - "{{ fw_pkg }}"

    - name: Starting Services
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      loop:
        - "{{ web_srv }}"
        - "{{ fw_srv }}"

    - name: allow {{ fw_rule }} in firewalld
      firewalld:
        service: "{{ fw_rule }}"
        state: enabled

    - name: Create Document root for WebServer
      copy: 
        content: "<h1>Hey Azher Khan You are a Rock Star, I am {{ ansible_fqdn }}</h1>"
        dest: /var/www/html/custom.html

    - name: Make config changes
      replace:
        path: /etc/httpd/conf/httpd.conf
        regexp: "index.html"
        replace: "custom.html"
      notify: Restart Apache

    - name: Install hello Pkg
      yum:
        name: hello
        state: latest
      register: output
      ignore_errors: true

    - debug:
        var: output
      register: output1

    - name: Print the Output message
      debug:
        msg: "Setting up a Repo"
      when: output.failed == true and output1.changed == true

  handlers:
    - name: Restart Apache
      service:
        name: "{{ web_srv }}"
        state: restarted


[devops@app1 project]$ vim apache.yml
[devops@app1 project]$ cat apache.yml
---
- name: Play for WebServer
  hosts: webserver
  become: true
  force_handler: true
  remote_user: devops
  vars:
    web_pkg: httpd
    fw_pkg: firewalld
    web_srv: httpd
    fw_srv: firewalld
    fw_rule: http

  tasks:
    - name: Install Packages
      yum: 
        name: "{{ item }}"
        state: latest
      loop:
        - "{{ web_pkg }}"
        - "{{ fw_pkg }}"

    - name: Starting Services
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      loop:
        - "{{ web_srv }}"
        - "{{ fw_srv }}"

    - name: allow {{ fw_rule }} in firewalld
      firewalld:
        service: "{{ fw_rule }}"
        state: enabled

    - name: Create Document root for WebServer
      copy: 
        content: "<h1>Hey Azher Khan You are a Rock Star, I am {{ ansible_fqdn }}</h1>"
        dest: /var/www/html/custom.html

    - name: Make config changes
      replace:
        path: /etc/httpd/conf/httpd.conf
        regexp: "index.html"
        replace: "custom.html"
      notify: Restart Apache

    - name: Install hello Pkg
      yum:
        name: hello
        state: latest
      register: output
      ignore_errors: true

    - debug:
        var: output
      register: output1

    - name: Print the Output message
      debug:
        msg: "Setting up a Repo"
      when: output.failed == true and output1.changed == true

  handlers:
    - name: Restart Apache
      service:
        name: "{{ web_srv }}"
        state: restarted


[devops@app1 project]$ ansible-playbook apache.yml 
ERROR! 'force_handler' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/apache.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Play for WebServer
  ^ here

[devops@app1 project]$ vim apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "output": {
        "changed": false, 
        "failed": true, 
        "msg": "No package matching 'hello' found available, installed or updated", 
        "rc": 126, 
        "results": [
            "No package matching 'hello' found available, installed or updated"
        ]
    }
}

TASK [Print the Output message] **********************************************************************
skipping: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=1   

[devops@app1 project]$ vi file.yml
[devops@app1 project]$ mv file.yml file.txt
[devops@app1 project]$ #vi file.j2
[devops@app1 project]$ vi file.j2
[devops@app1 project]$ vi network.yml
[devops@app1 project]$ cat network.yml
---
- name: Create J2 Template
  hosts: all
  tasks:
    - name: Generating Template
      template: 
        src: file.j2
        dest: "/tmp/ifcfg-{{ ansible_facts.default_ipv4.interface }}"
[devops@app1 project]$ cat file.j2 
{# This is a Sample template (comments) ifcfg-eth0 #}
DEVICE={{ ansible_facts.default_ipv4.interface }} 
ONBOOT=yes
BOOTPROTO=none
IPADDR={{ ansible_facts.default_ipv4.address }}
NETMASK={{ ansible_facts.default_ipv4.netmask }}
GATEWAY={{ ansible_facts.default_ipv4.gateway }}
DNS1={{ ansible_dns.nameservers[0] }}

[devops@app1 project]$ ansible-playbook network.yml --syntax-check

playbook: network.yml
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ls -ltr
total 68
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  316 Feb  5 06:22 file.j2
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
[devops@app1 project]$ cat file.j2 
{# This is a Sample template (comments) ifcfg-eth0 #}
DEVICE={{ ansible_facts.default_ipv4.interface }} 
ONBOOT=yes
BOOTPROTO=none
IPADDR={{ ansible_facts.default_ipv4.address }}
NETMASK={{ ansible_facts.default_ipv4.netmask }}
GATEWAY={{ ansible_facts.default_ipv4.gateway }}
DNS1={{ ansible_dns.nameservers[0] }}

[devops@app1 project]$ cat network.yml 
---
- name: Create J2 Template
  hosts: all
  tasks:
    - name: Generating Template
      template: 
        src: file.j2
        dest: "/tmp/ifcfg-{{ ansible_facts.default_ipv4.interface }}"
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
ok: [app3]
ok: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg*"
app3 | FAILED | rc=1 >>
cat: /tmp/ifcfg*: No such file or directorynon-zero return code

app2 | FAILED | rc=1 >>
cat: /tmp/ifcfg*: No such file or directorynon-zero return code

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg-eth0"
app3 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

app2 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

[devops@app1 project]$ vi file.j2 
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg-eth0"
app3 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
#IPADDR=10.0.2.15
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

app2 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
#IPADDR=10.0.2.15
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

[devops@app1 project]$ 

[devops@app1 project]$ vi file.j2 
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg-eth0"
app3 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR1=10.0.2.15
IPADDR2=192.168.3.7
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

app2 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR1=10.0.2.15
IPADDR2=192.168.3.6
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

[devops@app1 project]$ cat file.j2 
{# This is a Sample template (comments) ifcfg-eth0 #}
DEVICE={{ ansible_facts.default_ipv4.interface }} 
ONBOOT=yes
BOOTPROTO=none
IPADDR1={{ ansible_facts.default_ipv4.address }}
IPADDR2={{ ansible_facts.all_ipv4_addresses[1] }}
NETMASK={{ ansible_facts.default_ipv4.netmask }}
GATEWAY={{ ansible_facts.default_ipv4.gateway }}
DNS1={{ ansible_dns.nameservers[0] }}

[devops@app1 project]$ ansible all -a "{{ ansible_facts.all_ipv4_addresses[1] }}"
app2 | FAILED | rc=-1 >>
The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'

app3 | FAILED | rc=-1 >>
The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'

[devops@app1 project]$ ansible all "{{ ansible_facts.all_ipv4_addresses[1] }}"
usage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD]
               [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts]
               [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k]
               [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
               [-c CONNECTION] [-T TIMEOUT]
               [--ssh-common-args SSH_COMMON_ARGS]
               [--sftp-extra-args SFTP_EXTRA_ARGS]
               [--scp-extra-args SCP_EXTRA_ARGS]
               [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D]
               [-e EXTRA_VARS] [--vault-id VAULT_IDS]
               [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
               [-f FORKS] [-M MODULE_PATH] [--playbook-dir BASEDIR]
               [-a MODULE_ARGS] [-m MODULE_NAME]
               pattern
ansible: error: unrecognized arguments: {{ ansible_facts.all_ipv4_addresses[1] }}
[devops@app1 project]$ ansible all -m setup -a "{{ ansible_facts.all_ipv4_addresses[1] }}"
app2 | FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'"
}
app3 | FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'"
}
[devops@app1 project]$ ansible all -m setup -a "*ipv4*"
ERROR! this task 'setup' has extra params, which is only allowed in the following modules: shell, win_shell, include_vars, add_host, raw, include_role, meta, set_fact, include, import_tasks, script, import_role, include_tasks, group_by, command, win_command
[devops@app1 project]$ ansible localhost -m setup -a "*ipv4*"
ERROR! this task 'setup' has extra params, which is only allowed in the following modules: shell, win_shell, include_vars, add_host, raw, include_role, meta, set_fact, include, import_tasks, script, import_role, include_tasks, group_by, command, win_command
[devops@app1 project]$ ansible localhost -m setup -a "filter=*ipv4*"
localhost | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "192.168.3.5", 
            "10.0.2.15"
        ], 
        "ansible_default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }
    }, 
    "changed": false
}
[devops@app1 project]$ ansible all -m setup -a "filter=*ipv4*"
app3 | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "10.0.2.15", 
            "192.168.3.7"
        ], 
        "ansible_default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }, 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
app2 | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "10.0.2.15", 
            "192.168.3.6"
        ], 
        "ansible_default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }, 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ ansible localhost -m setup -a 'filter=ansible_eth*'
localhost | SUCCESS => {
    "ansible_facts": {
        "ansible_eth0": {
            "active": true, 
            "device": "eth0", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "10.0.2.15", 
                "broadcast": "10.0.2.255", 
                "netmask": "255.255.255.0", 
                "network": "10.0.2.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::5054:ff:fe8a:fee6", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "52:54:00:8a:fe:e6", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:03.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "ansible_eth1": {
            "active": true, 
            "device": "eth1", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "192.168.3.5", 
                "broadcast": "192.168.3.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.3.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::a00:27ff:fe7f:509", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "08:00:27:7f:05:09", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:08.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }
    }, 
    "changed": false
}
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}
ok: [app3] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}

PLAY RECAP *******************************************************************************************
app2                       : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat static.yml
---
- name: Playbook to display Static Module Manipulation
  hosts: all
  tasks:
    - name: Verify the Directory exists
      stat:
        path: /tmp/files
      register: var1

    - debug:
        var: var1
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}
ok: [app3] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}

TASK [Creating a Directory] **************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "atime": 1580885757.3520622, 
            "attr_flags": "", 
            "attributes": [], 
            "block_size": 4096, 
            "blocks": 0, 
            "charset": "binary", 
            "ctime": 1580885757.3520622, 
            "dev": 2049, 
            "device_type": 0, 
            "executable": true, 
            "exists": true, 
            "gid": 1001, 
            "gr_name": "devops", 
            "inode": 100817496, 
            "isblk": false, 
            "ischr": false, 
            "isdir": true, 
            "isfifo": false, 
            "isgid": false, 
            "islnk": false, 
            "isreg": false, 
            "issock": false, 
            "isuid": false, 
            "mimetype": "inode/directory", 
            "mode": "0775", 
            "mtime": 1580885757.3520622, 
            "nlink": 2, 
            "path": "/tmp/files", 
            "pw_name": "devops", 
            "readable": true, 
            "rgrp": true, 
            "roth": true, 
            "rusr": true, 
            "size": 6, 
            "uid": 1001, 
            "version": "1696186859", 
            "wgrp": true, 
            "woth": false, 
            "writeable": true, 
            "wusr": true, 
            "xgrp": true, 
            "xoth": true, 
            "xusr": true
        }
    }
}
ok: [app3] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "atime": 1580885757.3034186, 
            "attr_flags": "", 
            "attributes": [], 
            "block_size": 4096, 
            "blocks": 0, 
            "charset": "binary", 
            "ctime": 1580885757.3034186, 
            "dev": 2049, 
            "device_type": 0, 
            "executable": true, 
            "exists": true, 
            "gid": 1001, 
            "gr_name": "devops", 
            "inode": 4796004, 
            "isblk": false, 
            "ischr": false, 
            "isdir": true, 
            "isfifo": false, 
            "isgid": false, 
            "islnk": false, 
            "isreg": false, 
            "issock": false, 
            "isuid": false, 
            "mimetype": "inode/directory", 
            "mode": "0775", 
            "mtime": 1580885757.3034186, 
            "nlink": 2, 
            "path": "/tmp/files", 
            "pw_name": "devops", 
            "readable": true, 
            "rgrp": true, 
            "roth": true, 
            "rusr": true, 
            "size": 6, 
            "uid": 1001, 
            "version": "18446744073082428293", 
            "wgrp": true, 
            "woth": false, 
            "writeable": true, 
            "wusr": true, 
            "xgrp": true, 
            "xoth": true, 
            "xusr": true
        }
    }
}

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
ok: [app3]
ok: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
changed: [app2]
changed: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml --syntax-check

playbook: static.yml
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml --syntax-check

playbook: static.yml
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
ok: [app3]
ok: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
fatal: [app3]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app3 does not exist !", "rc": 257}
fatal: [app2]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app2 does not exist !", "rc": 257}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=2    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
app3                       : ok=6    changed=2    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app2]
changed: [app3]

TASK [Adding a Set of Lines in the file] *************************************************************
fatal: [app3]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app3 does not exist !", "rc": 257}
fatal: [app2]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app2 does not exist !", "rc": 257}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
app3                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app2 does not exist !", "rc": 257}
fatal: [app3]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app3 does not exist !", "rc": 257}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
app3                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app2]
ok: [app3]

TASK [Creating a Directory] **************************************************************************
skipping: [app3]
skipping: [app2]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app3]
changed: [app2]

TASK [Add a line Before a regex] *********************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=8    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app3]
skipping: [app2]

TASK [Creating file using copy module] ***************************************************************
changed: [app2]
changed: [app3]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app3]
changed: [app2]

TASK [Add a line Before a regex] *********************************************************************
changed: [app3]
changed: [app2]

TASK [Copy files from managed nodes] *****************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=9    changed=6    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=9    changed=6    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ ll
total 80
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops 1830 Feb  5 07:26 static.yml
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
[devops@app1 project]$ cat app2.txt 
Sample file using the MOVED Module in 192.168.3.6 instance 
This is the Second Line in the file using LINEINFILE module
# BEGIN ANSIBLE MANAGED BLOCK
Using the Block Module and as you can see this is the First line
Hehehe Added more content
I know i need to stop now but this is the third line
# END ANSIBLE MANAGED BLOCK
[devops@app1 project]$ cat app3.txt 
Sample file using the MOVED Module in 192.168.3.7 instance 
This is the Second Line in the file using LINEINFILE module
# BEGIN ANSIBLE MANAGED BLOCK
Using the Block Module and as you can see this is the First line
Hehehe Added more content
I know i need to stop now but this is the third line
# END ANSIBLE MANAGED BLOCK
[devops@app1 project]$ date
Wed Feb  5 07:27:36 UTC 2020
[devops@app1 project]$ cat static.yml 
---
- name: Playbook to display Static Module Manipulation
  hosts: all
  tasks:
    - name: Verify the Directory exists
      stat:
        path: /tmp/files
      register: var1

    #- debug:
    #    var: var1

    - name: Creating a Directory
      file:
        path: /tmp/files
        state: directory
        owner: devops
        group: devops
        mode: 0775
      when: var1.stat.exists == false

    - name: Creating file using copy module
      copy:
        content: "Sample file using the Copy Module in {{ ansible_facts.all_ipv4_addresses[1] }} instance "
        dest: "/tmp/files/{{ ansible_hostname }}.txt"

    - name : Copy file from controller to manage nodes
      copy:
        src: index.html
        dest: /tmp/files/

    - name: Replace the content of existing file
      replace:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        regexp: "Copy"
        replace: "MOVED"

    - name: Appending a New line in the existing file
      lineinfile:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        line: "This is the Second Line in the file using LINEINFILE module"

    - name: Adding a Set of Lines in the file
      blockinfile:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        block: |
          Using the Block Module and as you can see this is the First line
          Yep this is the second line like you didnt know
          I know i need to stop now but this is the third line
        
    - name: Add a line Before a regex
      lineinfile:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        regexp: "^Yep"
        insertbefore: "^second"
        line: "Hehehe Added more content"

    - name: Copy files from managed nodes
      fetch:
        src: "/tmp/files/{{ ansible_hostname }}.txt"
        dest: /home/devops/project/
        flat: true
[devops@app1 project]$ ls -ltr
total 80
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops 1830 Feb  5 07:26 static.yml
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
[devops@app1 project]$ 




ansible ungrouped  --list-hosts    -i  inventory
#inventory : all  | ungrouped
ansible web,db --list-hosts -i inventory
ansible "*" --list-hosts -i inventory
#ansible "*" --list-hosts -i inventory
ansible "node*" --list-hosts -i inventory
#ansible "node*" --list-hosts -i inventory
cat inventory
ansible "*example.com" --list-hosts -i inventory
#hosts: "*"  web,db,192.168.56.*
ansible web --list-hosts -i inventory
ansible 'web,!node1.example.com' --list-hosts -i inventory
ansible 'web&db' --list-hosts -i inventory
ansible 'web,&db' --list-hosts -i inventory
ansible 'db' --list-hosts -i inventory
##hosts: all|ungrouped|"*"|web,db|node1,node2,node3|'web,!node1'|'web,&db'
cat inventory
#/etc/ansible/hosts
#ansible 'db' --list-hosts -i inventory
#ansible 'web,&db' --list-hosts -i inventory
#ansible 'web,!node1.example.com' --list





[vagrant@app1 ~]$ 
 2020-02-03 15:07:42 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant ssh app1
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
Last login: Mon Feb  3 06:53:55 2020 from 192.168.3.1
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[vagrant@app1 ~]$ cl

















total 0
[vagrant@app1 ~]$ ansible-doc service
> SERVICE    (/usr/lib/python2.7/site-packages/ansible/modules/system/service.py)

        Controls services on remote hosts. Supported init systems include BSD init,
        OpenRC, SysV, Solaris SMF, systemd, upstart. For Windows targets, use the
        [win_service] module instead.

  * This module is maintained by The Ansible Core Team
  * note: This module has a corresponding action plugin.

OPTIONS (= is mandatory):

- arguments
        Additional arguments provided on the command line.
        (Aliases: args)[Default: (null)]
        type: str

- enabled
        Whether the service should start on boot.
        *At least one of state and enabled are required.*
        [Default: (null)]
        type: bool

= name
        Name of the service.

        type: str

- pattern
        If the service does not respond to the status command, name a substring to
        look for as would be found in the output of the `ps' command as a stand-in for
        a status result.
        If the string is found, the service will be assumed to be started.
        [Default: (null)]
        type: str
        version_added: 0.7

- runlevel
        For OpenRC init scripts (e.g. Gentoo) only.
        The runlevel that this service belongs to.
        [Default: default]
        type: str

...skipping...
EXAMPLES:

- name: Start service httpd, if not started
  service:
    name: httpd
    state: started

- name: Stop service httpd, if started
  service:
    name: httpd
    state: stopped

- name: Restart service httpd, in all cases
  service:
    name: httpd
    state: restarted

- name: Reload service httpd, in all cases
  service:
    name: httpd
    state: reloaded

- name: Enable service httpd, and not touch the state
  service:
    name: httpd
    enabled: yes

- name: Start service foo, based on running process /usr/bin/foo
  service:
    name: foo
    pattern: /usr/bin/foo
    state: started

- name: Restart network service for interface eth0
  service:
    name: network
    state: restarted
    args: eth0


~
~
[vagrant@app1 ~]$ ansible-doc yum
> YUM    (/usr/lib/python2.7/site-packages/ansible/modules/packaging/os/yum.py)

        Installs, upgrade, downgrades, removes, and lists packages and groups with the
        `yum' package manager. This module only works on Python 2. If you require
        Python 3 support see the [dnf] module.

  * This module is maintained by The Ansible Core Team
  * note: This module has a corresponding action plugin.

OPTIONS (= is mandatory):

- allow_downgrade
        Specify if the named package and version is allowed to downgrade a maybe
        already installed higher version of that package. Note that setting
        allow_downgrade=True can make this module behave in a non-idempotent way. The
        task could end up with a set of packages that does not match the complete list
        of specified packages to install (because dependencies between the downgraded
        package and others can cause changes to the packages which were in the earlier
        transaction).
        [Default: no]
        type: bool
        version_added: 2.4

- autoremove
        If `yes', removes all "leaf" packages from the system that were originally
        installed as dependencies of user-installed packages but which are no longer
        required by any such package. Should be used alone or when state is `absent'
        NOTE: This feature requires yum >= 3.4.3 (RHEL/CentOS 7+)
        [Default: no]
        type: bool
        version_added: 2.7

- bugfix
        If set to `yes', and `state=latest' then only installs updates that have been
        marked bugfix related.
        [Default: no]
        version_added: 2.6

- conf_file
        The remote yum configuration file to use for the transaction.
        [Default: (null)]
        version_added: 0.6
...skipping...
EXAMPLES:

- name: install the latest version of Apache
  yum:
    name: httpd
    state: latest

- name: ensure a list of packages installed
  yum:
    name: "{{ packages }}"
  vars:
    packages:
    - httpd
    - httpd-tools

- name: remove the Apache package
  yum:
    name: httpd
    state: absent

- name: install the latest version of Apache from the testing repo
  yum:
    name: httpd
    enablerepo: testing
    state: present

- name: install one specific version of Apache
  yum:
    name: httpd-2.2.29-1.4.amzn1
    state: present

- name: upgrade all packages
  yum:
    name: '*'
    state: latest

- name: upgrade all packages, excluding kernel & foo related packages
  yum:
    name: '*'
    state: latest
    exclude: kernel*,foo*

[vagrant@app1 ~]$ ansible-doc firewalld
> FIREWALLD    (/usr/lib/python2.7/site-packages/ansible/modules/system/firewalld.py)

        This module allows for addition or deletion of services and ports (either TCP
        or UDP) in either running or permanent firewalld rules.

  * This module is maintained by The Ansible Community
OPTIONS (= is mandatory):

- icmp_block
        The ICMP block you would like to add/remove to/from a zone in firewalld.
        [Default: (null)]
        type: str
        version_added: 2.8

- icmp_block_inversion
        Enable/Disable inversion of ICMP blocks for a zone in firewalld.
        [Default: (null)]
        type: str
        version_added: 2.8

- immediate
        Should this configuration be applied immediately, if set as permanent.
        [Default: False]
        type: bool
        version_added: 1.9

- interface
        The interface you would like to add/remove to/from a zone in firewalld.
        [Default: (null)]
        type: str
        version_added: 2.1

- masquerade
        The masquerade setting you would like to enable/disable to/from zones within
        firewalld.
        [Default: (null)]
        type: str
        version_added: 2.1

- offline
        Whether to run this module even when firewalld is offline.
        [Default: (null)]
...skipping...
EXAMPLES:

- firewalld:
    service: https
    permanent: yes
    state: enabled

- firewalld:
    port: 8081/tcp
    permanent: yes
    state: disabled

- firewalld:
    port: 161-162/udp
    permanent: yes
    state: enabled

- firewalld:
    zone: dmz
    service: http
    permanent: yes
    state: enabled

- firewalld:
    rich_rule: rule service name="ftp" audit limit value="1/m" accept
    permanent: yes
    state: enabled

- firewalld:
    source: 192.0.2.0/24
    zone: internal
    state: enabled

- firewalld:
    zone: trusted
    interface: eth2
    permanent: yes
    state: enabled

- firewalld:
    masquerade: yes
    state: enabled
[vagrant@app1 ~]$ ansible-doc httpd
[WARNING]: module httpd not found in:
/home/vagrant/.ansible/plugins/modules:/usr/share/ansible/plugins/modules:/usr/lib/python2.7/site-
packages/ansible/modules

[vagrant@app1 ~]$ ll
total 0
[vagrant@app1 ~]$ 
 2020-02-04 08:37:03 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → ssh vagrant@192.168.3.5
^C

 2020-02-04 09:35:27 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant ssh app1
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
Last login: Mon Feb  3 10:45:26 2020 from 10.0.2.2
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[vagrant@app1 ~]$ ssh vagrant@192.168.3.7
Last login: Tue Feb  4 04:07:20 2020 from 10.0.2.2
[vagrant@app3 ~]$ exit
logout
Connection to 192.168.3.7 closed.
[vagrant@app1 ~]$ ssh vagrant@192.168.3.6
Last login: Tue Feb  4 04:07:24 2020 from 10.0.2.2
[vagrant@app2 ~]$ exit
logout
Connection to 192.168.3.6 closed.
[vagrant@app1 ~]$ ping 192.168.3.7
PING 192.168.3.7 (192.168.3.7) 56(84) bytes of data.
64 bytes from 192.168.3.7: icmp_seq=1 ttl=64 time=0.303 ms
64 bytes from 192.168.3.7: icmp_seq=2 ttl=64 time=0.317 ms
64 bytes from 192.168.3.7: icmp_seq=3 ttl=64 time=0.477 ms
^C
--- 192.168.3.7 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2003ms
rtt min/avg/max/mdev = 0.303/0.365/0.477/0.081 ms
[vagrant@app1 ~]$ ping 8.8.8.8
PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
64 bytes from 8.8.8.8: icmp_seq=1 ttl=63 time=8.60 ms
64 bytes from 8.8.8.8: icmp_seq=2 ttl=63 time=8.23 ms
^C
--- 8.8.8.8 ping statistics ---
3 packets transmitted, 2 received, 33% packet loss, time 2004ms
rtt min/avg/max/mdev = 8.231/8.417/8.604/0.207 ms
[vagrant@app1 ~]$ vi /etc/ansible/ansible.cfg 
[vagrant@app1 ~]$ ansible all -m ping
192.168.3.6 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
192.168.3.7 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[vagrant@app1 ~]$ ll
total 0
[vagrant@app1 ~]$ ll
total 0
[vagrant@app1 ~]$ vi vars.yml
[vagrant@app1 ~]$ vim vars.yml
[vagrant@app1 ~]$ ls -altr
total 28
-rw-r--r--. 1 vagrant vagrant  231 Oct 30  2018 .bashrc
-rw-r--r--. 1 vagrant vagrant  193 Oct 30  2018 .bash_profile
-rw-r--r--. 1 vagrant vagrant   18 Oct 30  2018 .bash_logout
drwx------. 2 vagrant vagrant   80 Feb  3 05:12 .ssh
drwxr-xr-x. 4 root    root      35 Feb  3 07:14 ..
-rw-------. 1 vagrant vagrant   44 Feb  3 10:46 .lesshst
-rw-------. 1 vagrant vagrant 1051 Feb  4 04:10 .bash_history
drwx------. 4 vagrant vagrant   27 Feb  4 04:24 .ansible
-rw-rw-r--. 1 vagrant vagrant    4 Feb  4 04:33 vars.yml
-rw-------. 1 vagrant vagrant 1011 Feb  4 04:33 .viminfo
drwx------. 4 vagrant vagrant  159 Feb  4 04:33 .
[vagrant@app1 ~]$ vi ~/.vimrc 
[vagrant@app1 ~]$ . ~/.vimrc 
[vagrant@app1 ~]$ vim vars.yml
[vagrant@app1 ~]$ ansible-playbook vars.yml --syntax-check
[WARNING]: Could not match supplied host pattern, ignoring: webserver


playbook: vars.yml
[vagrant@app1 ~]$ sudo -iu devops
[devops@app1 ~]$ exit
logout
[vagrant@app1 ~]$ cp vars.yml /tmp/
[vagrant@app1 ~]$ sudo -iu devops
[devops@app1 ~]$ cd project/
[devops@app1 project]$ ll
total 16
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
[devops@app1 project]$ cp /tmp/vars.yml .
[devops@app1 project]$ ll
total 20
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops 532 Feb  4 04:49 vars.yml
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
changed: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat vars.yml 
---
- name: Play1
  hosts: webserver
  vars:
    pkg: httpd
    srv: httpd
    rule: http
    ## a-z | _ | 0-9 var1 var_1 >> _vars  1var
  tasks:
    - name: Installing {{ pkg }} Package
      yum:
        name: "{{ pkg }}"
        state: latest

    - name: Starting {{ srv }} Service
      service:
        name: "{{ srv }}"
        state: started
        enabled: true

    - name: Allow {{ rule }} in Firewall
      firewalld:
        service: "{{ rule }}"
        state: enabled
        permanent: true
        immediate: true
[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
remote_user=devops
ask_pass=False

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ ansible-playbook var_file.yml --syntax-check
ERROR! A playbook must be a list of plays, got a <class 'ansible.parsing.yaml.objects.AnsibleMapping'> instead

The error appears to be in '/home/devops/project/var_file.yml': line 2, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
pkg:
^ here

[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ ansible-playbook var_file.yml --syntax-check
ERROR! A playbook must be a list of plays, got a <class 'ansible.parsing.yaml.objects.AnsibleMapping'> instead

The error appears to be in '/home/devops/project/var_file.yml': line 2, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
pkg:
^ here

[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ cat var_file.yml
---
pkg:
  - httpd
  - firewalld
  - vim
  - elinks
  - top
  - git

srv: httpd
rule: http
[devops@app1 project]$ #vi 
[devops@app1 project]$ ll
total 24
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops 584 Feb  4 05:04 vars.yml
-rw-rw-r--. 1 devops devops  91 Feb  4 05:08 var_file.yml
[devops@app1 project]$ vi vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'httpd', u'firewalld', u'vim', u'elinks', u'top', u'git'] Package] ********
fatal: [192.168.3.6]: FAILED! => {"changed": false, "msg": "No package matching 'top' found available, installed or updated", "rc": 126, "results": ["All packages providing httpd are up to date", "All packages providing firewalld are up to date", "No package matching 'top' found available, installed or updated"]}

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim var_file.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'httpd', u'firewalld', u'vim', u'elinks', u'git'] Package] ****************
changed: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat vars.yml 
---
- name: Play1
  hosts: webserver
  become: true
  vars_files:
    - var_file.yml
  #vars:
    #pkg: httpd
    #srv: httpd
    #rule: http
    ## a-z | _ | 0-9 var1 var_1 >> _vars  1var
  tasks:
    - name: Installing {{ pkg }} Package
      yum:
        name: "{{ pkg }}"
        state: latest

    - name: Starting {{ srv }} Service
      service:
        name: "{{ srv }}"
        state: started
        enabled: true

    - name: Allow {{ rule }} in Firewall
      firewalld:
        service: "{{ rule }}"
        state: enabled
        permanent: true
        immediate: true
[devops@app1 project]$ cat var_file.yml 
---
pkg:
  - httpd
  - firewalld
  - vim
  - elinks
  - git

srv: httpd
rule: http
[devops@app1 project]$ ll
total 24
-rw-rw-r--. 1 devops devops  88 Feb  3 09:23 hosts
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops 584 Feb  4 05:04 vars.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ cat hosts 
[webserver]
192.168.3.6   pkg=vsftpd srv=vsftpd rule=ftp

[dbserver]
192.168.3.7

[servers:children]
webserver
dbserver

[webserver:vars]
pkg=mariadb-server
srv=mariadb
rule=mysql
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ vi vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'httpd', u'firewalld', u'vim', u'elinks', u'git'] Package] ****************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing vsftpd Package] *************************************************************
changed: [192.168.3.6]

TASK [Starting vsftpd Service] ***************************************************************
changed: [192.168.3.6]

TASK [Allow ftp in Firewall] *****************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ls
ansible.cfg  hosts  index.html  playbook.yml  var_file.yml  vars.yml
[devops@app1 project]$ mkdir host_vars
[devops@app1 project]$ mkdir group_vars
[devops@app1 project]$ vim group_vars/webserver
[devops@app1 project]$ cat group_vars/webserver
---
pkg:
  - maria-server
  - mariadb

srv: mariadb
rule: mysql
[devops@app1 project]$ vim hosts 
[devops@app1 project]$ sudo yum install -y tree
Failed to set locale, defaulting to C
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
Could not get metalink https://mirrors.fedoraproject.org/metalink?repo=epel-7&arch=x86_64 error was
14: curl#6 - "Could not resolve host: mirrors.fedoraproject.org; Unknown error"
 * base: centos.excellmedia.net
 * epel: epel.mirror.angkasa.id
 * extras: centos.excellmedia.net
 * updates: centos.excellmedia.net
base                                                                   | 3.6 kB  00:00:00     
extras                                                                 | 2.9 kB  00:00:00     
updates                                                                | 2.9 kB  00:00:00     
Resolving Dependencies
--> Running transaction check
---> Package tree.x86_64 0:1.6.0-10.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

==============================================================================================
 Package            Arch                 Version                     Repository          Size
==============================================================================================
Installing:
 tree               x86_64               1.6.0-10.el7                base                46 k

Transaction Summary
==============================================================================================
Install  1 Package

Total download size: 46 k
Installed size: 87 k
Downloading packages:
tree-1.6.0-10.el7.x86_64.rpm                                           |  46 kB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : tree-1.6.0-10.el7.x86_64                                                   1/1 
  Verifying  : tree-1.6.0-10.el7.x86_64                                                   1/1 

Installed:
  tree.x86_64 0:1.6.0-10.el7                                                                  

Complete!
[devops@app1 project]$ tree
.
|-- ansible.cfg
|-- group_vars
|   `-- webserver
|-- hosts
|-- host_vars
|-- index.html
|-- playbook.yml
|-- var_file.yml
`-- vars.yml

2 directories, 7 files
[devops@app1 project]$ ll
total 24
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
-rw-rw-r--. 1 devops devops 180 Feb  4 05:33 hosts
-rw-rw-r--. 1 devops devops 586 Feb  4 05:35 vars.yml
drwxrwxr-x. 2 devops devops   6 Feb  4 06:09 host_vars
drwxrwxr-x. 2 devops devops  23 Feb  4 06:14 group_vars
[devops@app1 project]$ vi group_vars/webserver 
[devops@app1 project]$ cat group_vars/webserver 
---
pkg:
  - mariadb-server
  - mariadb

srv: mariadb
rule: mysql
[devops@app1 project]$ vim hosts 
[devops@app1 project]$ cat hosts 
[webserver]
192.168.3.6

[dbserver]
192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing [u'mariadb-server', u'mariadb'] Package] ************************************
changed: [192.168.3.6]

TASK [Starting mariadb Service] **************************************************************
changed: [192.168.3.6]

TASK [Allow mysql in Firewall] ***************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim host_vars/192.168.3.6
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing mariadb Package] ************************************************************
ok: [192.168.3.6]

TASK [Starting mariadb Service] **************************************************************
ok: [192.168.3.6]

TASK [Allow mysql in Firewall] ***************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ tree
.
|-- ansible.cfg
|-- group_vars
|   `-- webserver
|-- hosts
|-- host_vars
|   `-- 192.168.3.6
|-- index.html
|-- playbook.yml
|-- var_file.yml
`-- vars.yml

2 directories, 8 files
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ #vi hosts 
[devops@app1 project]$ ansible webserver -m yum -a "name=vsftpd state=absent" -u root --ask-pass
SSH password: 
192.168.3.6 | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic).", 
    "unreachable": true
}
[devops@app1 project]$ ^Ci hosts 
[devops@app1 project]$ 
[devops@app1 project]$ ansible webserver -m yum -a "name=vsftpd state=absent" 
192.168.3.6 | CHANGED => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": true, 
    "changes": {
        "removed": [
            "vsftpd"
        ]
    }, 
    "msg": "", 
    "rc": 0, 
    "results": [
        "Loaded plugins: fastestmirror\nResolving Dependencies\n--> Running transaction check\n---> Package vsftpd.x86_64 0:3.0.2-25.el7 will be erased\n--> Finished Dependency Resolution\n\nDependencies Resolved\n\n================================================================================\n Package          Arch             Version                Repository       Size\n================================================================================\nRemoving:\n vsftpd           x86_64           3.0.2-25.el7           @base           353 k\n\nTransaction Summary\n================================================================================\nRemove  1 Package\n\nInstalled size: 353 k\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Erasing    : vsftpd-3.0.2-25.el7.x86_64                                   1/1 \n  Verifying  : vsftpd-3.0.2-25.el7.x86_64                                   1/1 \n\nRemoved:\n  vsftpd.x86_64 0:3.0.2-25.el7                                                  \n\nComplete!\n"
    ]
}
[devops@app1 project]$ ansible dbserver -m setup | less
[devops@app1 project]$ ansible dbserver -m setup | less
[devops@app1 project]$ vmstat
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 2  0  33172  71056      0 116096    0    1    69    16   42   51  1  0 99  0  0
[devops@app1 project]$ ansible dbserver -m setup -a filter=swap
192.168.3.7 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ ansible dbserver -m setup | grep swap
            "swap": {
        "ansible_swapfree_mb": 2024, 
        "ansible_swaptotal_mb": 2047, 
[devops@app1 project]$ ansible dbserver -m setup | less
[devops@app1 project]$ !
[devops@app1 project]$ ansible dbserver -m setup -a filter=ansible_memory_mb
192.168.3.7 | SUCCESS => {
    "ansible_facts": {
        "ansible_memory_mb": {
            "nocache": {
                "free": 101, 
                "used": 134
            }, 
            "real": {
                "free": 5, 
                "total": 235, 
                "used": 230
            }, 
            "swap": {
                "cached": 11, 
                "free": 2024, 
                "total": 2047, 
                "used": 23
            }
        }, 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/facts.yml': line 3, column 8, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name:collecting facts of ansible
  hosts: dbserver
       ^ here

[devops@app1 project]$ ansible-playbook facts.yml
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/facts.yml': line 3, column 8, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

- name:collecting facts of ansible
  hosts: dbserver
       ^ here

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ cat host
cat: host: No such file or directory
[devops@app1 project]$ cat hosts 
[webserver]
192.168.3.6

[dbserver]
192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        var: ansible_facts
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_facts": {
        "_facts_gathered": true, 
        "all_ipv4_addresses": [
            "10.0.2.15", 
            "192.168.3.7"
        ], 
        "all_ipv6_addresses": [
            "fe80::5054:ff:fe8a:fee6", 
            "fe80::a00:27ff:fe14:135f"
        ], 
        "ansible_local": {}, 
        "apparmor": {
            "status": "disabled"
        }, 
        "architecture": "x86_64", 
        "bios_date": "12/01/2006", 
        "bios_version": "VirtualBox", 
        "cmdline": {
            "BOOT_IMAGE": "/boot/vmlinuz-3.10.0-957.12.2.el7.x86_64", 
            "LANG": "en_US.UTF-8", 
            "biosdevname": "0", 
            "console": "ttyS0,115200n8", 
            "crashkernel": "auto", 
            "elevator": "noop", 
            "net.ifnames": "0", 
            "no_timer_check": true, 
            "ro": true, 
            "root": "UUID=8ac075e3-1124-4bb6-bef7-a6811bf8b870"
        }, 
        "date_time": {
            "date": "2020-02-04", 
            "day": "04", 
            "epoch": "1580799993", 
            "hour": "07", 
            "iso8601": "2020-02-04T07:06:33Z", 
            "iso8601_basic": "20200204T070633444334", 
            "iso8601_basic_short": "20200204T070633", 
            "iso8601_micro": "2020-02-04T07:06:33.444458Z", 
            "minute": "06", 
            "month": "02", 
            "second": "33", 
            "time": "07:06:33", 
            "tz": "UTC", 
            "tz_offset": "+0000", 
            "weekday": "Tuesday", 
            "weekday_number": "2", 
            "weeknumber": "05", 
            "year": "2020"
        }, 
        "default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }, 
        "default_ipv6": {}, 
        "device_links": {
            "ids": {
                "sda": [
                    "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6"
                ], 
                "sda1": [
                    "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6-part1"
                ]
            }, 
            "labels": {}, 
            "masters": {}, 
            "uuids": {
                "sda1": [
                    "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
                ]
            }
        }, 
        "devices": {
            "loop0": {
                "holders": [], 
                "host": "", 
                "links": {
                    "ids": [], 
                    "labels": [], 
                    "masters": [], 
                    "uuids": []
                }, 
                "model": null, 
                "partitions": {}, 
                "removable": "0", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "", 
                "sectors": "0", 
                "sectorsize": "512", 
                "size": "0.00 Bytes", 
                "support_discard": "4096", 
                "vendor": null, 
                "virtual": 1
            }, 
            "sda": {
                "holders": [], 
                "host": "IDE interface: Intel Corporation 82371AB/EB/MB PIIX4 IDE (rev 01)", 
                "links": {
                    "ids": [
                        "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6"
                    ], 
                    "labels": [], 
                    "masters": [], 
                    "uuids": []
                }, 
                "model": "VBOX HARDDISK", 
                "partitions": {
                    "sda1": {
                        "holders": [], 
                        "links": {
                            "ids": [
                                "ata-VBOX_HARDDISK_VBfab860fe-f122f1d6-part1"
                            ], 
                            "labels": [], 
                            "masters": [], 
                            "uuids": [
                                "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
                            ]
                        }, 
                        "sectors": "83884032", 
                        "sectorsize": 512, 
                        "size": "40.00 GB", 
                        "start": "2048", 
                        "uuid": "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
                    }
                }, 
                "removable": "0", 
                "rotational": "1", 
                "sas_address": null, 
                "sas_device_handle": null, 
                "scheduler_mode": "noop", 
                "sectors": "83886080", 
                "sectorsize": "512", 
                "serial": "VBfab860fe", 
                "size": "40.00 GB", 
                "support_discard": "0", 
                "vendor": "ATA", 
                "virtual": 1
            }
        }, 
        "discovered_interpreter_python": "/usr/bin/python", 
        "distribution": "CentOS", 
        "distribution_file_parsed": true, 
        "distribution_file_path": "/etc/redhat-release", 
        "distribution_file_variety": "RedHat", 
        "distribution_major_version": "7", 
        "distribution_release": "Core", 
        "distribution_version": "7.7", 
        "dns": {
            "nameservers": [
                "10.0.2.3"
            ], 
            "search": [
                "dev"
            ]
        }, 
        "domain": "dev", 
        "effective_group_id": 0, 
        "effective_user_id": 0, 
        "env": {
            "HOME": "/root", 
            "LANG": "C", 
            "LC_ALL": "C", 
            "LC_CTYPE": "UTF-8", 
            "LC_MESSAGES": "C", 
            "LOGNAME": "root", 
            "LS_COLORS": "rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:", 
            "MAIL": "/var/mail/devops", 
            "PATH": "/sbin:/bin:/usr/sbin:/usr/bin", 
            "PWD": "/home/devops", 
            "SHELL": "/bin/bash", 
            "SHLVL": "1", 
            "SUDO_COMMAND": "/bin/sh -c echo BECOME-SUCCESS-wjderyeodbqdqvmoivfkggfjkokaqatm ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580799991.0-132614975966941/AnsiballZ_setup.py", 
            "SUDO_GID": "1001", 
            "SUDO_UID": "1001", 
            "SUDO_USER": "devops", 
            "TERM": "xterm-256color", 
            "USER": "root", 
            "USERNAME": "root", 
            "XDG_SESSION_ID": "34", 
            "_": "/usr/bin/python"
        }, 
        "eth0": {
            "active": true, 
            "device": "eth0", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "10.0.2.15", 
                "broadcast": "10.0.2.255", 
                "netmask": "255.255.255.0", 
                "network": "10.0.2.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::5054:ff:fe8a:fee6", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "52:54:00:8a:fe:e6", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:03.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "eth1": {
            "active": true, 
            "device": "eth1", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "192.168.3.7", 
                "broadcast": "192.168.3.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.3.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::a00:27ff:fe14:135f", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "08:00:27:14:13:5f", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:08.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "fibre_channel_wwn": [], 
        "fips": false, 
        "form_factor": "Other", 
        "fqdn": "app3.dev", 
        "gather_subset": [
            "all"
        ], 
        "hostname": "app3", 
        "hostnqn": "", 
        "interfaces": [
            "lo", 
            "eth1", 
            "eth0"
        ], 
        "is_chroot": false, 
        "iscsi_iqn": "", 
        "kernel": "3.10.0-957.12.2.el7.x86_64", 
        "kernel_version": "#1 SMP Tue May 14 21:24:32 UTC 2019", 
        "lo": {
            "active": true, 
            "device": "lo", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "on [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "on [fixed]", 
                "netns_local": "on [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off [fixed]", 
                "rx_checksumming": "on [fixed]", 
                "rx_fcs": "off [fixed]", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "off [fixed]", 
                "rx_vlan_offload": "off [fixed]", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on [fixed]", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "on [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "on [fixed]", 
                "tx_nocache_copy": "off [fixed]", 
                "tx_scatter_gather": "on [fixed]", 
                "tx_scatter_gather_fraglist": "on [fixed]", 
                "tx_sctp_segmentation": "on", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "on", 
                "tx_tcp_ecn_segmentation": "on", 
                "tx_tcp_mangleid_segmentation": "on", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "off [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "on", 
                "vlan_challenged": "on [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "127.0.0.1", 
                "broadcast": "host", 
                "netmask": "255.0.0.0", 
                "network": "127.0.0.0"
            }, 
            "ipv6": [
                {
                    "address": "::1", 
                    "prefix": "128", 
                    "scope": "host"
                }
            ], 
            "mtu": 65536, 
            "promisc": false, 
            "timestamping": [
                "rx_software", 
                "software"
            ], 
            "type": "loopback"
        }, 
        "lsb": {}, 
        "machine": "x86_64", 
        "machine_id": "4a3369a823a64378a8ed4fa5e1225aa2", 
        "memfree_mb": 5, 
        "memory_mb": {
            "nocache": {
                "free": 101, 
                "used": 134
            }, 
            "real": {
                "free": 5, 
                "total": 235, 
                "used": 230
            }, 
            "swap": {
                "cached": 11, 
                "free": 2024, 
                "total": 2047, 
                "used": 23
            }
        }, 
        "memtotal_mb": 235, 
        "module_setup": true, 
        "mounts": [
            {
                "block_available": 9506952, 
                "block_size": 4096, 
                "block_total": 10480385, 
                "block_used": 973433, 
                "device": "/dev/sda1", 
                "fstype": "xfs", 
                "inode_available": 20922845, 
                "inode_total": 20971008, 
                "inode_used": 48163, 
                "mount": "/", 
                "options": "rw,seclabel,relatime,attr2,inode64,noquota", 
                "size_available": 38940475392, 
                "size_total": 42927656960, 
                "uuid": "8ac075e3-1124-4bb6-bef7-a6811bf8b870"
            }
        ], 
        "nodename": "app3.dev", 
        "os_family": "RedHat", 
        "pkg_mgr": "yum", 
        "proc_cmdline": {
            "BOOT_IMAGE": "/boot/vmlinuz-3.10.0-957.12.2.el7.x86_64", 
            "LANG": "en_US.UTF-8", 
            "biosdevname": "0", 
            "console": [
                "tty0", 
                "ttyS0,115200n8"
            ], 
            "crashkernel": "auto", 
            "elevator": "noop", 
            "net.ifnames": "0", 
            "no_timer_check": true, 
            "ro": true, 
            "root": "UUID=8ac075e3-1124-4bb6-bef7-a6811bf8b870"
        }, 
        "processor": [
            "0", 
            "GenuineIntel", 
            "Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz"
        ], 
        "processor_cores": 1, 
        "processor_count": 1, 
        "processor_threads_per_core": 1, 
        "processor_vcpus": 1, 
        "product_name": "VirtualBox", 
        "product_serial": "0", 
        "product_uuid": "4A3369A8-23A6-4378-A8ED-4FA5E1225AA2", 
        "product_version": "1.2", 
        "python": {
            "executable": "/usr/bin/python", 
            "has_sslcontext": true, 
            "type": "CPython", 
            "version": {
                "major": 2, 
                "micro": 5, 
                "minor": 7, 
                "releaselevel": "final", 
                "serial": 0
            }, 
            "version_info": [
                2, 
                7, 
                5, 
                "final", 
                0
            ]
        }, 
        "python_version": "2.7.5", 
        "real_group_id": 0, 
        "real_user_id": 0, 
        "selinux": {
            "config_mode": "enforcing", 
            "mode": "enforcing", 
            "policyvers": 31, 
            "status": "enabled", 
            "type": "targeted"
        }, 
        "selinux_python_present": true, 
        "service_mgr": "systemd", 
        "ssh_host_key_ecdsa_public": "AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBOQE9XPbQGYJdSKxBEVsTdN0u7LQ8llahIVxHWtJL+tZacEEkqlFslhB3AUfAeOIPYKwOLwZdZp/uRP6UH81zCs=", 
        "ssh_host_key_ed25519_public": "AAAAC3NzaC1lZDI1NTE5AAAAIANPg/KM4UU4a4m2Fsv0ZJ8GyV+kpukz5wbpfnWOfMqd", 
        "ssh_host_key_rsa_public": "AAAAB3NzaC1yc2EAAAADAQABAAABAQC1pbAglNeLryKsQRpGQobN9j1ee+nt+0INeu7OHcCUl22ar771H4mdhFZl4giVHELiAYVUSPfrZzzi0iH+9B36brNtn9eLS3Ew4VjDYcqrtZEB/x4GDIJe9giL0dhPeKtjlLVe6u+eGCSotZO/Rrr489vb1DIDbzd0XLI18hgz4b9cRUMurczOeIQEPKGW3dmRfoRSQThA6nNzvLTRLBSnVJxhzD5j9oNtaqUARE6Nem4E6ykIcKvxnSMLJ/gTGFoiaXRUAB8hPpNfFaGuoEffznHf5sHQmwPbjWBljL0kJRKIovrYIL97HMesO8vRv/x6xCvFQKuci0ysq0HDI+eJ", 
        "swapfree_mb": 2024, 
        "swaptotal_mb": 2047, 
        "system": "Linux", 
        "system_capabilities": [
            "cap_chown", 
            "cap_dac_override", 
            "cap_dac_read_search", 
            "cap_fowner", 
            "cap_fsetid", 
            "cap_kill", 
            "cap_setgid", 
            "cap_setuid", 
            "cap_setpcap", 
            "cap_linux_immutable", 
            "cap_net_bind_service", 
            "cap_net_broadcast", 
            "cap_net_admin", 
            "cap_net_raw", 
            "cap_ipc_lock", 
            "cap_ipc_owner", 
            "cap_sys_module", 
            "cap_sys_rawio", 
            "cap_sys_chroot", 
            "cap_sys_ptrace", 
            "cap_sys_pacct", 
            "cap_sys_admin", 
            "cap_sys_boot", 
            "cap_sys_nice", 
            "cap_sys_resource", 
            "cap_sys_time", 
            "cap_sys_tty_config", 
            "cap_mknod", 
            "cap_lease", 
            "cap_audit_write", 
            "cap_audit_control", 
            "cap_setfcap", 
            "cap_mac_override", 
            "cap_mac_admin", 
            "cap_syslog", 
            "35", 
            "36+ep"
        ], 
        "system_capabilities_enforced": "True", 
        "system_vendor": "innotek GmbH", 
        "uptime_seconds": 42617, 
        "user_dir": "/root", 
        "user_gecos": "root", 
        "user_gid": 0, 
        "user_id": "root", 
        "user_shell": "/bin/bash", 
        "user_uid": 0, 
        "userspace_architecture": "x86_64", 
        "userspace_bits": "64", 
        "virtualization_role": "guest", 
        "virtualization_type": "virtualbox"
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        var: ansible_facts
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_memory_mb": {
        "nocache": {
            "free": 101, 
            "used": 134
        }, 
        "real": {
            "free": 5, 
            "total": 235, 
            "used": 230
        }, 
        "swap": {
            "cached": 11, 
            "free": 2024, 
            "total": 2047, 
            "used": 23
        }
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        #var: ansible_facts
        var: ansible_memory_mb
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_memory_mb.swap": {
        "cached": 11, 
        "free": 2024, 
        "total": 2047, 
        "used": 23
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        #var: ansible_facts
        var: ansible_memory_mb.swap
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_facts.memory_mb": {
        "nocache": {
            "free": 101, 
            "used": 134
        }, 
        "real": {
            "free": 5, 
            "total": 235, 
            "used": 230
        }, 
        "swap": {
            "cached": 11, 
            "free": 2024, 
            "total": 2047, 
            "used": 23
        }
    }
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat facts.yml
---
- name: collecting facts of ansible
  hosts: dbserver
  tasks: 
    - name: print facts value
      debug:
        #var: ansible_facts
        #var: ansible_memory_mb.swap
        var: ansible_facts.memory_mb
[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
fatal: [192.168.3.7]: FAILED! => {"msg": "Invalid options for debug: var1,var2"}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
fatal: [192.168.3.7]: FAILED! => {"msg": "Invalid options for debug: var2"}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "ansible_facts.hostname": "app3"
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ ansible-playbook facts.yml

PLAY [collecting facts of ansible] ***********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]

TASK [print facts value] *********************************************************************
ok: [192.168.3.7] => {
    "msg": "Hostname = app3 IPADDR = 10.0.2.2"
}

PLAY RECAP ***********************************************************************************
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim facts.yml
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml --syntax-check

playbook: vars.yml
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

TASK [Creating index.html file] **************************************************************
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=5    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ curl http://192.168.3.6/facts.html
Hello from app2 and my IP is 10.0.2.15[devops@app1 project]$ 
[devops@app1 project]$ 
[devops@app1 project]$ ansible webserver -a "cat /var/www/html/facts.html"
192.168.3.6 | CHANGED | rc=0 >>
Hello from app2 and my IP is 10.0.2.15

[devops@app1 project]$ cat vars.yml 
---
- name: Play1
  hosts: webserver
  become: true
  #vars_files:
    #- var_file.yml
  vars:
    pkg: httpd
    srv: httpd
    rule: http
    ## a-z | _ | 0-9 var1 var_1 >> _vars  1var
  tasks:
    - name: Installing {{ pkg }} Package
      yum:
        name: "{{ pkg }}"
        state: latest

    - name: Starting {{ srv }} Service
      service:
        name: "{{ srv }}"
        state: started
        enabled: true

    - name: Allow {{ rule }} in Firewall
      firewalld:
        service: "{{ rule }}"
        state: enabled
        permanent: true
        immediate: true

    - name: Creating index.html file
      copy:
        content: "Hello from {{ ansible_facts.hostname }} and my IP is {{ ansible_default_ipv4.address }}"
        dest: /var/www/html/facts.html
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

TASK [Creating index.html file] **************************************************************
fatal: [192.168.3.6]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'hostname'\n\nThe error appears to be in '/home/devops/project/vars.yml': line 32, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n\n    - name: Creating index.html file\n      ^ here\n"}

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible-playbook vars.yml  --syntax-check

playbook: vars.yml
[devops@app1 project]$ vim vars.yml 
[devops@app1 project]$ ansible-playbook vars.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Installing httpd Package] **************************************************************
ok: [192.168.3.6]

TASK [Starting httpd Service] ****************************************************************
ok: [192.168.3.6]

TASK [Allow http in Firewall] ****************************************************************
ok: [192.168.3.6]

TASK [Creating index.html file] **************************************************************
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=5    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ll
total 28
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
-rw-rw-r--. 1 devops devops  87 Feb  4 06:22 hosts
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ ansible-playbook copy_facts.yml

PLAY [Copy ansible_facts in a file] **********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Saving Facts under /tmp firectory] *****************************************************
fatal: [192.168.3.7]: FAILED! => {"msg": "template error while templating string: no filter named 'to_pretty_json'. String: {{ ansible_facts | to_pretty_json }}"}
fatal: [192.168.3.6]: FAILED! => {"msg": "template error while templating string: no filter named 'to_pretty_json'. String: {{ ansible_facts | to_pretty_json }}"}

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ ansible-playbook copy_facts.yml
[WARNING]: While constructing a mapping from /home/devops/project/copy_facts.yml, line 7,
column 9, found a duplicate dict key (content). Using last defined value only.


PLAY [Copy ansible_facts in a file] **********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Saving Facts under /tmp firectory] *****************************************************
changed: [192.168.3.6 -> localhost]
changed: [192.168.3.7 -> localhost]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi /tmp/
ansible.cfg
app2.json
app3.json
devops
.font-unix/
.ICE-unix/
systemd-private-5aceaa79014746659fc5385d2fe80f4a-chronyd.service-iNQp8q/
systemd-private-ab3ad3ad33b44f9a8ef3fd1adb52de03-chronyd.service-enUMfn/
.Test-unix/
vars.yml
vboxguest-Module.symvers
.X11-unix/
.XIM-unix/
[devops@app1 project]$ vi /tmp/app2.json 
[devops@app1 project]$ vi /tmp/app3.json 
[devops@app1 project]$ vi /tmp/devops 
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ cat copy_facts.yml
---
- name: Copy ansible_facts in a file
  hosts: all
  tasks:
    - name: Saving Facts under /tmp firectory
      copy:
        content: "{{ ansible_facts | to_nice_json }}"
        dest: "/tmp/{{ ansible_hostname }}.json"
      delegate_to: localhost
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ ansible-playbook copy_facts.yml

PLAY [Copy ansible_facts in a file] **********************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [localhost]

TASK [Saving Facts under /tmp firectory] *****************************************************
changed: [localhost -> localhost]

PLAY RECAP ***********************************************************************************
localhost                  : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi /tmp/
ansible.cfg
app1.json
app2.json
app3.json
devops
.font-unix/
.ICE-unix/
systemd-private-5aceaa79014746659fc5385d2fe80f4a-chronyd.service-iNQp8q/
systemd-private-ab3ad3ad33b44f9a8ef3fd1adb52de03-chronyd.service-enUMfn/
.Test-unix/
vars.yml
vboxguest-Module.symvers
.X11-unix/
.XIM-unix/
[devops@app1 project]$ vi /tmp/app1.json 
[devops@app1 project]$ vim copy_facts.yml
[devops@app1 project]$ cat copy_facts.yml
---
- name: Copy ansible_facts in a file
  hosts: all
  ##hosts: localhost
  tasks:
    - name: Saving Facts under /tmp firectory
      copy:
        content: "{{ ansible_facts | to_nice_json }}"
        dest: "/tmp/{{ ansible_hostname }}.json"
      delegate_to: localhost
[devops@app1 project]$ ls -ltr /tmp/app*json
-rw-r--r--. 1 root root 21247 Feb  4 08:55 /tmp/app2.json
-rw-r--r--. 1 root root 21893 Feb  4 08:55 /tmp/app3.json
-rw-r--r--. 1 root root 21285 Feb  4 08:59 /tmp/app1.json
[devops@app1 project]$ vim users.yml
[devops@app1 project]$ ansible-playbook users.yml --syntax-check
ERROR! vars file pass.yml was not found
Could not find file on the Ansible Controller.
If you are using a module and expect the file to exist on the remote, see the remote_src option
[devops@app1 project]$ ansible-playbook users.yml  --syntax-check
ERROR! vars file pass.yml was not found
Could not find file on the Ansible Controller.
If you are using a module and expect the file to exist on the remote, see the remote_src option
[devops@app1 project]$ vim pass.yml
[devops@app1 project]$ cat pass.yml
---
user_pass: AjjuR0ck$
[devops@app1 project]$ cat users.yml 
---
- name: Playbook for User Accounts
  hosts: all
  vars_files:
    - pass.yml
  tasks:
    - name: Adding a User Account
      user: 
        name: ajju
        state: present
        uid: 1010
        shell: /bin/sh
        groups: wheel
        password: "{{ user_pass }}"
[devops@app1 project]$ ansible-playbook users.yml  --syntax-check

playbook: users.yml
[devops@app1 project]$ ansible-vault
usage: ansible-vault [-h] [--version] [-v]
                     {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
                     ...
ansible-vault: error: too few arguments
[devops@app1 project]$ ansible-vault -h
usage: ansible-vault [-h] [--version] [-v]
                     {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
                     ...

encryption/decryption utility for Ansible data files

positional arguments:
  {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
    create              Create new vault encrypted file
    decrypt             Decrypt vault encrypted file
    edit                Edit vault encrypted file
    view                View vault encrypted file
    encrypt             Encrypt YAML file
    encrypt_string      Encrypt a string
    rekey               Re-key a vault encrypted file

optional arguments:
  --version             show program's version number, config file location,
                        configured module search path, module location,
                        executable location and exit
  -h, --help            show this help message and exit
  -v, --verbose         verbose mode (-vvv for more, -vvvv to enable
                        connection debugging)

See 'ansible-vault <command> --help' for more information on a specific
command.
[devops@app1 project]$ ansible-
ansible-2             ansible-console-2.7   ansible-galaxy-2.7    ansible-pull-2
ansible-2.7           ansible-doc           ansible-inventory     ansible-pull-2.7
ansible-config        ansible-doc-2         ansible-playbook      ansible-test
ansible-connection    ansible-doc-2.7       ansible-playbook-2    ansible-vault
ansible-console       ansible-galaxy        ansible-playbook-2.7  ansible-vault-2
ansible-console-2     ansible-galaxy-2      ansible-pull          ansible-vault-2.7
[devops@app1 project]$ ansible-vault encrypt pass.yml 
New Vault password: 
Confirm New Vault password: 
Encryption successful
[devops@app1 project]$ cat pass.yml 
$ANSIBLE_VAULT;1.1;AES256
66636137656235353464336337393137393866393364623434303139326537636363303464653933
6135656338663932386464633765666236626530336530650a303861353830653631376335626163
61326565343033343861643361623232376238376331393831323533623461636663393838326163
3832386438656139360a326466346564623233303232613064313662626263306333633161396465
65306538356137366132646366313465303232303736353935303637316631333238
[devops@app1 project]$ ansible-vault dencrypt pass.yml 
usage: ansible-vault [-h] [--version] [-v]
                     {create,decrypt,edit,view,encrypt,encrypt_string,rekey}
                     ...
ansible-vault: error: argument action: invalid choice: u'dencrypt' (choose from 'create', 'decrypt', 'edit', 'view', 'encrypt', 'encrypt_string', 'rekey')
[devops@app1 project]$ ansible-vault decrypt pass.yml 
Vault password: 
Decryption successful
[devops@app1 project]$ cat pass.yml 
---
user_pass: AjjuR0ck$
[devops@app1 project]$ ansible-vault encrypt pass.yml 
New Vault password: 
Confirm New Vault password: 
Encryption successful
[devops@app1 project]$ ansible-vault view pass.yml 
Vault password: 
---
user_pass: AjjuR0ck$
[devops@app1 project]$ cat pass.yml 
$ANSIBLE_VAULT;1.1;AES256
63616532353035376233316639646161343763663038376139666637323366316131386363633264
3131366461393031623639633865666238336364353136330a353633643037316264356135343734
35363361636465343930373966633361663265663762303238376437323162663264376437343166
3238383837623535650a643935366363623038316237313966666461376463643063633838323430
32396262623036653166663165333138346665303933373731343033343933656337
[devops@app1 project]$ ansible-playbook users.yml 
ERROR! Attempting to decrypt but no vault secrets found
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass --syntax-check
Vault password: 

playbook: users.yml
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass 
Vault password: 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass 
Vault password: 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
[WARNING]: The input password appears not to have been hashed. The 'password' argument must
be encrypted for this module to work properly.

changed: [192.168.3.6]
changed: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 project]$ vim pass.yml 
[devops@app1 project]$ vim users.yml 
[devops@app1 project]$ ansible-playbook users.yml 
ERROR! Attempting to decrypt but no vault secrets found
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass
Vault password: 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
changed: [192.168.3.7]
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat users.yml
---
- name: Playbook for User Accounts
  hosts: all
  vars_files:
    - pass.yml
  tasks:
    - name: Adding a User Account
      user: 
        name: ajju
        state: present
        uid: 1010
        shell: /bin/sh
        groups: wheel
        password: "{{ user_pass | password_hash('sha512') }}"
[devops@app1 project]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 project]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 project]$ exit
logout
[vagrant@app1 ~]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[vagrant@app1 ~]$ vi /etc/ssh/
moduli                    ssh_host_ecdsa_key        ssh_host_ed25519_key.pub
ssh_config                ssh_host_ecdsa_key.pub    ssh_host_rsa_key
sshd_config               ssh_host_ed25519_key      ssh_host_rsa_key.pub
[vagrant@app1 ~]$ vi /etc/ssh/sshd_config 
[vagrant@app1 ~]$ sudo vi /etc/ssh/sshd_config 
[vagrant@app1 ~]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[vagrant@app1 ~]$ sudo vi /etc/ssh/sshd_config 
[vagrant@app1 ~]$ sudo -iu devops
[devops@app1 ~]$ ssh ajju@192.168.3.7
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 ~]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 ~]$ ssh ajju@192.168.3.6
ajju@192.168.3.6's password: 
Permission denied, please try again.
ajju@192.168.3.6's password: 
Last failed login: Tue Feb  4 09:39:30 UTC 2020 from 192.168.3.5 on ssh:notty
There was 1 failed login attempt since the last successful login.
-sh-4.2$ exit
logout
Connection to 192.168.3.6 closed.
[devops@app1 ~]$ ssh ajju@192.168.3.6
Permission denied (publickey,gssapi-keyex,gssapi-with-mic).
[devops@app1 ~]$ vim users.yml
[devops@app1 ~]$ pwd
/home/devops
[devops@app1 ~]$ cd project/
group_vars/ host_vars/  
[devops@app1 ~]$ cd project/
[devops@app1 project]$ ll
total 40
-rw-rw-r--. 1 devops devops 157 Feb  3 10:54 ansible.cfg
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
-rw-rw-r--. 1 devops devops  87 Feb  4 06:22 hosts
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 304 Feb  4 09:26 users.yml
[devops@app1 project]$ vim users.yml
[devops@app1 project]$ ansibe-playbook users.yml
-bash: ansibe-playbook: command not found
[devops@app1 project]$ ansible-playbook users.yml
ERROR! Syntax Error while loading YAML.
  found unexpected end of stream

The error appears to be in '/home/devops/project/users.yml': line 22, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

(specified line no longer in file, maybe it changed?)
[devops@app1 project]$ vim users.yml
[devops@app1 project]$ ansible-playbook users.yml
ERROR! Attempting to decrypt but no vault secrets found
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass
Vault password: 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [SSH Copy Public Key] *******************************************************************
changed: [192.168.3.7]
changed: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=3    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ssh ajju@192.168.3.6
Last login: Tue Feb  4 09:40:16 2020 from 192.168.3.5
-sh-4.2$ whoami
ajju
-sh-4.2$ exit
logout
Connection to 192.168.3.6 closed.
[devops@app1 project]$ ssh ajju@192.168.3.7
-sh-4.2$ whoami
ajju
-sh-4.2$ hostname
app3.dev
-sh-4.2$ exit
logout
Connection to 192.168.3.7 closed.
[devops@app1 project]$ vim .myvaultpassword.txt
[devops@app1 project]$ ansible-playbook users.yml --ask-password-file .myvaultpassword.txt 
usage: ansible-playbook [-h] [--version] [-v] [-k]
                        [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
                        [-c CONNECTION] [-T TIMEOUT]
                        [--ssh-common-args SSH_COMMON_ARGS]
                        [--sftp-extra-args SFTP_EXTRA_ARGS]
                        [--scp-extra-args SCP_EXTRA_ARGS]
                        [--ssh-extra-args SSH_EXTRA_ARGS] [--force-handlers]
                        [--flush-cache] [-b] [--become-method BECOME_METHOD]
                        [--become-user BECOME_USER] [-K] [-t TAGS]
                        [--skip-tags SKIP_TAGS] [-C] [--syntax-check] [-D]
                        [-i INVENTORY] [--list-hosts] [-l SUBSET]
                        [-e EXTRA_VARS] [--vault-id VAULT_IDS]
                        [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
                        [-f FORKS] [-M MODULE_PATH] [--list-tasks]
                        [--list-tags] [--step] [--start-at-task START_AT_TASK]
                        playbook [playbook ...]
ansible-playbook: error: unrecognized arguments: --ask-password-file .myvaultpassword.txt
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ cat .myvaultpassword.txt 
AjjuR0ck$
[devops@app1 project]$ vim .myvaultpassword.txt 
[devops@app1 project]$ cat .myvaultpassword.txt 
AjjuR0ck$
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ cat .myvaultpassword.txt 
AjjuR0ck$
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 
ERROR! Decryption failed (no vault secrets were found that could decrypt) on /home/devops/project/pass.yml
[devops@app1 project]$ ansible-playbook users.yml --ask-vault-pass
Vault password:  [ERROR]: User interrupted execution

[devops@app1 project]$ vim .myvaultpassword.txt 
[devops@app1 project]$ ansible-playbook users.yml --vault-password-file .myvaultpassword.txt 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Adding a User Account] *****************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [SSH Copy Public Key] *******************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat .myvaultpassword.txt 
Acc1234$$
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ vim ansible.cfg 
[devops@app1 project]$ ansible-playbook users.yml 

PLAY [Playbook for User Accounts] ************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]
ok: [192.168.3.7]

TASK [Adding a User Account] *****************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [SSH Copy Public Key] *******************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
192.168.3.7                : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
remote_user=devops
ask_pass=False
vault_password_file=.myvaultpassword.txt

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ vim loops.yml
[devops@app1 project]$ ansible-playbook loops.yml --syntax-check

playbook: loops.yml
[devops@app1 project]$ ansible-playbook loops.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Install rpms] **************************************************************************
changed: [192.168.3.6]

TASK [Starting Service] **********************************************************************
ok: [192.168.3.6] => (item=httpd)
changed: [192.168.3.6] => (item=vsftpd)
ok: [192.168.3.6] => (item=mariadb)

TASK [Adding Users] **************************************************************************
changed: [192.168.3.6] => (item=user1)
changed: [192.168.3.6] => (item=user2)
changed: [192.168.3.6] => (item=user3)

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=3    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim loops.yml
[devops@app1 project]$ ansible-playbook loops.yml 
ERROR! Vars in a Play must be specified as a dictionary, or a list of dictionaries

The error appears to be in '/home/devops/project/loops.yml': line 5, column 5, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  vars:
    - httpd
    ^ here

[devops@app1 project]$ vim loops.yml
[devops@app1 project]$ ansible-playbook loops.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Install rpms] **************************************************************************
ok: [192.168.3.6]

TASK [Starting Service] **********************************************************************
ok: [192.168.3.6] => (item=httpd)
ok: [192.168.3.6] => (item=vsftpd)
ok: [192.168.3.6] => (item=mariadb)

TASK [Adding Users] **************************************************************************
ok: [192.168.3.6] => (item=user1)
ok: [192.168.3.6] => (item=user2)
ok: [192.168.3.6] => (item=user3)

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat loops.yml 
---
- name: Play1
  hosts: webserver
  vars:
    pkg:
    - httpd
    - vsftpd
    - mariadb
  tasks:
    - name: Install rpms
      yum:
        name:
          - elinks
          - git 
          - tree
          - httpd
          - vsftpd
          - mariadb
        state: latest

    - name: Starting Service
      service:
        name: "{{ item }}"
        state: started
      loop: "{{ pkg }}"

    - name: Adding Users
      user:
        name: "{{ item }}"
        state: present
      loop:
        - user1
        - user2
        - user3
[devops@app1 project]$ vim loops.yml 
[devops@app1 project]$ ansible-playbook loops.yml 

PLAY [Play1] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]

TASK [Install rpms] **************************************************************************
ok: [192.168.3.6]

TASK [Starting Service] **********************************************************************
ok: [192.168.3.6] => (item=httpd)
ok: [192.168.3.6] => (item=vsftpd)
ok: [192.168.3.6] => (item=mariadb)

TASK [Adding Users] **************************************************************************
ok: [192.168.3.6] => (item=user1)
ok: [192.168.3.6] => (item=user2)
ok: [192.168.3.6] => (item=user3)

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=4    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat loops.yml 
---
- name: Play1
  hosts: webserver
  vars:
    pkg:
    - httpd
    - vsftpd
    - mariadb
  tasks:
    - name: Install rpms
      yum:
        name:
          - elinks
          - git 
          - tree
          - httpd
          - vsftpd
          - mariadb
        state: latest

    - name: Starting Service
      service:
        name: "{{ item }}"
        state: started
      loop: "{{ pkg }}"

    - name: Adding Users
      user:
        name: "{{ item }}"
        state: present
      with_items:
        - user1
        - user2
        - user3
[devops@app1 project]$ vim play.yml
[devops@app1 project]$ ansible-playbook play.yml --syntax-check
ERROR! Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/home/devops/project/play.yml': line 9, column 4, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

      - Fedora
   tasks:
   ^ here

[devops@app1 project]$ vim play.yml
[devops@app1 project]$ ansible-playbook play.yml --syntax-check
ERROR! Syntax Error while loading YAML.
  did not find expected key

The error appears to be in '/home/devops/project/play.yml': line 9, column 4, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

      - Fedora
   - tasks:
   ^ here

[devops@app1 project]$ vim play.yml
[devops@app1 project]$ ansible-playbook play.yml --syntax-check

playbook: play.yml
[devops@app1 project]$ ansible-playbook play.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is EL] ********************************************************
ok: [192.168.3.6]
changed: [192.168.3.7]

TASK [Install Apache PKG if OS is Ubuntu] ****************************************************
skipping: [192.168.3.6]
skipping: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat play.yml
---
- name: Play2
  hosts: all
  vars:
    supported_distros:
      - CentOS
      - RedHat
      - Fedora

  tasks:
    - name: Install Apache PKG if OS is EL
      yum:
        name: httpd
        state: present
      when: ansible_distribution == "CentOS"

    - name: Install Apache PKG if OS is Ubuntu
      apt:
        name: apache2
        state: present
      when: ansible_distribution == "Ubuntu"
[devops@app1 project]$ mv play.yml [devops@app1 project]$ cat play.yml
mv: target 'play.yml' is not a directory
[devops@app1 project]$ ---
-bash: ---: command not found
[devops@app1 project]$ - name: Play2
-bash: -: command not found
[devops@app1 project]$   hosts: all
-bash: hosts:: command not found
[devops@app1 project]$   vars:
-bash: vars:: command not found
[devops@app1 project]$     supported_distros:
-bash: supported_distros:: command not found
[devops@app1 project]$       - CentOS
-bash: -: command not found
[devops@app1 project]$       - RedHat
-bash: -: command not found
[devops@app1 project]$       - Fedora
-bash: -: command not found
[devops@app1 project]$ 
[devops@app1 project]$   tasks:
-bash: tasks:: command not found
[devops@app1 project]$     - name: Install Apache PKG if OS is EL
-bash: -: command not found
[devops@app1 project]$       yum:
-bash: yum:: command not found
[devops@app1 project]$         name: httpd
-bash: name:: command not found
[devops@app1 project]$         state: present
-bash: state:: command not found
[devops@app1 project]$       when: ansible_distribution == "CentOS"
-bash: when:: command not found
[devops@app1 project]$ 
[devops@app1 project]$     - name: Install Apache PKG if OS is Ubuntu
-bash: -: command not found
[devops@app1 project]$       apt:
-bash: apt:: command not found
[devops@app1 project]$         name: apache2
-bash: name:: command not found
[devops@app1 project]$         state: present
-bash: state:: command not found
[devops@app1 project]$       when: ansible_distribution == "Ubuntu"^C
[devops@app1 project]$ ^C
[devops@app1 project]$ ll
total 48
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
-rw-rw-r--. 1 devops devops  87 Feb  4 06:22 hosts
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops 198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops 557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops 408 Feb  4 10:58 play.yml
[devops@app1 project]$ mv play.yml conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.6]
ok: [192.168.3.7]

TASK [Install Apache PKG if OS is EL] ********************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is Ubuntu] ****************************************************
skipping: [192.168.3.6]
skipping: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is EL] ********************************************************
ok: [192.168.3.7]
ok: [192.168.3.6]

TASK [Install Apache PKG if OS is Ubuntu] ****************************************************
skipping: [192.168.3.6]
skipping: [192.168.3.7]

PLAY RECAP ***********************************************************************************
192.168.3.6                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
192.168.3.7                : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ cat hosts 
[webserver]
node1 ansible_host=192.168.3.6

[dbserver]
node2 ansible_host=192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ ansible node1 -m ping
node1 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ ansible node2 -m ping
node2 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [node2]
ok: [node1]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [node2]
skipping: [node1]

TASK [Installing Database Package] ***********************************************************
skipping: [node1]
skipping: [node2]

PLAY RECAP ***********************************************************************************
node1                      : ok=1    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   
node2                      : ok=1    changed=0    unreachable=0    failed=0    skipped=2    rescued=0    ignored=0   

[devops@app1 project]$ vi hosts 
[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [app3]
ok: [app2]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [app3]
ok: [app2]

TASK [Installing Database Package] ***********************************************************
skipping: [app2]
changed: [app3]

PLAY RECAP ***********************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat hosts 
[webserver]
app2 ansible_host=192.168.3.6

[dbserver]
app3 ansible_host=192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ cat conditions.yml
---
- name: Play2
  hosts: all
  vars:
    supported_distros:
      - CentOS
      - RedHat
      - Fedora

  tasks:
    - name: Install Apache PKG if OS is EL
      yum:
        name: httpd
        state: present
      #when: ansible_distribution == "CentOS"
      #when: ansible_distribution in supported_distros
      when: ansible_hostname in groups['webserver']

    #- name: Install Apache PKG if OS is Ubuntu
    #  apt:
    #    name: apache2
    #    state: present
    #  when: ansible_distribution == "Ubuntu"

    - name: Installing Database Package
      yum:
        name: mariadb-server
        state: latest
      when: ansible_hostname in groups['dbserver']
[devops@app1 project]$ ansible all -m setup -a filter=ansible_hostname
app2 | SUCCESS => {
    "ansible_facts": {
        "ansible_hostname": "app2", 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
app3 | SUCCESS => {
    "ansible_facts": {
        "ansible_hostname": "app3", 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ ansible all -a "hostnamectl"
app3 | CHANGED | rc=0 >>
   Static hostname: app3.dev
         Icon name: computer-vm
           Chassis: vm
        Machine ID: 4a3369a823a64378a8ed4fa5e1225aa2
           Boot ID: 48b1b765568c4a3fad4af05bd9056577
    Virtualization: kvm
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-957.12.2.el7.x86_64
      Architecture: x86-64

app2 | CHANGED | rc=0 >>
   Static hostname: app2.dev
         Icon name: computer-vm
           Chassis: vm
        Machine ID: e6367a4627964527b496be84d8dfee8e
           Boot ID: 60112875e7334263805b5524d2ca597d
    Virtualization: kvm
  Operating System: CentOS Linux 7 (Core)
       CPE OS Name: cpe:/o:centos:centos:7
            Kernel: Linux 3.10.0-957.12.2.el7.x86_64
      Architecture: x86-64

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [app3]
ok: [app2]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [app3]
ok: [app2]

TASK [Installing Database Package] ***********************************************************
skipping: [app2]
ok: [app3]

PLAY RECAP ***********************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ ansible-playbook conditions.yml 

PLAY [Play2] *********************************************************************************

TASK [Gathering Facts] ***********************************************************************
ok: [app2]
ok: [app3]

TASK [Install Apache PKG if OS is EL] ********************************************************
skipping: [app3]
ok: [app2]

TASK [Installing Database Package] ***********************************************************
skipping: [app2]
ok: [app3]

PLAY RECAP ***********************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat conditions.yml
---
- name: Play2
  hosts: all
  vars:
    supported_distros:
      - CentOS
      - RedHat
      - Fedora

  tasks:
    - name: Install Apache PKG if OS is EL
      yum:
        name: httpd
        state: present
      #when: ansible_distribution == "CentOS"
      #when: ansible_distribution in supported_distros
      when: ansible_hostname in groups['webserver'] and ansible_distribution in supported_distros

    #- name: Install Apache PKG if OS is Ubuntu
    #  apt:
    #    name: apache2
    #    state: present
    #  when: ansible_distribution == "Ubuntu"

    - name: Installing Database Package
      yum:
        name: mariadb-server
        state: latest
      when: inventory_hostname in groups['dbserver'] or ansible_distribution == "Ubuntu"
[devops@app1 project]$ vim conditions.yml
[devops@app1 project]$ 
[devops@app1 project]$ vi /etc/ansible/ansible.cfg 
[devops@app1 project]$ ll
total 48
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops 198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops 557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops 123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 836 Feb  4 11:31 conditions.yml
[devops@app1 project]$ ll
total 48
-rw-rw-r--. 1 devops devops  91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops 819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops  83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops  23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops  25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops 357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops 799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops 274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops 419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops 504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops 198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops 557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops 123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 836 Feb  4 11:31 conditions.yml
[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ ll ~/.vim
.viminfo  .vimrc    
[devops@app1 project]$ ll ~/.vimrc 
-rw-rw-r--. 1 devops devops 28 Feb  3 10:29 /home/devops/.vimrc
[devops@app1 project]$ cat ~/.vimrc 
set ai et ts=2 cursorcolumn
[devops@app1 project]$ unset ai et ts=2 cursorcolumn
-bash: unset: `ts=2': not a valid identifier
[devops@app1 project]$ unset ai et 
[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ ansible-playbook conditions.yml 
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/conditions.yml': line 2, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---A
- name: Play2
      ^ here

[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ ansible-playbook conditions.yml 
[WARNING]: While constructing a mapping from /home/devops/project/conditions.yml, line 11, column 7, found a duplicate
dict key (when). Using last defined value only.


PLAY [Play2] **********************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************
ok: [app2]
ok: [app3]

TASK [Install Apache PKG if OS is EL] *********************************************************************************
fatal: [app3]: FAILED! => {"msg": "The conditional check 'ansible_total_mem != 15000' failed. The error was: error while evaluating conditional (ansible_total_mem != 15000): 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/conditions.yml': line 11, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Install Apache PKG if OS is EL\n      ^ here\n"}
fatal: [app2]: FAILED! => {"msg": "The conditional check 'ansible_total_mem != 15000' failed. The error was: error while evaluating conditional (ansible_total_mem != 15000): 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/conditions.yml': line 11, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Install Apache PKG if OS is EL\n      ^ here\n"}

PLAY RECAP ************************************************************************************************************
app2                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
app3                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cp conditions.yml  test.yml
[devops@app1 project]$ vim test.yml 
[devops@app1 project]$ ansible-playbook test.yml 

PLAY [Play2] **********************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************
ok: [app2]
ok: [app3]

TASK [Facts Find | Debug facts] ***************************************************************************************
fatal: [app2]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/test.yml': line 5, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Facts Find | Debug facts\n      ^ here\n"}
fatal: [app3]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'ansible_total_mem' is undefined\n\nThe error appears to be in '/home/devops/project/test.yml': line 5, column 7, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n  tasks:\n    - name: Facts Find | Debug facts\n      ^ here\n"}

PLAY RECAP ************************************************************************************************************
app2                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
app3                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim test.yml 
[devops@app1 project]$ ls -ltr
total 52
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  215 Feb  4 23:32 test.yml
[devops@app1 project]$ vi users.yml 
[devops@app1 project]$ vim conditions.yml 
[devops@app1 project]$ vim test.yml 
[devops@app1 project]$ ansible-playbook test.yml 

PLAY [Play2] **********************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************
ok: [app3]
ok: [app2]

TASK [Facts Find | Debug facts] ***************************************************************************************
ok: [app2] => {
    "msg": [
        "ansible_distribution: CentOS", 
        "ansible_hostname: app2"
    ]
}
ok: [app3] => {
    "msg": [
        "ansible_distribution: CentOS", 
        "ansible_hostname: app3"
    ]
}

PLAY RECAP ************************************************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi conditions.yml 
[devops@app1 project]$ vi users.yml 
[devops@app1 project]$ pwd
/home/devops/project
[devops@app1 project]$ ll
total 52
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check
ERROR! 'var' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/apache.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Play for WebServer
  ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible node2 -m ping
[WARNING]: Could not match supplied host pattern, ignoring: node2

[WARNING]: No hosts matched, nothing to do

[devops@app1 project]$ ansible all -m ping -v
Using /home/devops/project/ansible.cfg as config file
app3 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
app2 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check
ERROR! conflicting action statements: dest, copy

The error appears to be in '/home/devops/project/apache.yml': line 36, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


    - name: Create Documnet root for WebServer
      ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check
ERROR! conflicting action statements: dest, copy

The error appears to be in '/home/devops/project/apache.yml': line 36, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


    - name: Create Document root for WebServer
      ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml --syntax-check

playbook: apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
changed: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
changed: [app2]

TASK [Make config changes] ***************************************************************************
changed: [app2]

RUNNING HANDLER [Restart Apache] *********************************************************************
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=7    changed=4    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat apache.yml
---
- name: Play for WebServer
  hosts: webserver
  become: true
  remote_user: devops
  vars:
    web_pkg: httpd
    fw_pkg: firewalld
    web_srv: httpd
    fw_srv: firewalld
    fw_rule: http

  tasks:
    - name: Install Packages
      yum: 
        name: "{{ item }}"
        state: latest
      loop:
        - "{{ web_pkg }}"
        - "{{ fw_pkg }}"

    - name: Starting Services
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      loop:
        - "{{ web_srv }}"
        - "{{ fw_srv }}"

    - name: allow {{ fw_rule }} in firewalld
      firewalld:
        service: "{{ fw_rule }}"
        state: enabled

    - name: Create Document root for WebServer
      copy: 
        content: "<h1>Hey Azher Khan You are a Rock Star, I am {{ ansible_fqdn }}</h1>"
        dest: /var/www/html/custom.html

    - name: Make config changes
      replace:
        path: /etc/httpd/conf/httpd.conf
        regexp: "index.html"
        replace: "custom.html"
      notify: Restart Apache

  handlers:
    - name: Restart Apache
      service:
        name: "{{ web_srv }}"
        state: restarted


[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

PLAY RECAP *******************************************************************************************
app2                       : ok=7    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=1   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/apache.yml': line 56, column 12, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

    - debug: Output of the Install hello Pkg Task
        var: output
           ^ here

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "output": {
        "changed": false, 
        "failed": true, 
        "msg": "No package matching 'hello' found available, installed or updated", 
        "rc": 126, 
        "results": [
            "No package matching 'hello' found available, installed or updated"
        ]
    }
}

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=1   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [Print the Output message] **********************************************************************
ok: [app2] => {
    "msg": "Setting up a Repo"
}

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=1   

[devops@app1 project]$ vi apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "output": {
        "changed": false, 
        "failed": true, 
        "msg": "No package matching 'hello' found available, installed or updated", 
        "rc": 126, 
        "results": [
            "No package matching 'hello' found available, installed or updated"
        ]
    }
}

TASK [Print the Output message] **********************************************************************
skipping: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=1   

[devops@app1 project]$ cat apache.yml
---
- name: Play for WebServer
  hosts: webserver
  become: true
  remote_user: devops
  vars:
    web_pkg: httpd
    fw_pkg: firewalld
    web_srv: httpd
    fw_srv: firewalld
    fw_rule: http

  tasks:
    - name: Install Packages
      yum: 
        name: "{{ item }}"
        state: latest
      loop:
        - "{{ web_pkg }}"
        - "{{ fw_pkg }}"

    - name: Starting Services
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      loop:
        - "{{ web_srv }}"
        - "{{ fw_srv }}"

    - name: allow {{ fw_rule }} in firewalld
      firewalld:
        service: "{{ fw_rule }}"
        state: enabled

    - name: Create Document root for WebServer
      copy: 
        content: "<h1>Hey Azher Khan You are a Rock Star, I am {{ ansible_fqdn }}</h1>"
        dest: /var/www/html/custom.html

    - name: Make config changes
      replace:
        path: /etc/httpd/conf/httpd.conf
        regexp: "index.html"
        replace: "custom.html"
      notify: Restart Apache

    - name: Install hello Pkg
      yum:
        name: hello
        state: latest
      register: output
      ignore_errors: true

    - debug:
        var: output
      register: output1

    - name: Print the Output message
      debug:
        msg: "Setting up a Repo"
      when: output.failed == true and output1.changed == true

  handlers:
    - name: Restart Apache
      service:
        name: "{{ web_srv }}"
        state: restarted


[devops@app1 project]$ vim apache.yml
[devops@app1 project]$ cat apache.yml
---
- name: Play for WebServer
  hosts: webserver
  become: true
  force_handler: true
  remote_user: devops
  vars:
    web_pkg: httpd
    fw_pkg: firewalld
    web_srv: httpd
    fw_srv: firewalld
    fw_rule: http

  tasks:
    - name: Install Packages
      yum: 
        name: "{{ item }}"
        state: latest
      loop:
        - "{{ web_pkg }}"
        - "{{ fw_pkg }}"

    - name: Starting Services
      service:
        name: "{{ item }}"
        state: started
        enabled: yes
      loop:
        - "{{ web_srv }}"
        - "{{ fw_srv }}"

    - name: allow {{ fw_rule }} in firewalld
      firewalld:
        service: "{{ fw_rule }}"
        state: enabled

    - name: Create Document root for WebServer
      copy: 
        content: "<h1>Hey Azher Khan You are a Rock Star, I am {{ ansible_fqdn }}</h1>"
        dest: /var/www/html/custom.html

    - name: Make config changes
      replace:
        path: /etc/httpd/conf/httpd.conf
        regexp: "index.html"
        replace: "custom.html"
      notify: Restart Apache

    - name: Install hello Pkg
      yum:
        name: hello
        state: latest
      register: output
      ignore_errors: true

    - debug:
        var: output
      register: output1

    - name: Print the Output message
      debug:
        msg: "Setting up a Repo"
      when: output.failed == true and output1.changed == true

  handlers:
    - name: Restart Apache
      service:
        name: "{{ web_srv }}"
        state: restarted


[devops@app1 project]$ ansible-playbook apache.yml 
ERROR! 'force_handler' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/apache.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Play for WebServer
  ^ here

[devops@app1 project]$ vim apache.yml
[devops@app1 project]$ ansible-playbook apache.yml 

PLAY [Play for WebServer] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Install Packages] ******************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [Starting Services] *****************************************************************************
ok: [app2] => (item=httpd)
ok: [app2] => (item=firewalld)

TASK [allow http in firewalld] ***********************************************************************
ok: [app2]

TASK [Create Document root for WebServer] ************************************************************
ok: [app2]

TASK [Make config changes] ***************************************************************************
ok: [app2]

TASK [Install hello Pkg] *****************************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "No package matching 'hello' found available, installed or updated", "rc": 126, "results": ["No package matching 'hello' found available, installed or updated"]}
...ignoring

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "output": {
        "changed": false, 
        "failed": true, 
        "msg": "No package matching 'hello' found available, installed or updated", 
        "rc": 126, 
        "results": [
            "No package matching 'hello' found available, installed or updated"
        ]
    }
}

TASK [Print the Output message] **********************************************************************
skipping: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=1   

[devops@app1 project]$ vi file.yml
[devops@app1 project]$ mv file.yml file.txt
[devops@app1 project]$ #vi file.j2
[devops@app1 project]$ vi file.j2
[devops@app1 project]$ vi network.yml
[devops@app1 project]$ cat network.yml
---
- name: Create J2 Template
  hosts: all
  tasks:
    - name: Generating Template
      template: 
        src: file.j2
        dest: "/tmp/ifcfg-{{ ansible_facts.default_ipv4.interface }}"
[devops@app1 project]$ cat file.j2 
{# This is a Sample template (comments) ifcfg-eth0 #}
DEVICE={{ ansible_facts.default_ipv4.interface }} 
ONBOOT=yes
BOOTPROTO=none
IPADDR={{ ansible_facts.default_ipv4.address }}
NETMASK={{ ansible_facts.default_ipv4.netmask }}
GATEWAY={{ ansible_facts.default_ipv4.gateway }}
DNS1={{ ansible_dns.nameservers[0] }}

[devops@app1 project]$ ansible-playbook network.yml --syntax-check

playbook: network.yml
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ls -ltr
total 68
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  316 Feb  5 06:22 file.j2
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
[devops@app1 project]$ cat file.j2 
{# This is a Sample template (comments) ifcfg-eth0 #}
DEVICE={{ ansible_facts.default_ipv4.interface }} 
ONBOOT=yes
BOOTPROTO=none
IPADDR={{ ansible_facts.default_ipv4.address }}
NETMASK={{ ansible_facts.default_ipv4.netmask }}
GATEWAY={{ ansible_facts.default_ipv4.gateway }}
DNS1={{ ansible_dns.nameservers[0] }}

[devops@app1 project]$ cat network.yml 
---
- name: Create J2 Template
  hosts: all
  tasks:
    - name: Generating Template
      template: 
        src: file.j2
        dest: "/tmp/ifcfg-{{ ansible_facts.default_ipv4.interface }}"
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
ok: [app3]
ok: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg*"
app3 | FAILED | rc=1 >>
cat: /tmp/ifcfg*: No such file or directorynon-zero return code

app2 | FAILED | rc=1 >>
cat: /tmp/ifcfg*: No such file or directorynon-zero return code

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg-eth0"
app3 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

app2 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

[devops@app1 project]$ vi file.j2 
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg-eth0"
app3 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
#IPADDR=10.0.2.15
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

app2 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
#IPADDR=10.0.2.15
IPADDR=10.0.2.15
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

[devops@app1 project]$ 

[devops@app1 project]$ vi file.j2 
[devops@app1 project]$ ansible-playbook network.yml 

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Generating Template] ***************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible all -a "cat /tmp/ifcfg-eth0"
app3 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR1=10.0.2.15
IPADDR2=192.168.3.7
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

app2 | CHANGED | rc=0 >>
DEVICE=eth0 
ONBOOT=yes
BOOTPROTO=none
IPADDR1=10.0.2.15
IPADDR2=192.168.3.6
NETMASK=255.255.255.0
GATEWAY=10.0.2.2
DNS1=10.0.2.3

[devops@app1 project]$ cat file.j2 
{# This is a Sample template (comments) ifcfg-eth0 #}
DEVICE={{ ansible_facts.default_ipv4.interface }} 
ONBOOT=yes
BOOTPROTO=none
IPADDR1={{ ansible_facts.default_ipv4.address }}
IPADDR2={{ ansible_facts.all_ipv4_addresses[1] }}
NETMASK={{ ansible_facts.default_ipv4.netmask }}
GATEWAY={{ ansible_facts.default_ipv4.gateway }}
DNS1={{ ansible_dns.nameservers[0] }}

[devops@app1 project]$ ansible all -a "{{ ansible_facts.all_ipv4_addresses[1] }}"
app2 | FAILED | rc=-1 >>
The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'

app3 | FAILED | rc=-1 >>
The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'

[devops@app1 project]$ ansible all "{{ ansible_facts.all_ipv4_addresses[1] }}"
usage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD]
               [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts]
               [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k]
               [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
               [-c CONNECTION] [-T TIMEOUT]
               [--ssh-common-args SSH_COMMON_ARGS]
               [--sftp-extra-args SFTP_EXTRA_ARGS]
               [--scp-extra-args SCP_EXTRA_ARGS]
               [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D]
               [-e EXTRA_VARS] [--vault-id VAULT_IDS]
               [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
               [-f FORKS] [-M MODULE_PATH] [--playbook-dir BASEDIR]
               [-a MODULE_ARGS] [-m MODULE_NAME]
               pattern
ansible: error: unrecognized arguments: {{ ansible_facts.all_ipv4_addresses[1] }}
[devops@app1 project]$ ansible all -m setup -a "{{ ansible_facts.all_ipv4_addresses[1] }}"
app2 | FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'"
}
app3 | FAILED! => {
    "msg": "The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'all_ipv4_addresses'"
}
[devops@app1 project]$ ansible all -m setup -a "*ipv4*"
ERROR! this task 'setup' has extra params, which is only allowed in the following modules: shell, win_shell, include_vars, add_host, raw, include_role, meta, set_fact, include, import_tasks, script, import_role, include_tasks, group_by, command, win_command
[devops@app1 project]$ ansible localhost -m setup -a "*ipv4*"
ERROR! this task 'setup' has extra params, which is only allowed in the following modules: shell, win_shell, include_vars, add_host, raw, include_role, meta, set_fact, include, import_tasks, script, import_role, include_tasks, group_by, command, win_command
[devops@app1 project]$ ansible localhost -m setup -a "filter=*ipv4*"
localhost | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "192.168.3.5", 
            "10.0.2.15"
        ], 
        "ansible_default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }
    }, 
    "changed": false
}
[devops@app1 project]$ ansible all -m setup -a "filter=*ipv4*"
app3 | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "10.0.2.15", 
            "192.168.3.7"
        ], 
        "ansible_default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }, 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
app2 | SUCCESS => {
    "ansible_facts": {
        "ansible_all_ipv4_addresses": [
            "10.0.2.15", 
            "192.168.3.6"
        ], 
        "ansible_default_ipv4": {
            "address": "10.0.2.15", 
            "alias": "eth0", 
            "broadcast": "10.0.2.255", 
            "gateway": "10.0.2.2", 
            "interface": "eth0", 
            "macaddress": "52:54:00:8a:fe:e6", 
            "mtu": 1500, 
            "netmask": "255.255.255.0", 
            "network": "10.0.2.0", 
            "type": "ether"
        }, 
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false
}
[devops@app1 project]$ ansible localhost -m setup -a 'filter=ansible_eth*'
localhost | SUCCESS => {
    "ansible_facts": {
        "ansible_eth0": {
            "active": true, 
            "device": "eth0", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "10.0.2.15", 
                "broadcast": "10.0.2.255", 
                "netmask": "255.255.255.0", 
                "network": "10.0.2.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::5054:ff:fe8a:fee6", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "52:54:00:8a:fe:e6", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:03.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }, 
        "ansible_eth1": {
            "active": true, 
            "device": "eth1", 
            "features": {
                "busy_poll": "off [fixed]", 
                "fcoe_mtu": "off [fixed]", 
                "generic_receive_offload": "on", 
                "generic_segmentation_offload": "on", 
                "highdma": "off [fixed]", 
                "hw_tc_offload": "off [fixed]", 
                "l2_fwd_offload": "off [fixed]", 
                "large_receive_offload": "off [fixed]", 
                "loopback": "off [fixed]", 
                "netns_local": "off [fixed]", 
                "ntuple_filters": "off [fixed]", 
                "receive_hashing": "off [fixed]", 
                "rx_all": "off", 
                "rx_checksumming": "off", 
                "rx_fcs": "off", 
                "rx_gro_hw": "off [fixed]", 
                "rx_udp_tunnel_port_offload": "off [fixed]", 
                "rx_vlan_filter": "on [fixed]", 
                "rx_vlan_offload": "on", 
                "rx_vlan_stag_filter": "off [fixed]", 
                "rx_vlan_stag_hw_parse": "off [fixed]", 
                "scatter_gather": "on", 
                "tcp_segmentation_offload": "on", 
                "tx_checksum_fcoe_crc": "off [fixed]", 
                "tx_checksum_ip_generic": "on", 
                "tx_checksum_ipv4": "off [fixed]", 
                "tx_checksum_ipv6": "off [fixed]", 
                "tx_checksum_sctp": "off [fixed]", 
                "tx_checksumming": "on", 
                "tx_fcoe_segmentation": "off [fixed]", 
                "tx_gre_csum_segmentation": "off [fixed]", 
                "tx_gre_segmentation": "off [fixed]", 
                "tx_gso_partial": "off [fixed]", 
                "tx_gso_robust": "off [fixed]", 
                "tx_ipip_segmentation": "off [fixed]", 
                "tx_lockless": "off [fixed]", 
                "tx_nocache_copy": "off", 
                "tx_scatter_gather": "on", 
                "tx_scatter_gather_fraglist": "off [fixed]", 
                "tx_sctp_segmentation": "off [fixed]", 
                "tx_sit_segmentation": "off [fixed]", 
                "tx_tcp6_segmentation": "off [fixed]", 
                "tx_tcp_ecn_segmentation": "off [fixed]", 
                "tx_tcp_mangleid_segmentation": "off", 
                "tx_tcp_segmentation": "on", 
                "tx_udp_tnl_csum_segmentation": "off [fixed]", 
                "tx_udp_tnl_segmentation": "off [fixed]", 
                "tx_vlan_offload": "on [fixed]", 
                "tx_vlan_stag_hw_insert": "off [fixed]", 
                "udp_fragmentation_offload": "off [fixed]", 
                "vlan_challenged": "off [fixed]"
            }, 
            "hw_timestamp_filters": [], 
            "ipv4": {
                "address": "192.168.3.5", 
                "broadcast": "192.168.3.255", 
                "netmask": "255.255.255.0", 
                "network": "192.168.3.0"
            }, 
            "ipv6": [
                {
                    "address": "fe80::a00:27ff:fe7f:509", 
                    "prefix": "64", 
                    "scope": "link"
                }
            ], 
            "macaddress": "08:00:27:7f:05:09", 
            "module": "e1000", 
            "mtu": 1500, 
            "pciid": "0000:00:08.0", 
            "promisc": false, 
            "speed": 1000, 
            "timestamping": [
                "tx_software", 
                "rx_software", 
                "software"
            ], 
            "type": "ether"
        }
    }, 
    "changed": false
}
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}
ok: [app3] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}

PLAY RECAP *******************************************************************************************
app2                       : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat static.yml
---
- name: Playbook to display Static Module Manipulation
  hosts: all
  tasks:
    - name: Verify the Directory exists
      stat:
        path: /tmp/files
      register: var1

    - debug:
        var: var1
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}
ok: [app3] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "exists": false
        }
    }
}

TASK [Creating a Directory] **************************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=4    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "atime": 1580885757.3520622, 
            "attr_flags": "", 
            "attributes": [], 
            "block_size": 4096, 
            "blocks": 0, 
            "charset": "binary", 
            "ctime": 1580885757.3520622, 
            "dev": 2049, 
            "device_type": 0, 
            "executable": true, 
            "exists": true, 
            "gid": 1001, 
            "gr_name": "devops", 
            "inode": 100817496, 
            "isblk": false, 
            "ischr": false, 
            "isdir": true, 
            "isfifo": false, 
            "isgid": false, 
            "islnk": false, 
            "isreg": false, 
            "issock": false, 
            "isuid": false, 
            "mimetype": "inode/directory", 
            "mode": "0775", 
            "mtime": 1580885757.3520622, 
            "nlink": 2, 
            "path": "/tmp/files", 
            "pw_name": "devops", 
            "readable": true, 
            "rgrp": true, 
            "roth": true, 
            "rusr": true, 
            "size": 6, 
            "uid": 1001, 
            "version": "1696186859", 
            "wgrp": true, 
            "woth": false, 
            "writeable": true, 
            "wusr": true, 
            "xgrp": true, 
            "xoth": true, 
            "xusr": true
        }
    }
}
ok: [app3] => {
    "var1": {
        "changed": false, 
        "failed": false, 
        "stat": {
            "atime": 1580885757.3034186, 
            "attr_flags": "", 
            "attributes": [], 
            "block_size": 4096, 
            "blocks": 0, 
            "charset": "binary", 
            "ctime": 1580885757.3034186, 
            "dev": 2049, 
            "device_type": 0, 
            "executable": true, 
            "exists": true, 
            "gid": 1001, 
            "gr_name": "devops", 
            "inode": 4796004, 
            "isblk": false, 
            "ischr": false, 
            "isdir": true, 
            "isfifo": false, 
            "isgid": false, 
            "islnk": false, 
            "isreg": false, 
            "issock": false, 
            "isuid": false, 
            "mimetype": "inode/directory", 
            "mode": "0775", 
            "mtime": 1580885757.3034186, 
            "nlink": 2, 
            "path": "/tmp/files", 
            "pw_name": "devops", 
            "readable": true, 
            "rgrp": true, 
            "roth": true, 
            "rusr": true, 
            "size": 6, 
            "uid": 1001, 
            "version": "18446744073082428293", 
            "wgrp": true, 
            "woth": false, 
            "writeable": true, 
            "wusr": true, 
            "xgrp": true, 
            "xoth": true, 
            "xusr": true
        }
    }
}

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
ok: [app3]
ok: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
changed: [app2]
changed: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=4    changed=1    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml --syntax-check

playbook: static.yml
[devops@app1 project]$ vim static.yml
[devops@app1 project]$ ansible-playbook static.yml --syntax-check

playbook: static.yml
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
ok: [app3]
ok: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
fatal: [app3]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app3 does not exist !", "rc": 257}
fatal: [app2]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app2 does not exist !", "rc": 257}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=2    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
app3                       : ok=6    changed=2    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app2]
changed: [app3]

TASK [Adding a Set of Lines in the file] *************************************************************
fatal: [app3]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app3 does not exist !", "rc": 257}
fatal: [app2]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app2 does not exist !", "rc": 257}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
app3                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app2 does not exist !", "rc": 257}
fatal: [app3]: FAILED! => {"changed": false, "msg": "Path /tmp/files/app3 does not exist !", "rc": 257}

PLAY RECAP *******************************************************************************************
app2                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   
app3                       : ok=6    changed=3    unreachable=0    failed=1    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app2]
ok: [app3]

TASK [Creating a Directory] **************************************************************************
skipping: [app3]
skipping: [app2]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app3]
changed: [app2]

TASK [Add a line Before a regex] *********************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=8    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app3]
skipping: [app2]

TASK [Creating file using copy module] ***************************************************************
changed: [app2]
changed: [app3]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app3]
changed: [app2]

TASK [Add a line Before a regex] *********************************************************************
changed: [app3]
changed: [app2]

TASK [Copy files from managed nodes] *****************************************************************
changed: [app3]
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=9    changed=6    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=9    changed=6    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ ll
total 80
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops 1830 Feb  5 07:26 static.yml
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
[devops@app1 project]$ cat app2.txt 
Sample file using the MOVED Module in 192.168.3.6 instance 
This is the Second Line in the file using LINEINFILE module
# BEGIN ANSIBLE MANAGED BLOCK
Using the Block Module and as you can see this is the First line
Hehehe Added more content
I know i need to stop now but this is the third line
# END ANSIBLE MANAGED BLOCK
[devops@app1 project]$ cat app3.txt 
Sample file using the MOVED Module in 192.168.3.7 instance 
This is the Second Line in the file using LINEINFILE module
# BEGIN ANSIBLE MANAGED BLOCK
Using the Block Module and as you can see this is the First line
Hehehe Added more content
I know i need to stop now but this is the third line
# END ANSIBLE MANAGED BLOCK
[devops@app1 project]$ date
Wed Feb  5 07:27:36 UTC 2020
[devops@app1 project]$ cat static.yml 
---
- name: Playbook to display Static Module Manipulation
  hosts: all
  tasks:
    - name: Verify the Directory exists
      stat:
        path: /tmp/files
      register: var1

    #- debug:
    #    var: var1

    - name: Creating a Directory
      file:
        path: /tmp/files
        state: directory
        owner: devops
        group: devops
        mode: 0775
      when: var1.stat.exists == false

    - name: Creating file using copy module
      copy:
        content: "Sample file using the Copy Module in {{ ansible_facts.all_ipv4_addresses[1] }} instance "
        dest: "/tmp/files/{{ ansible_hostname }}.txt"

    - name : Copy file from controller to manage nodes
      copy:
        src: index.html
        dest: /tmp/files/

    - name: Replace the content of existing file
      replace:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        regexp: "Copy"
        replace: "MOVED"

    - name: Appending a New line in the existing file
      lineinfile:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        line: "This is the Second Line in the file using LINEINFILE module"

    - name: Adding a Set of Lines in the file
      blockinfile:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        block: |
          Using the Block Module and as you can see this is the First line
          Yep this is the second line like you didnt know
          I know i need to stop now but this is the third line
        
    - name: Add a line Before a regex
      lineinfile:
        path: "/tmp/files/{{ ansible_hostname }}.txt"
        regexp: "^Yep"
        insertbefore: "^second"
        line: "Hehehe Added more content"

    - name: Copy files from managed nodes
      fetch:
        src: "/tmp/files/{{ ansible_hostname }}.txt"
        dest: /home/devops/project/
        flat: true
[devops@app1 project]$ ls -ltr
total 80
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops 1830 Feb  5 07:26 static.yml
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
[devops@app1 project]$ 
[devops@app1 project]$ 
[devops@app1 project]$ vi host
[devops@app1 project]$ vi hosts 
[devops@app1 project]$ ansible webserver --list-hosts -i inventory
[WARNING]: Unable to parse /home/devops/project/inventory as an inventory source

[WARNING]: No inventory was parsed, only implicit localhost is available

[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'

[WARNING]: Could not match supplied host pattern, ignoring: webserver

  hosts (0):
[devops@app1 project]$ ansible dbserver --list-hosts -i inventory
[WARNING]: Unable to parse /home/devops/project/inventory as an inventory source

[WARNING]: No inventory was parsed, only implicit localhost is available

[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'

[WARNING]: Could not match supplied host pattern, ignoring: dbserver

  hosts (0):
[devops@app1 project]$ cat host
cat: host: No such file or directory
[devops@app1 project]$ cat hosts
[webserver]
app2 ansible_host=192.168.3.6

[dbserver]
app3 ansible_host=192.168.3.7

[servers:children]
webserver
dbserver
[devops@app1 project]$ ansible all --list-hosts -i inventory
[WARNING]: Unable to parse /home/devops/project/inventory as an inventory source

[WARNING]: No inventory was parsed, only implicit localhost is available

[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'

  hosts (0):
[devops@app1 project]$ vi inventory
[devops@app1 project]$ ansible all --list-hosts -i inventory
  hosts (15):
    node1.example.com
    node2.example.com
    node3.example.com
    node4.example.com
    node5.example.com
    node6.example.com
    node7.example.com
    node8.example.com
    node9.example.com
    172.19.2.100
    172.19.2.101
    172.19.2.102
    172.19.2.103
    172.19.2.104
    172.19.2.105
[devops@app1 project]$ ansible ip --list-hosts -i inventory
  hosts (6):
    172.19.2.100
    172.19.2.101
    172.19.2.102
    172.19.2.103
    172.19.2.104
    172.19.2.105
[devops@app1 project]$ vi inventory
[devops@app1 project]$ ansible ungroup --list-hosts -i inventory
[WARNING]: Could not match supplied host pattern, ignoring: ungroup

[WARNING]: No hosts matched, nothing to do

  hosts (0):
[devops@app1 project]$ ansible ungrouped --list-hosts -i inventory
  hosts (2):
    server1
    server2
[devops@app1 project]$ cat in
cat: in: No such file or directory
[devops@app1 project]$ cat inventory 
server1
server2
[web]
node1.example.com
node2.example.com
node3.example.com
node4.example.com

[db]
node[5:9].example.com

[ip]
172.19.2.[100:105]
[devops@app1 project]$ vi inventory 
[devops@app1 project]$ ansible ip --list-hosts -i inventory
  hosts (24):
    172.19.2.100
    172.19.2.101
    172.19.2.102
    172.19.2.103
    172.19.2.104
    172.19.2.105
    172.19.1.20
    172.19.1.21
    172.19.1.22
    172.19.1.23
    172.19.1.24
    172.19.1.25
    172.19.2.20
    172.19.2.21
    172.19.2.22
    172.19.2.23
    172.19.2.24
    172.19.2.25
    172.19.3.20
    172.19.3.21
    172.19.3.22
    172.19.3.23
    172.19.3.24
    172.19.3.25
[devops@app1 project]$ ansible * --list-hosts -i inventory
usage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD]
               [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts]
               [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k]
               [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
               [-c CONNECTION] [-T TIMEOUT]
               [--ssh-common-args SSH_COMMON_ARGS]
               [--sftp-extra-args SFTP_EXTRA_ARGS]
               [--scp-extra-args SCP_EXTRA_ARGS]
               [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D]
               [-e EXTRA_VARS] [--vault-id VAULT_IDS]
               [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
               [-f FORKS] [-M MODULE_PATH] [--playbook-dir BASEDIR]
               [-a MODULE_ARGS] [-m MODULE_NAME]
               pattern
ansible: error: unrecognized arguments: apache.yml app2.txt app3.txt conditions.yml copy_facts.yml facts.yml file.j2 file.txt group_vars hosts host_vars index.html inventory loops.yml network.yml pass.yml playbook.yml static.yml test.yml users.yml var_file.yml vars.yml
[devops@app1 project]$ ansible "*" --list-hosts -i inventory
  hosts (35):
    server1
    server2
    node1.example.com
    node2.example.com
    node3.example.com
    node4.example.com
    node5.example.com
    node6.example.com
    node7.example.com
    node8.example.com
    node9.example.com
    172.19.2.100
    172.19.2.101
    172.19.2.102
    172.19.2.103
    172.19.2.104
    172.19.2.105
    172.19.1.20
    172.19.1.21
    172.19.1.22
    172.19.1.23
    172.19.1.24
    172.19.1.25
    172.19.2.20
    172.19.2.21
    172.19.2.22
    172.19.2.23
    172.19.2.24
    172.19.2.25
    172.19.3.20
    172.19.3.21
    172.19.3.22
    172.19.3.23
    172.19.3.24
    172.19.3.25
[devops@app1 project]$ ansible "node*" --list-hosts -i inventory
  hosts (9):
    node9.example.com
    node3.example.com
    node5.example.com
    node4.example.com
    node1.example.com
    node8.example.com
    node7.example.com
    node6.example.com
    node2.example.com
[devops@app1 project]$ vi inventory 
[devops@app1 project]$ ansible "node*" --list-hosts -i inventory
  hosts (33):
    node1.example.com
    node2.example.com
    node3.example.com
    node4.example.com
    node5.example.com
    node6.example.com
    node7.example.com
    node8.example.com
    node9.example.com
    172.19.2.100
    172.19.2.101
    172.19.2.102
    172.19.2.103
    172.19.2.104
    172.19.2.105
    172.19.1.20
    172.19.1.21
    172.19.1.22
    172.19.1.23
    172.19.1.24
    172.19.1.25
    172.19.2.20
    172.19.2.21
    172.19.2.22
    172.19.2.23
    172.19.2.24
    172.19.2.25
    172.19.3.20
    172.19.3.21
    172.19.3.22
    172.19.3.23
    172.19.3.24
    172.19.3.25
[devops@app1 project]$ ansible 'web,!node1.example.com' --list-hosts -i inventory
  hosts (3):
    node2.example.com
    node3.example.com
    node4.example.com
[devops@app1 project]$ ansible 'web,&db' --list-hosts -i inventory
[WARNING]: No hosts matched, nothing to do

  hosts (0):
[devops@app1 project]$ vi inventory 
[devops@app1 project]$ ansible 'web,&db' --list-hosts -i inventory
  hosts (1):
    node2.example.com
[devops@app1 project]$ ansible 'web,&db' --list-hosts
[WARNING]: Could not match supplied host pattern, ignoring: web

[WARNING]: Could not match supplied host pattern, ignoring: db

[WARNING]: No hosts matched, nothing to do

  hosts (0):
[devops@app1 project]$ vi /etc/ansible/ansible.cfg 
[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ ll /etc/ansible/
total 24
drwxr-xr-x. 2 root root     6 Dec  8 20:42 roles
-rw-r--r--. 1 root root 19985 Dec  8 20:42 ansible.cfg
-rw-r--r--. 1 root root  1040 Feb  3 07:37 hosts
[devops@app1 project]$ cat /etc/ansible/hosts 
# This is the default ansible 'hosts' file.
#
# It should live in /etc/ansible/hosts
#
#   - Comments begin with the '#' character
#   - Blank lines are ignored
#   - Groups of hosts are delimited by [header] elements
#   - You can enter hostnames or ip addresses
#   - A hostname/ip can be a member of multiple groups

# Ex 1: Ungrouped hosts, specify before any group headers.

## green.example.com
## blue.example.com
## 192.168.100.1
## 192.168.100.10

# Ex 2: A collection of hosts belonging to the 'webservers' group

## [webservers]
## alpha.example.org
## beta.example.org
## 192.168.1.100
## 192.168.1.110

# If you have multiple hosts following a pattern you can specify
# them like this:

## www[001:006].example.com

# Ex 3: A collection of database servers in the 'dbservers' group

## [dbservers]
## 
## db01.intranet.mydomain.net
## db02.intranet.mydomain.net
## 10.25.1.56
## 10.25.1.57

# Here's another example of host ranges, this time there are no
# leading 0s:

## db-[99:101]-node.example.com

192.168.3.6
192.168.3.7
[devops@app1 project]$ ll
total 84
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops 1830 Feb  5 07:26 static.yml
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
-rw-rw-r--. 1 devops devops  215 Feb  5 08:55 inventory
[devops@app1 project]$ ansible-inventory --list -i hosts
{
    "_meta": {
        "hostvars": {
            "app2": {
                "ansible_host": "192.168.3.6", 
                "pkg": [
                    "mariadb-server", 
                    "mariadb"
                ], 
                "rule": "mysql", 
                "srv": "mariadb"
            }, 
            "app3": {
                "ansible_host": "192.168.3.7"
            }
        }
    }, 
    "all": {
        "children": [
            "servers", 
            "ungrouped"
        ]
    }, 
    "dbserver": {
        "hosts": [
            "app3"
        ]
    }, 
    "servers": {
        "children": [
            "dbserver", 
            "webserver"
        ]
    }, 
    "webserver": {
        "hosts": [
            "app2"
        ]
    }
}
[devops@app1 project]$ ansible-inventory --hosts node1
usage: ansible-inventory [-h] [--version] [-v] [-i INVENTORY]
                         [--vault-id VAULT_IDS]
                         [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
                         [--playbook-dir BASEDIR] [--list] [--host HOST]
                         [--graph] [-y] [--toml] [--vars] [--export]
                         [--output OUTPUT_FILE]
                         [host|group]
ansible-inventory: error: unrecognized arguments: --hosts
[devops@app1 project]$ ansible-inventory --host node1
[WARNING]: Could not match supplied host pattern, ignoring: node1

usage: ansible-inventory [-h] [--version] [-v] [-i INVENTORY]
                         [--vault-id VAULT_IDS]
                         [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
                         [--playbook-dir BASEDIR] [--list] [--host HOST]
                         [--graph] [-y] [--toml] [--vars] [--export]
                         [--output OUTPUT_FILE]
                         [host|group]

positional arguments:
  host|group

optional arguments:
  --ask-vault-pass      ask for vault password
  --export              When doing an --list, represent in a way that is
                        optimized for export,not as an accurate representation
                        of how Ansible has processed it
  --output OUTPUT_FILE  When doing --list, send the inventory to a file
                        instead of to the screen
  --playbook-dir BASEDIR
                        Since this tool does not use playbooks, use this as a
                        substitute playbook directory.This sets the relative
                        path for many features including roles/ group_vars/
                        etc.
  --toml                Use TOML format instead of default JSON, ignored for
                        --graph
  --vars                Add vars to graph display, ignored unless used with
                        --graph
  --vault-id VAULT_IDS  the vault identity to use
  --vault-password-file VAULT_PASSWORD_FILES
                        vault password file
  --version             show program's version number, config file location,
                        configured module search path, module location,
                        executable location and exit
  -h, --help            show this help message and exit
  -i INVENTORY, --inventory INVENTORY, --inventory-file INVENTORY
                        specify inventory host path or comma separated host
                        list. --inventory-file is deprecated
  -v, --verbose         verbose mode (-vvv for more, -vvvv to enable
                        connection debugging)
  -y, --yaml            Use YAML format instead of default JSON, ignored for
                        --graph

Actions:
  One of following must be used on invocation, ONLY ONE!

  --graph               create inventory graph, if supplying pattern it must
                        be a valid group name
  --host HOST           Output specific host info, works as inventory script
  --list                Output all hosts info, works as inventory script

Show Ansible inventory information, by default it uses the inventory script
JSON format
ERROR! You must pass a single valid host to --host parameter
[devops@app1 project]$ ansible-inventory --host app2
{
    "ansible_host": "192.168.3.6", 
    "pkg": [
        "mariadb-server", 
        "mariadb"
    ], 
    "rule": "mysql", 
    "srv": "mariadb"
}
[devops@app1 project]$ ll
total 84
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  198 Feb  4 10:00 ansible.cfg
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops 1830 Feb  5 07:26 static.yml
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
-rw-rw-r--. 1 devops devops  215 Feb  5 08:55 inventory
[devops@app1 project]$ mkdir dynamic
[devops@app1 project]$ cd dynamic
[devops@app1 dynamic]$ wget https://raw.githubusercontent.com/ansible/ansible/devel/contrib/inventory/ec2.py
-bash: wget: command not found
[devops@app1 dynamic]$ sudo yum install wget
Failed to set locale, defaulting to C
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
epel/x86_64/metalink                                                           | 7.2 kB  00:00:00     
 * base: centos.excellmedia.net
 * epel: mirrors.piconets.webwerks.in
 * extras: centos.excellmedia.net
 * updates: centos.excellmedia.net
base                                                                           | 3.6 kB  00:00:00     
epel                                                                           | 5.3 kB  00:00:00     
extras                                                                         | 2.9 kB  00:00:00     
updates                                                                        | 2.9 kB  00:00:00     
(1/2): epel/x86_64/updateinfo                                                  | 1.0 MB  00:00:01     
(2/2): epel/x86_64/primary_db                                                  | 6.9 MB  00:00:02     
Resolving Dependencies
--> Running transaction check
---> Package wget.x86_64 0:1.14-18.el7_6.1 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

======================================================================================================
 Package             Arch                  Version                          Repository           Size
======================================================================================================
Installing:
 wget                x86_64                1.14-18.el7_6.1                  base                547 k

Transaction Summary
======================================================================================================
Install  1 Package

Total download size: 547 k
Installed size: 2.0 M
Is this ok [y/d/N]: y
Downloading packages:
wget-1.14-18.el7_6.1.x86_64.rpm                                                | 547 kB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : wget-1.14-18.el7_6.1.x86_64                                                        1/1 
  Verifying  : wget-1.14-18.el7_6.1.x86_64                                                        1/1 

Installed:
  wget.x86_64 0:1.14-18.el7_6.1                                                                       

Complete!
[devops@app1 dynamic]$ wget https://raw.githubusercontent.com/ansible/ansible/devel/contrib/inventory/ec2.py
--2020-02-05 09:42:38--  https://raw.githubusercontent.com/ansible/ansible/devel/contrib/inventory/ec2.py
Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.156.133
Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.156.133|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 73130 (71K) [text/plain]
Saving to: 'ec2.py'

100%[============================================================>] 73,130      --.-K/s   in 0.09s   

2020-02-05 09:42:39 (838 KB/s) - 'ec2.py' saved [73130/73130]

[devops@app1 dynamic]$ ll
total 72
-rw-rw-r--. 1 devops devops 73130 Feb  5 09:42 ec2.py
[devops@app1 dynamic]$ vi ec2.py 
[devops@app1 dynamic]$ python ec2.py 
Traceback (most recent call last):
  File "ec2.py", line 164, in <module>
    import boto
ImportError: No module named boto
[devops@app1 dynamic]$ cd ..
[devops@app1 project]$ ansible all --list-hosts -v
Using /home/devops/project/ansible.cfg as config file
  hosts (2):
    app2
    app3
[devops@app1 project]$ chmod -R 777 ./dynamic
[devops@app1 project]$ ansible all --list-hosts -v
Using /home/devops/project/ansible.cfg as config file
  hosts (2):
    app2
    app3
[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ ansible all --list-hosts -v
Using /home/devops/project/ansible.cfg as config file
[WARNING]:  * Failed to parse /home/devops/project/dynamic/ec2.py with script plugin: Inventory
script (/home/devops/project/dynamic/ec2.py) had an execution error: Traceback (most recent call
last):   File "/home/devops/project/dynamic/ec2.py", line 164, in <module>     import boto
ImportError: No module named boto

[WARNING]:  * Failed to parse /home/devops/project/dynamic/ec2.py with ini plugin:
/home/devops/project/dynamic/ec2.py:3: Error parsing host definition ''''': No closing quotation

[WARNING]: Unable to parse /home/devops/project/dynamic/ec2.py as an inventory source

[WARNING]: Unable to parse /home/devops/project/dynamic as an inventory source

[WARNING]: No inventory was parsed, only implicit localhost is available

[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'

  hosts (0):
[devops@app1 project]$ cat ansible.cfg 
[defaults]
#inventory=./hosts
inventory=dynamic
remote_user=devops
ask_pass=False
vault_password_file=.myvaultpassword.txt

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ ll dynamic/
total 72
-rwxrwxrwx. 1 devops devops 73130 Feb  5 09:42 ec2.py
[devops@app1 project]$ ansible-inventory --yaml --list -i hosts
all:
  children:
    servers:
      children:
        dbserver:
          hosts:
            app3:
              ansible_host: 192.168.3.7
        webserver:
          hosts:
            app2:
              ansible_host: 192.168.3.6
              pkg:
              - mariadb-server
              - mariadb
              rule: mysql
              srv: mariadb
    ungrouped: {}
[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ ansible-playbook static.yml 
[WARNING]:  * Failed to parse /home/devops/project/dynamic/ec2.py with script plugin: Inventory
script (/home/devops/project/dynamic/ec2.py) had an execution error: Traceback (most recent call
last):   File "/home/devops/project/dynamic/ec2.py", line 164, in <module>     import boto
ImportError: No module named boto

[WARNING]:  * Failed to parse /home/devops/project/dynamic/ec2.py with ini plugin:
/home/devops/project/dynamic/ec2.py:3: Error parsing host definition ''''': No closing quotation

[WARNING]: Unable to parse /home/devops/project/dynamic/ec2.py as an inventory source

[WARNING]: Unable to parse /home/devops/project/dynamic as an inventory source

[WARNING]: No inventory was parsed, only implicit localhost is available

[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'


PLAY [Playbook to display Static Module Manipulation] ************************************************
skipping: no hosts matched

PLAY RECAP *******************************************************************************************

[devops@app1 project]$ ansible-playbook static.yml 
[WARNING]:  * Failed to parse /home/devops/project/dynamic/ec2.py with script plugin: Inventory
script (/home/devops/project/dynamic/ec2.py) had an execution error: Traceback (most recent call
last):   File "/home/devops/project/dynamic/ec2.py", line 164, in <module>     import boto
ImportError: No module named boto

[WARNING]:  * Failed to parse /home/devops/project/dynamic/ec2.py with ini plugin:
/home/devops/project/dynamic/ec2.py:3: Error parsing host definition ''''': No closing quotation

[WARNING]: Unable to parse /home/devops/project/dynamic/ec2.py as an inventory source

[WARNING]: Unable to parse /home/devops/project/dynamic as an inventory source

[WARNING]: No inventory was parsed, only implicit localhost is available

[WARNING]: provided hosts list is empty, only localhost is available. Note that the implicit
localhost does not match 'all'


PLAY [Playbook to display Static Module Manipulation] ************************************************
skipping: no hosts matched

PLAY RECAP *******************************************************************************************

[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app2]
ok: [app3]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app2]
changed: [app3]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app2]
ok: [app3]

TASK [Replace the content of existing file] **********************************************************
changed: [app2]
changed: [app3]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app2]
changed: [app3]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app2]
changed: [app3]

TASK [Add a line Before a regex] *********************************************************************
changed: [app2]
changed: [app3]

TASK [Copy files from managed nodes] *****************************************************************
ok: [app2]
ok: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=9    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=9    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vim static.yml 
[devops@app1 project]$ ansible-playbook static.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]

TASK [Creating file using copy module] ***************************************************************
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app2]

TASK [Add a line Before a regex] *********************************************************************
changed: [app2]

TASK [Copy files from managed nodes] *****************************************************************
ok: [app2]

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]

TASK [Creating a Directory] **************************************************************************
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app3]

TASK [Add a line Before a regex] *********************************************************************
changed: [app3]

TASK [Copy files from managed nodes] *****************************************************************
ok: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=9    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=9    changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
#inventory=dynamic
remote_user=devops
ask_pass=False
vault_password_file=.myvaultpassword.txt
forks=1

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ #vim static.yml 
[devops@app1 project]$ vim httpd_vars.yml
[devops@app1 project]$ cat httpd_vars.yml
---
web_pkg: httpd
web_srv: httpd
web_rule: http
[devops@app1 project]$ vi httpd_tasks.yml
[devops@app1 project]$ cat httpd_tasks.yml
---
- name: Installing {{ web_pkg }}
  yum:
    name: "{{ web_pkg }}"
    state: present

- name: starting {{ web_srv }}
  service:
    name: "{{ web_srv }}"
    state: started

- name: Allow {{ web_rule }} in firewall
  firewalld:
    service: "{{ web_rule }}"
    state: enabled
    
[devops@app1 project]$ vim fw_vars.yml
[devops@app1 project]$ cat fw_vars.yml
---
fw_pkg: firewalld
fw_srv: firewalld
[devops@app1 project]$ vim fw_tasks.yml
[devops@app1 project]$ cat fw_tasks.yml
---
- name: Setup {{ fw_pkg }}
  yum:
    name: "{{ fw_pkg }}"
    state: latest

- name: Starting {{ fw_srv }}
  service:
    name: "{{ fw_srv }}"
    state: started
  
[devops@app1 project]$ vim master.yml
[devops@app1 project]$ ansible-doc -l | grep -e include -e import
bigip_apm_policy_import                                       Manage BIG-IP APM policy or APM acc...
import_playbook                                               Import a playbook                  
include_vars                                                  Load variables from files, dynamica...
import_role                                                   Import a role into a play          
panos_import                                                  import file on PAN-OS devices      
include_role                                                  Load and execute a role            
bigip_asm_policy_import                                       Manage BIG-IP ASM policy imports   
include_tasks                                                 Dynamically include a task list    
include                                                       Include a play or task list        
import_tasks                                                  Import a task list                 
java_cert                                                     Uses keytool to import/remove key f...
[devops@app1 project]$ vim master.yml
[devops@app1 project]$ cat master.yml
---
- name: Master Playbook
  hosts: webserver
  become: true
  vars_files:
    - fw_vars.yml
  tasks:
    - include_vars: http_vars.yml

    - include_tasks: http_tasks.yml

    - import_tasks: fw_tasks.yml
[devops@app1 project]$ ll [devops@app1 project]$ cat fw_tasks.yml
ls: cannot access [devops@app1: No such file or directory
ls: cannot access project]$: No such file or directory
ls: cannot access cat: No such file or directory
-rw-rw-r--. 1 devops devops 170 Feb  5 10:49 fw_tasks.yml
[devops@app1 project]$ ---
-bash: ---: command not found
[devops@app1 project]$ - name: Setup {{ fw_pkg }}
-bash: -: command not found
[devops@app1 project]$   yum:
-bash: yum:: command not found
[devops@app1 project]$     name: "{{ fw_pkg }}"
-bash: name:: command not found
[devops@app1 project]$     state: latest
-bash: state:: command not found
[devops@app1 project]$ 
[devops@app1 project]$ - name: Starting {{ fw_srv }}
-bash: -: command not found
[devops@app1 project]$   service:
-bash: service:: command not found
[devops@app1 project]$     name: "{{ fw_srv }}"
-bash: name:: command not found
[devops@app1 project]$     state: started
-bash: state:: command not found
[devops@app1 project]$   
[devops@app1 project]$ ll fw_vars.yml
-rw-rw-r--. 1 devops devops 40 Feb  5 10:47 fw_vars.yml
[devops@app1 project]$ ll fw_vars.yml http_vars.yml http_tasks.yml fw_tasks.yml
ls: cannot access http_vars.yml: No such file or directory
ls: cannot access http_tasks.yml: No such file or directory
-rw-rw-r--. 1 devops devops  40 Feb  5 10:47 fw_vars.yml
-rw-rw-r--. 1 devops devops 170 Feb  5 10:49 fw_tasks.yml
[devops@app1 project]$ ll httpd_*
-rw-rw-r--. 1 devops devops  49 Feb  5 10:40 httpd_vars.yml
-rw-rw-r--. 1 devops devops 286 Feb  5 10:44 httpd_tasks.yml
[devops@app1 project]$ mv httpd_vars.yml http_vars.yml
[devops@app1 project]$ mv httpd_tasks.yml http_tasks.yml
[devops@app1 project]$ 
[devops@app1 project]$ 
[devops@app1 project]$ 
[devops@app1 project]$ ll httpd_*
ls: cannot access httpd_*: No such file or directory
[devops@app1 project]$ ll fw_vars.yml http_vars.yml http_tasks.yml fw_tasks.yml
-rw-rw-r--. 1 devops devops  49 Feb  5 10:40 http_vars.yml
-rw-rw-r--. 1 devops devops 286 Feb  5 10:44 http_tasks.yml
-rw-rw-r--. 1 devops devops  40 Feb  5 10:47 fw_vars.yml
-rw-rw-r--. 1 devops devops 170 Feb  5 10:49 fw_tasks.yml
[devops@app1 project]$ ansible-playbook fw_vars.yml http_vars.yml http_tasks.yml fw_tasks.yml --syntax-check
ERROR! A playbook must be a list of plays, got a <class 'ansible.parsing.yaml.objects.AnsibleMapping'> instead

The error appears to be in '/home/devops/project/fw_vars.yml': line 2, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
fw_pkg: firewalld
^ here

[devops@app1 project]$ ansible-playbook fw_vars.yml  --syntax-check
ERROR! A playbook must be a list of plays, got a <class 'ansible.parsing.yaml.objects.AnsibleMapping'> instead

The error appears to be in '/home/devops/project/fw_vars.yml': line 2, column 1, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
fw_pkg: firewalld
^ here

[devops@app1 project]$ vi fw_
fw_tasks.yml  fw_vars.yml   
[devops@app1 project]$ vi fw_vars.yml 
[devops@app1 project]$ ansible-playbook   http_tasks.yml fw_tasks.yml --syntax-check
ERROR! 'yum' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/http_tasks.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Installing {{ web_pkg }}
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

[devops@app1 project]$ vi http_tasks.yml 
[devops@app1 project]$ ansible-playbook   master.yml --syntax-check

playbook: master.yml
[devops@app1 project]$ ansible-playbook   master.yml 

PLAY [Master Playbook] *******************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [include_vars] **********************************************************************************
ok: [app2]

TASK [include_tasks] *********************************************************************************
included: /home/devops/project/http_tasks.yml for app2

TASK [Installing httpd] ******************************************************************************
ok: [app2]

TASK [starting httpd] ********************************************************************************
ok: [app2]

TASK [Allow http in firewall] ************************************************************************
ok: [app2]

TASK [Setup firewalld] *******************************************************************************
ok: [app2]

TASK [Starting firewalld] ****************************************************************************
ok: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=8    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat master.yml 
---
- name: Master Playbook
  hosts: webserver
  become: true
  vars_files:
    - fw_vars.yml
  tasks:
    - include_vars: http_vars.yml

    - include_tasks: http_tasks.yml

    - import_tasks: fw_tasks.yml
[devops@app1 project]$ vim app.yml
[devops@app1 project]$ cat app.yml
---
- import_playbook: static.yml

- import_playbook: network.yml

- import_playbook: master.yml

[devops@app1 project]$ ansible-playbook app.yml

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]

TASK [Creating file using copy module] ***************************************************************
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app2]

TASK [Add a line Before a regex] *********************************************************************
changed: [app2]

TASK [Copy files from managed nodes] *****************************************************************
ok: [app2]

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]

TASK [Creating a Directory] **************************************************************************
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app3]

TASK [Add a line Before a regex] *********************************************************************
changed: [app3]

TASK [Copy files from managed nodes] *****************************************************************
ok: [app3]

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [Generating Template] ***************************************************************************
ok: [app2]
ok: [app3]

PLAY [Master Playbook] *******************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [include_vars] **********************************************************************************
ok: [app2]

TASK [include_tasks] *********************************************************************************
included: /home/devops/project/http_tasks.yml for app2

TASK [Installing httpd] ******************************************************************************
ok: [app2]

TASK [starting httpd] ********************************************************************************
ok: [app2]

TASK [Allow http in firewall] ************************************************************************
ok: [app2]

TASK [Setup firewalld] *******************************************************************************
ok: [app2]

TASK [Starting firewalld] ****************************************************************************
ok: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=19   changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=11   changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat master.yml 
---
- name: Master Playbook
  hosts: webserver
  become: true
  vars_files:
    - fw_vars.yml
  tasks:
    - include_vars: http_vars.yml

    - include_tasks: http_tasks.yml

    - import_tasks: fw_tasks.yml
[devops@app1 project]$ ll app
app2.txt  app3.txt  app.yml   
[devops@app1 project]$ ll app
app2.txt  app3.txt  app.yml   
[devops@app1 project]$ ll app.yml 
-rw-rw-r--. 1 devops devops 98 Feb  5 11:06 app.yml
[devops@app1 project]$ cat app.yml 
---
- import_playbook: static.yml

- import_playbook: network.yml

- import_playbook: master.yml

[devops@app1 project]$ ansible-playbook app.yml 

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Verify the Directory exists] *******************************************************************
ok: [app2]

TASK [Creating a Directory] **************************************************************************
skipping: [app2]

TASK [Creating file using copy module] ***************************************************************
changed: [app2]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app2]

TASK [Replace the content of existing file] **********************************************************
changed: [app2]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app2]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app2]

TASK [Add a line Before a regex] *********************************************************************
changed: [app2]

TASK [Copy files from managed nodes] *****************************************************************
ok: [app2]

PLAY [Playbook to display Static Module Manipulation] ************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]

TASK [Verify the Directory exists] *******************************************************************
ok: [app3]

TASK [Creating a Directory] **************************************************************************
skipping: [app3]

TASK [Creating file using copy module] ***************************************************************
changed: [app3]

TASK [Copy file from controller to manage nodes] *****************************************************
ok: [app3]

TASK [Replace the content of existing file] **********************************************************
changed: [app3]

TASK [Appending a New line in the existing file] *****************************************************
changed: [app3]

TASK [Adding a Set of Lines in the file] *************************************************************
changed: [app3]

TASK [Add a line Before a regex] *********************************************************************
changed: [app3]

TASK [Copy files from managed nodes] *****************************************************************
ok: [app3]

PLAY [Create J2 Template] ****************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [Generating Template] ***************************************************************************
ok: [app2]
ok: [app3]

PLAY [Master Playbook] *******************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [include_vars] **********************************************************************************
ok: [app2]

TASK [include_tasks] *********************************************************************************
included: /home/devops/project/http_tasks.yml for app2

TASK [Installing httpd] ******************************************************************************
ok: [app2]

TASK [starting httpd] ********************************************************************************
ok: [app2]

TASK [Allow http in firewall] ************************************************************************
ok: [app2]

TASK [Setup firewalld] *******************************************************************************
ok: [app2]

TASK [Starting firewalld] ****************************************************************************
ok: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=19   changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=11   changed=5    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ cat app.yml 
---
- import_playbook: static.yml

- import_playbook: network.yml

- import_playbook: master.yml

[devops@app1 project]$ #ansible-playbook app.yml 
[devops@app1 project]$ 
  [Restored 06-Feb-2020 at 8:18:42 AM]
Last login: Thu Feb  6 08:18:34 on console

 2020-02-06 08:18:58 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant status
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
Current machine states:

app1                      poweroff (virtualbox)
app2                      poweroff (virtualbox)
app3                      poweroff (virtualbox)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.

 2020-02-06 08:21:01 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant up
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
Bringing machine 'app1' up with 'virtualbox' provider...
Bringing machine 'app2' up with 'virtualbox' provider...
Bringing machine 'app3' up with 'virtualbox' provider...
==> app1: Checking if box 'centos/7' version '1905.1' is up to date...
==> app1: Clearing any previously set forwarded ports...
==> app1: Clearing any previously set network interfaces...
==> app1: Preparing network interfaces based on configuration...
    app1: Adapter 1: nat
    app1: Adapter 2: hostonly
==> app1: Forwarding ports...
    app1: 22 (guest) => 2222 (host) (adapter 1)
==> app1: Running 'pre-boot' VM customizations...
==> app1: Booting VM...
==> app1: Waiting for machine to boot. This may take a few minutes...
    app1: SSH address: 127.0.0.1:2222
    app1: SSH username: vagrant
    app1: SSH auth method: private key
==> app1: Machine booted and ready!
[app1] GuestAdditions seems to be installed (6.0.15) correctly, but not running.
Redirecting to /bin/systemctl start vboxadd.service
Redirecting to /bin/systemctl start vboxadd-service.service
bash: line 4: setup: command not found
==> app1: Checking for guest additions in VM...
The following SSH command responded with a non-zero exit status.
Vagrant assumes that this means the command failed!

 setup

Stdout from the command:



Stderr from the command:

bash: line 4: setup: command not found


 2020-02-06 08:36:06 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant status
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
Current machine states:

app1                      running (virtualbox)
app2                      poweroff (virtualbox)
app3                      poweroff (virtualbox)

This environment represents multiple VMs. The VMs are all listed
above with their current state. For more information about a specific
VM, run `vagrant status NAME`.

 2020-02-06 08:37:31 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant --help
Usage: vagrant [options] <command> [<args>]

    -v, --version                    Print the version and exit.
    -h, --help                       Print this help.

Common commands:
     box             manages boxes: installation, removal, etc.
     cloud           manages everything related to Vagrant Cloud
     destroy         stops and deletes all traces of the vagrant machine
     global-status   outputs status Vagrant environments for this user
     halt            stops the vagrant machine
     help            shows the help for a subcommand
     init            initializes a new Vagrant environment by creating a Vagrantfile
     login           
     package         packages a running vagrant environment into a box
     plugin          manages plugins: install, uninstall, update, etc.
     port            displays information about guest port mappings
     powershell      connects to machine via powershell remoting
     provision       provisions the vagrant machine
     push            deploys code in this environment to a configured destination
     rdp             connects to machine via RDP
     reload          restarts vagrant machine, loads new Vagrantfile configuration
     resume          resume a suspended vagrant machine
     snapshot        manages snapshots: saving, restoring, etc.
     ssh             connects to machine via SSH
     ssh-config      outputs OpenSSH valid configuration to connect to the machine
     status          outputs status of the vagrant machine
     suspend         suspends the machine
     up              starts and provisions the vagrant environment
     upload          upload to machine via communicator
     validate        validates the Vagrantfile
     vbguest         plugin: vagrant-vbguest: install VirtualBox Guest Additions to the machine
     version         prints current and latest Vagrant version
     winrm           executes commands on a machine via WinRM
     winrm-config    outputs WinRM configuration to connect to the machine

For help on any individual command run `vagrant COMMAND -h`

Additional subcommands are available, but are either more advanced
or not commonly used. To see all subcommands, run the command
`vagrant list-commands`.


 2020-02-06 08:37:48 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → vagrant halt app1
/opt/vagrant/embedded/gems/2.2.4/gems/vagrant-2.2.4/lib/vagrant/util/which.rb:37: warning: Insecure world writable dir /Users/azhekhan/vault in PATH, mode 040777
==> app1: Attempting graceful shutdown of VM...

 2020-02-06 08:38:15 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → ssh vagrant@192.168.50.7
^C

 2020-02-06 08:39:36 ⌚  azhekhan-mac in ~/vagrant_dev/v_ansible_centos7
○ → ssh vagrant@192.168.3.5
Last login: Wed Feb  5 06:17:33 2020 from 10.0.2.2
-bash: warning: setlocale: LC_CTYPE: cannot change locale (UTF-8): No such file or directory
[vagrant@app1 ~]$ sudo -iu devops
[devops@app1 ~]$ ll
total 8
drwxrwxr-x. 5 devops devops 4096 Feb  5 11:06 project
[devops@app1 ~]$ cd project/
[devops@app1 project]$ ll
total 108
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
-rw-rw-r--. 1 devops devops  215 Feb  5 08:55 inventory
drwxrwxrwx. 2 devops devops   20 Feb  5 09:43 dynamic
-rw-rw-r--. 1 devops devops  225 Feb  5 10:11 ansible.cfg
-rw-rw-r--. 1 devops devops 1842 Feb  5 10:18 static.yml
-rw-rw-r--. 1 devops devops   49 Feb  5 10:40 http_vars.yml
-rw-rw-r--. 1 devops devops  286 Feb  5 10:44 http_tasks.yml
-rw-rw-r--. 1 devops devops   40 Feb  5 10:47 fw_vars.yml
-rw-rw-r--. 1 devops devops  170 Feb  5 10:49 fw_tasks.yml
-rw-rw-r--. 1 devops devops  208 Feb  5 10:54 master.yml
-rw-rw-r--. 1 devops devops   98 Feb  5 11:06 app.yml
[devops@app1 project]$ vi test.yml
[devops@app1 project]$ vi t.yml
[devops@app1 project]$ ansible-playbook t.yml
ERROR! 'setup' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/t.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Running Setup to get host Facts
  ^ here

[devops@app1 project]$ vi t.yml
[devops@app1 project]$ ansible-playbook t.yml
ERROR! 'setup' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/t.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Collect only facts returned by facter
  ^ here

[devops@app1 project]$ vi t.yml
[devops@app1 project]$ ansible-playbook t.yml
ERROR! 'setup' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/t.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Collect only facts returned by facter
  ^ here

[devops@app1 project]$ vi t.yml
[devops@app1 project]$ vi r.yml
[devops@app1 project]$ #mv t.yml get_facts
[devops@app1 project]$ mkdir get_facts/tasks
mkdir: cannot create directory 'get_facts/tasks': No such file or directory
[devops@app1 project]$ mkdir -p get_facts/tasks
[devops@app1 project]$ mv t.yml get_facts/tasks/main.yml
[devops@app1 project]$ ansible-playbook r.yml 

PLAY [all] *******************************************************************************************

TASK [get_facts : Collect only facts returned by facter] *********************************************
ok: [app2]
ok: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat get_facts/tasks/main.yml 
---
- name: Collect only facts returned by facter
  setup:
    gather_subset:
      - '!all'
      - '!any'
      - facter
#- name: Running Setup to get host Facts
#  hosts: all
#  setup:
[devops@app1 project]$ vim get_facts/tasks/main.yml 
[devops@app1 project]$ ansible-playbook r.yml 

PLAY [all] *******************************************************************************************

TASK [get_facts : Collect only facts returned by facter] *********************************************
ok: [app2]
ok: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=1    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ nsible localhost -m -a msg="{{ lookup('env', 'SHELL') }}"
-bash: nsible: command not found
[devops@app1 project]$ 
[devops@app1 project]$ (Page 138). 
-bash: syntax error near unexpected token `.'
[devops@app1 project]$ ansible all -m -a "{{ lookup('env', 'SHELL') }}"
usage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD]
               [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts]
               [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k]
               [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
               [-c CONNECTION] [-T TIMEOUT]
               [--ssh-common-args SSH_COMMON_ARGS]
               [--sftp-extra-args SFTP_EXTRA_ARGS]
               [--scp-extra-args SCP_EXTRA_ARGS]
               [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D]
               [-e EXTRA_VARS] [--vault-id VAULT_IDS]
               [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
               [-f FORKS] [-M MODULE_PATH] [--playbook-dir BASEDIR]
               [-a MODULE_ARGS] [-m MODULE_NAME]
               pattern
ansible: error: argument -m/--module-name: expected one argument
[devops@app1 project]$ ansible all -m -a "{{ lookup('env', 'SHELL') }}"
usage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD]
               [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts]
               [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k]
               [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
               [-c CONNECTION] [-T TIMEOUT]
               [--ssh-common-args SSH_COMMON_ARGS]
               [--sftp-extra-args SFTP_EXTRA_ARGS]
               [--scp-extra-args SCP_EXTRA_ARGS]
               [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D]
               [-e EXTRA_VARS] [--vault-id VAULT_IDS]
               [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
               [-f FORKS] [-M MODULE_PATH] [--playbook-dir BASEDIR]
               [-a MODULE_ARGS] [-m MODULE_NAME]
               pattern
ansible: error: argument -m/--module-name: expected one argument
[devops@app1 project]$ ansible all -m -a msg "{{ lookup('env', 'SHELL') }}"
usage: ansible [-h] [--version] [-v] [-b] [--become-method BECOME_METHOD]
               [--become-user BECOME_USER] [-K] [-i INVENTORY] [--list-hosts]
               [-l SUBSET] [-P POLL_INTERVAL] [-B SECONDS] [-o] [-t TREE] [-k]
               [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
               [-c CONNECTION] [-T TIMEOUT]
               [--ssh-common-args SSH_COMMON_ARGS]
               [--sftp-extra-args SFTP_EXTRA_ARGS]
               [--scp-extra-args SCP_EXTRA_ARGS]
               [--ssh-extra-args SSH_EXTRA_ARGS] [-C] [--syntax-check] [-D]
               [-e EXTRA_VARS] [--vault-id VAULT_IDS]
               [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
               [-f FORKS] [-M MODULE_PATH] [--playbook-dir BASEDIR]
               [-a MODULE_ARGS] [-m MODULE_NAME]
               pattern
ansible: error: argument -m/--module-name: expected one argument
[devops@app1 project]$ ansible-docmsg
-bash: ansible-docmsg: command not found
[devops@app1 project]$ ansible-doc msg
[WARNING]: module msg not found in:
/home/devops/.ansible/plugins/modules:/usr/share/ansible/plugins/modules:/usr/lib/python2.7/site-
packages/ansible/modules

[devops@app1 project]$ ansible-doc lookup
[WARNING]: module lookup not found in:
/home/devops/.ansible/plugins/modules:/usr/share/ansible/plugins/modules:/usr/lib/python2.7/site-
packages/ansible/modules

[devops@app1 project]$ vi 1.yml
[devops@app1 project]$ ansible-playbook 1.yml
ERROR! 'debug' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/1.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: get the current shell
  ^ here

[devops@app1 project]$ vi hosts.j2
[devops@app1 project]$ vi hosts.yml
[devops@app1 project]$ ansible-playbook hosts.yml

PLAY [Play1] *****************************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [template] **************************************************************************************
changed: [app2]
changed: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=1    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat hosts.yml
---
- name: Play1
  hosts: all
  tasks:
    - template: src=hosts.j2 dest=/tmp/hosts

    #- template:
    #   src: hosts.j2
    #   dest: /tmp/hosts
[devops@app1 project]$ cat hosts.j2 
{# This is sample hosts template #}
# Comment line


{% for i in groups['all'] %}
{{ hostvars[i]['ansible_facts']['default_ipv4']['address'] }}  {{ hostvars[i]['ansible_facts']['fqdn'] }}   {{ hostvars[i]['ansible_facts']['hostname'] }}
{% endfor %}
[devops@app1 project]$ vim hosts.yml
[devops@app1 project]$ ll
total 124
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
-rw-rw-r--. 1 devops devops  215 Feb  5 08:55 inventory
drwxrwxrwx. 2 devops devops   20 Feb  5 09:43 dynamic
-rw-rw-r--. 1 devops devops  225 Feb  5 10:11 ansible.cfg
-rw-rw-r--. 1 devops devops 1842 Feb  5 10:18 static.yml
-rw-rw-r--. 1 devops devops   49 Feb  5 10:40 http_vars.yml
-rw-rw-r--. 1 devops devops  286 Feb  5 10:44 http_tasks.yml
-rw-rw-r--. 1 devops devops   40 Feb  5 10:47 fw_vars.yml
-rw-rw-r--. 1 devops devops  170 Feb  5 10:49 fw_tasks.yml
-rw-rw-r--. 1 devops devops  208 Feb  5 10:54 master.yml
-rw-rw-r--. 1 devops devops   98 Feb  5 11:06 app.yml
-rw-rw-r--. 1 devops devops   73 Feb  6 03:17 r.yml
drwxrwxr-x. 3 devops devops   19 Feb  6 03:17 get_facts
-rw-rw-r--. 1 devops devops   93 Feb  6 03:37 1.yml
-rw-rw-r--. 1 devops devops  250 Feb  6 04:38 hosts.j2
-rw-rw-r--. 1 devops devops  181 Feb  6 05:09 hosts.yml
[devops@app1 project]$ ansible-galaxy list
# /usr/share/ansible/roles
# /etc/ansible/roles
[WARNING]: - the configured path /home/devops/.ansible/roles does not exist.

[devops@app1 project]$ vim ansible.cfg 
[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
#inventory=dynamic
remote_user=devops
ask_pass=False
vault_password_file=.myvaultpassword.txt
forks=1
roles_path=roles

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ mkdir roles
[devops@app1 project]$ ansible-galaxy list
# /home/devops/project/roles
[devops@app1 project]$ ansible-galaxy list | grep roles
# /home/devops/project/roles
[devops@app1 project]$ cat ansible.cfg  | grep roles
roles_path=roles
[devops@app1 project]$ cd roles/
[devops@app1 roles]$ ll
total 0
[devops@app1 roles]$ ansible-galaxy azher.apache init
usage: ansible-galaxy role [-h] ROLE_ACTION ...
ansible-galaxy role: error: argument ROLE_ACTION: invalid choice: u'azher.apache' (choose from 'init', 'remove', 'delete', 'list', 'search', 'import', 'setup', 'login', 'info', 'install')
[devops@app1 roles]$ ll
total 0
[devops@app1 roles]$ ansible-galaxy init azher.apache
- Role azher.apache was created successfully
[devops@app1 roles]$ ll
total 0
drwxrwxr-x. 10 devops devops 154 Feb  6 05:15 azher.apache
[devops@app1 roles]$ ll azher.apache/
total 4
drwxrwxr-x. 2 devops devops    6 Feb  6 05:15 templates
drwxrwxr-x. 2 devops devops    6 Feb  6 05:15 files
-rw-rw-r--. 1 devops devops 1328 Feb  6 05:15 README.md
drwxrwxr-x. 2 devops devops   22 Feb  6 05:15 defaults
drwxrwxr-x. 2 devops devops   22 Feb  6 05:15 handlers
drwxrwxr-x. 2 devops devops   22 Feb  6 05:15 meta
drwxrwxr-x. 2 devops devops   22 Feb  6 05:15 tasks
drwxrwxr-x. 2 devops devops   39 Feb  6 05:15 tests
drwxrwxr-x. 2 devops devops   22 Feb  6 05:15 vars
[devops@app1 roles]$ tree
.
`-- azher.apache
    |-- defaults
    |   `-- main.yml
    |-- files
    |-- handlers
    |   `-- main.yml
    |-- meta
    |   `-- main.yml
    |-- README.md
    |-- tasks
    |   `-- main.yml
    |-- templates
    |-- tests
    |   |-- inventory
    |   `-- test.yml
    `-- vars
        `-- main.yml

9 directories, 8 files
[devops@app1 roles]$ ansible-galaxy init azher.mysql
- Role azher.mysql was created successfully
[devops@app1 roles]$ tree azher.mysql/
azher.mysql/
|-- defaults
|   `-- main.yml
|-- files
|-- handlers
|   `-- main.yml
|-- meta
|   `-- main.yml
|-- README.md
|-- tasks
|   `-- main.yml
|-- templates
|-- tests
|   |-- inventory
|   `-- test.yml
`-- vars
    `-- main.yml

8 directories, 8 files
[devops@app1 roles]$ cd ..
[devops@app1 project]$ ansible-galaxy list
# /home/devops/project/roles
- azher.apache, (unknown version)
- azher.mysql, (unknown version)
[devops@app1 project]$ ansible-galaxy remove azher.apache
- successfully removed azher.apache
[devops@app1 project]$ ll roles/
total 0
drwxrwxr-x. 10 devops devops 154 Feb  6 05:16 azher.mysql
[devops@app1 project]$ ansible-galaxy search mysq;

Found 2 roles matching your search:

 Name                         Description
 ----                         -----------
 juju4.icinga2                Icinga2
 stancel.restore_db_and_files This role picks up from the stancel.restore-bareos-backup role where fil
[devops@app1 project]$ cd roles/
[devops@app1 roles]$ ll
total 0
drwxrwxr-x. 10 devops devops 154 Feb  6 05:16 azher.mysql
[devops@app1 roles]$ tree
.
`-- azher.mysql
    |-- defaults
    |   `-- main.yml
    |-- files
    |-- handlers
    |   `-- main.yml
    |-- meta
    |   `-- main.yml
    |-- README.md
    |-- tasks
    |   `-- main.yml
    |-- templates
    |-- tests
    |   |-- inventory
    |   `-- test.yml
    `-- vars
        `-- main.yml

9 directories, 8 files
[devops@app1 roles]$ vi azher.mysql/tasks/main.yml 
[devops@app1 roles]$ ansible-playbook azher.mysql/tasks/main.yml  --syntax-check
ERROR! 'yum' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/roles/azher.mysql/tasks/main.yml': line 3, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

# tasks file for azher.mysql
- name: Install {{ db_pkg }} Packages
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

[devops@app1 roles]$ cat azher.mysql/tasks/main.yml 
---
# tasks file for azher.mysql
- name: Install {{ db_pkg }} Packages 
  yum:
    name: "{{ db_pkg }}"
    state: present
  notify: restart_db

- name: Starting {{ db_srv }} Service
  service:
    name: "{{ db_srv }}"
    state: started
    enabled: yes

- name: Copy template file for MOTD
  template:
    src: motd.j2
    dest: /etc/motd
    owner: root
    group: root
    mode: 0644

# 1. Remove Test DB
# 2. Disable Anonymous Access
# 3. Set Password for Root Login
# 4. Sample DB for a particular user
# 5. non-root user harry (Privilege to access Sample DB)

- name: Removing Test DB
  mysql_db:
    name: test
    state: absent
  ignore_errors: true

- name: Disable anonymous access to DB
  mysql_user:
    name: ''
    state: absent
  ignore_errors: true

- name: Setting root user password for DB
  mysql_user:
    name: root
    state: present
    password: "{{ root_pass }}"
  ignore_errors: true

- name: Create Database for User
  mysql_db:
    name: ansible_db
    state: present
    login_user: root
    login_password: "{{ root_pass }}"

- name: Adding non-root user and assign privileges
  mysql_user:
    name: harry
    state: present
    password: "{{ usr_pass }}"
    login_user: root
    login_password: "{{ root_pass }}"
    priv: 'ansible_db.*:ALL' 
    #*.* : ALL  C U R D
[devops@app1 roles]$ vim azher.mysql/vars/main.yml 
[devops@app1 roles]$ cat azher.mysql/vars/main.yml 
---
# vars file for azher.mysql
db_pkg: 
  - mariadb-server
  - mariadb
  - MySQL-python

db_srv: mariadb
root_pass: AjjuR0ck$
usr_pass: redhat

#vars_files: | include_vars:
[devops@app1 roles]$ vim azher.mysql/handlers/main.yml 
[devops@app1 roles]$ ansible-playbook azher.mysql/tasks/main.yml  --syntax-check
ERROR! 'yum' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/roles/azher.mysql/tasks/main.yml': line 3, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

# tasks file for azher.mysql
- name: Install {{ db_pkg }} Packages
  ^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes. Always quote template expression brackets when they
start a value. For instance:

    with_items:
      - {{ foo }}

Should be written as:

    with_items:
      - "{{ foo }}"

[devops@app1 roles]$ vim azher.mysql/tasks/main.yml 
[devops@app1 roles]$ vim azher.mysql/tasks/main.yml 
[devops@app1 roles]$ vim azher.mysql/templates/motd.j2
[devops@app1 roles]$ cat azher.mysql/templates/motd.j2
{#Sample motd template#}
Welcome to Database Server {{ ansible_hostname }}
Unauthorized access is Prohibited

NODE FQDN: {{ ansible_fqdn }}
NODE IP  : {{ ansible_facts.default_ipv4.address }}
NODE OS  : {{ ansible_distribution }}

For any incidents please write to admin at {{ admin_mail }}
[devops@app1 roles]$ vim azher.mysql/vars/main.yml 
[devops@app1 roles]$ cat azher.mysql/vars/main.yml 
---
# vars file for azher.mysql
db_pkg: 
  - mariadb-server
  - mariadb
  - MySQL-python

db_srv: mariadb
root_pass: AjjuR0ck$
usr_pass: redhat

admin_mail: azher.khan@oracle.com
#vars_files: | include_vars:
[devops@app1 roles]$ cat azher.mysql/templates/motd.j2
{#Sample motd template#}
Welcome to Database Server {{ ansible_hostname }}
Unauthorized access is Prohibited

NODE FQDN: {{ ansible_fqdn }}
NODE IP  : {{ ansible_facts.default_ipv4.address }}
NODE OS  : {{ ansible_distribution }}

For any incidents please write to admin at {{ admin_mail }}
[devops@app1 roles]$ cat azher.mysql/handlers/main.yml 
---
# handlers file for azher.mysql
- name: restart_db
  service:
    name: "{{ db_srv }}"
    state: restarted
[devops@app1 roles]$ vi azher.mysql/meta/main.yml 
[devops@app1 roles]$ cat  azher.mysql/meta/main.yml  | head -10
galaxy_info:
  author: Azher Khan
  description: OSVC CPE Engineering Team Database Server
  company: Oracle

  # If the issue tracker for your role is not on github, uncomment the
  # next line and provide a value
  # issue_tracker_url: http://example.com/issue/tracker

  # Choose a valid license ID from https://spdx.org - some suggested licenses:
[devops@app1 roles]$ tree
.
`-- azher.mysql
    |-- defaults
    |   `-- main.yml
    |-- files
    |-- handlers
    |   `-- main.yml
    |-- meta
    |   `-- main.yml
    |-- README.md
    |-- tasks
    |   `-- main.yml
    |-- templates
    |   `-- motd.j2
    |-- tests
    |   |-- inventory
    |   `-- test.yml
    `-- vars
        `-- main.yml

9 directories, 9 files
[devops@app1 roles]$ ll
total 0
drwxrwxr-x. 10 devops devops 154 Feb  6 05:16 azher.mysql
[devops@app1 roles]$ cd ..
[devops@app1 project]$ cd -
/home/devops/project/roles
[devops@app1 roles]$ find -exec ls -ltr {} \;
total 0
drwxrwxr-x. 10 devops devops 154 Feb  6 05:16 azher.mysql
total 4
drwxrwxr-x. 2 devops devops    6 Feb  6 05:16 files
-rw-rw-r--. 1 devops devops 1328 Feb  6 05:16 README.md
drwxrwxr-x. 2 devops devops   22 Feb  6 05:16 defaults
drwxrwxr-x. 2 devops devops   39 Feb  6 05:16 tests
drwxrwxr-x. 2 devops devops   22 Feb  6 06:25 handlers
drwxrwxr-x. 2 devops devops   22 Feb  6 06:27 tasks
drwxrwxr-x. 2 devops devops   21 Feb  6 06:30 templates
drwxrwxr-x. 2 devops devops   22 Feb  6 06:30 vars
drwxrwxr-x. 2 devops devops   22 Feb  6 06:34 meta
-rw-rw-r--. 1 devops devops 539 Feb  6 05:16 ./azher.mysql/.travis.yml
-rw-rw-r--. 1 devops devops 1328 Feb  6 05:16 ./azher.mysql/README.md
total 4
-rw-rw-r--. 1 devops devops 35 Feb  6 05:16 main.yml
-rw-rw-r--. 1 devops devops 35 Feb  6 05:16 ./azher.mysql/defaults/main.yml
total 0
total 4
-rw-rw-r--. 1 devops devops 112 Feb  6 06:25 main.yml
-rw-rw-r--. 1 devops devops 112 Feb  6 06:25 ./azher.mysql/handlers/main.yml
total 4
-rw-rw-r--. 1 devops devops 1642 Feb  6 06:34 main.yml
-rw-rw-r--. 1 devops devops 1642 Feb  6 06:34 ./azher.mysql/meta/main.yml
total 4
-rw-rw-r--. 1 devops devops 1301 Feb  6 05:55 main.yml
-rw-rw-r--. 1 devops devops 1301 Feb  6 05:55 ./azher.mysql/tasks/main.yml
total 4
-rw-rw-r--. 1 devops devops 291 Feb  6 06:30 motd.j2
-rw-rw-r--. 1 devops devops 291 Feb  6 06:30 ./azher.mysql/templates/motd.j2
total 8
-rw-rw-r--. 1 devops devops 69 Feb  6 05:16 test.yml
-rw-rw-r--. 1 devops devops 11 Feb  6 05:16 inventory
-rw-rw-r--. 1 devops devops 11 Feb  6 05:16 ./azher.mysql/tests/inventory
-rw-rw-r--. 1 devops devops 69 Feb  6 05:16 ./azher.mysql/tests/test.yml
total 4
-rw-rw-r--. 1 devops devops 208 Feb  6 06:30 main.yml
-rw-rw-r--. 1 devops devops 208 Feb  6 06:30 ./azher.mysql/vars/main.yml
[devops@app1 roles]$ find . -iname "*.yml" -exec ls -ltr {} \; 
-rw-rw-r--. 1 devops devops 539 Feb  6 05:16 ./azher.mysql/.travis.yml
-rw-rw-r--. 1 devops devops 35 Feb  6 05:16 ./azher.mysql/defaults/main.yml
-rw-rw-r--. 1 devops devops 112 Feb  6 06:25 ./azher.mysql/handlers/main.yml
-rw-rw-r--. 1 devops devops 1642 Feb  6 06:34 ./azher.mysql/meta/main.yml
-rw-rw-r--. 1 devops devops 1301 Feb  6 05:55 ./azher.mysql/tasks/main.yml
-rw-rw-r--. 1 devops devops 69 Feb  6 05:16 ./azher.mysql/tests/test.yml
-rw-rw-r--. 1 devops devops 208 Feb  6 06:30 ./azher.mysql/vars/main.yml
[devops@app1 roles]$ vi ./azher.mysql/tests/test.yml
[devops@app1 roles]$ vi ./azher.mysql/tests/inventory 
[devops@app1 roles]$ l
azher.mysql/
[devops@app1 roles]$ ll
total 0
drwxrwxr-x. 10 devops devops 154 Feb  6 05:16 azher.mysql
[devops@app1 roles]$ ll azher.mysql/
total 4
drwxrwxr-x. 2 devops devops    6 Feb  6 05:16 files
-rw-rw-r--. 1 devops devops 1328 Feb  6 05:16 README.md
drwxrwxr-x. 2 devops devops   22 Feb  6 05:16 defaults
drwxrwxr-x. 2 devops devops   22 Feb  6 06:25 handlers
drwxrwxr-x. 2 devops devops   22 Feb  6 06:27 tasks
drwxrwxr-x. 2 devops devops   21 Feb  6 06:30 templates
drwxrwxr-x. 2 devops devops   22 Feb  6 06:30 vars
drwxrwxr-x. 2 devops devops   22 Feb  6 06:34 meta
drwxrwxr-x. 2 devops devops   39 Feb  6 06:39 tests
[devops@app1 roles]$ tree
.
`-- azher.mysql
    |-- defaults
    |   `-- main.yml
    |-- files
    |-- handlers
    |   `-- main.yml
    |-- meta
    |   `-- main.yml
    |-- README.md
    |-- tasks
    |   `-- main.yml
    |-- templates
    |   `-- motd.j2
    |-- tests
    |   |-- inventory
    |   `-- test.yml
    `-- vars
        `-- main.yml

9 directories, 9 files
[devops@app1 roles]$ ls -altr azher.mysql/
total 8
drwxrwxr-x.  2 devops devops    6 Feb  6 05:16 files
-rw-rw-r--.  1 devops devops 1328 Feb  6 05:16 README.md
-rw-rw-r--.  1 devops devops  539 Feb  6 05:16 .travis.yml
drwxrwxr-x.  2 devops devops   22 Feb  6 05:16 defaults
drwxrwxr-x. 10 devops devops  154 Feb  6 05:16 .
drwxrwxr-x.  3 devops devops   25 Feb  6 05:25 ..
drwxrwxr-x.  2 devops devops   22 Feb  6 06:25 handlers
drwxrwxr-x.  2 devops devops   22 Feb  6 06:27 tasks
drwxrwxr-x.  2 devops devops   21 Feb  6 06:30 templates
drwxrwxr-x.  2 devops devops   22 Feb  6 06:30 vars
drwxrwxr-x.  2 devops devops   22 Feb  6 06:34 meta
drwxrwxr-x.  2 devops devops   39 Feb  6 06:39 tests
[devops@app1 roles]$ cat ./azher.mysql/tests/inventory
localhost

[devops@app1 roles]$ cat ./azher.mysql/tests/test.yml 
---
- hosts: localhost
  remote_user: root
  roles:
    - azher.mysql
[devops@app1 roles]$ cd ..
[devops@app1 project]$ vi azmysql.yml
[devops@app1 project]$ cat azmysql.yml
---
- hosts: all
  roles:
    - azher.mysql
[devops@app1 project]$ vi azmysql.yml
[devops@app1 project]$ ll roles/azher.mysql
total 4
drwxrwxr-x. 2 devops devops    6 Feb  6 05:16 files
-rw-rw-r--. 1 devops devops 1328 Feb  6 05:16 README.md
drwxrwxr-x. 2 devops devops   22 Feb  6 05:16 defaults
drwxrwxr-x. 2 devops devops   22 Feb  6 06:25 handlers
drwxrwxr-x. 2 devops devops   22 Feb  6 06:27 tasks
drwxrwxr-x. 2 devops devops   21 Feb  6 06:30 templates
drwxrwxr-x. 2 devops devops   22 Feb  6 06:30 vars
drwxrwxr-x. 2 devops devops   22 Feb  6 06:34 meta
drwxrwxr-x. 2 devops devops   39 Feb  6 06:39 tests
[devops@app1 project]$ vi azmysql.yml
[devops@app1 project]$ cat azmysql.yml
---
- name: Playbook to Setup MySQL Database 
  hosts: app3
  become: true
  roles:
    - azher.mysql
[devops@app1 project]$ ansible-playbook azmysql.yml --sytax-check
usage: ansible-playbook [-h] [--version] [-v] [-k]
                        [--private-key PRIVATE_KEY_FILE] [-u REMOTE_USER]
                        [-c CONNECTION] [-T TIMEOUT]
                        [--ssh-common-args SSH_COMMON_ARGS]
                        [--sftp-extra-args SFTP_EXTRA_ARGS]
                        [--scp-extra-args SCP_EXTRA_ARGS]
                        [--ssh-extra-args SSH_EXTRA_ARGS] [--force-handlers]
                        [--flush-cache] [-b] [--become-method BECOME_METHOD]
                        [--become-user BECOME_USER] [-K] [-t TAGS]
                        [--skip-tags SKIP_TAGS] [-C] [--syntax-check] [-D]
                        [-i INVENTORY] [--list-hosts] [-l SUBSET]
                        [-e EXTRA_VARS] [--vault-id VAULT_IDS]
                        [--ask-vault-pass | --vault-password-file VAULT_PASSWORD_FILES]
                        [-f FORKS] [-M MODULE_PATH] [--list-tasks]
                        [--list-tags] [--step] [--start-at-task START_AT_TASK]
                        playbook [playbook ...]
ansible-playbook: error: unrecognized arguments: --sytax-check
[devops@app1 project]$ /s^[k^C
[devops@app1 project]$ ansible-playbook azmysql.yml --syntax-check

playbook: azmysql.yml
[devops@app1 project]$ vi azmysql.yml
[devops@app1 project]$ ^C
[devops@app1 project]$ ansible-playbook azmysql.yml --syntax-check

playbook: azmysql.yml
[devops@app1 project]$ cat azmysql.yml
---
- name: Playbook to Setup MySQL Database 
  hosts: app3
  become: true
  pre_tasks:
    - name: Removing existing DB directory
      file:
        path: /var/lib/mysql
        state: absent
      ignore_errors: true

    - service: name=mariadb state=stopped
      ignore_errors: true

    - yum: name=mariadb-server state=absent
      ignore_errors: true
  roles:
    - azher.mysql
[devops@app1 project]$ ansible-playbook azmysql.yml 

PLAY [Playbook to Setup MySQL Database] **************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app3]

TASK [Removing existing DB directory] ****************************************************************
changed: [app3]

TASK [service] ***************************************************************************************
ok: [app3]

TASK [yum] *******************************************************************************************
changed: [app3]

TASK [azher.mysql : Install [u'mariadb-server', u'mariadb', u'MySQL-python'] Packages] ***************
changed: [app3]

TASK [azher.mysql : Starting mariadb Service] ********************************************************
changed: [app3]

TASK [azher.mysql : Copy template file for MOTD] *****************************************************
changed: [app3]

TASK [azher.mysql : Removing Test DB] ****************************************************************
changed: [app3]

TASK [azher.mysql : Disable anonymous access to DB] **************************************************
changed: [app3]

TASK [azher.mysql : Setting root user password for DB] ***********************************************
changed: [app3]

TASK [azher.mysql : Create Database for User] ********************************************************
changed: [app3]

TASK [azher.mysql : Adding non-root user and assign privileges] **************************************
changed: [app3]

RUNNING HANDLER [azher.mysql : restart_db] ***********************************************************
changed: [app3]

PLAY RECAP *******************************************************************************************
app3                       : ok=13   changed=11   unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible-galaxy search nginx

Found 1331 roles matching your search. Showing first 1000.

 Name                                                    Description
 ----                                                    -----------
 0x0i.prometheus                                         Prometheus - a multi-dimensional time-series 
 0x5a17ed.ansible_role_netbox                            Installs and configures NetBox, a DCIM suite,
 1davidmichael.ansible-role-nginx                        Nginx installation for Linux, FreeBSD and Ope
 1it.sudo                                                Ansible role for managing sudoers
 1nfinitum.php                                           PHP installation role.
 2kloc.trellis-monit                                     Install and configure Monit service in Trelli
 4linuxdevops.web-balancer                               Instalacao e Configuracao do servidor Nginx L
 aadl.docker-nginx-alpine                                Ansible role to manage and run the alpine ngi
 aalaesar.install_nextcloud                              Add a new Nextcloud instance in your infrastr
 aalaesar.upgrade-nextcloud                              Upgrade an Nextcloud instance in your infrast
 AAROC.discourse-sso                                     This is a role to deploy the [Discourse](http
 aaronpederson.ansible-autodeploy                        Simple deployment tool with hooks
 aaronpederson.fluentd                                   Really simple management of data collection f
 aaronpederson.newrelic                                  Application Performance Monitoring
 aaronpederson.nginx                                     nginx is an HTTP and reverse proxy server, a 
 abaez.domain                                            a nginx reverse proxy based on docker
 abtris.nginx-passenger                                  Ansible: nginx-passenger role
 acandid.nginx                                           Install Nginx and ssl and Create Vhost in Deb
 adamaod.Single-Instance-ELK                             Single Instance Elk Stack
 adarnimrod.nginx                                        Install Nginx with common minimal configurati
 adfinis-sygroup.nginx                                   Install and configure nginx with virtualhosts
 adityaprakash_bobby.ansible_role_nginx                  Ansible role for setting up Nginx
 AdnanHodzic.containerized-wordpress                     Deploy & run Docker Compose project for WordP
 AdrianGPrado.coreos-bootstrap                           CoreOS bootstrap
 AdrianGPrado.coreos-nginx                               CoreOS Nginx configurable server
 AdrianGPrado.gitlab                                     GitLab Git web interface
 AdrienKuhn.fail2ban                                     Configure fail2ban jails
 adzumatokaku.nginx_role                                 your description
 AerisCloud.firewall                                     Manage the iptables rules.
 AerisCloud.librato                                      Install and configure the Librato Agent
 AerisCloud.nginx                                        Sets up nginx
 AerisCloud.repos                                        Manage CentOS yum and Debian apt repositories
 afonsog.k8s_nginx_ingress                               Install nginx ingress on k8s
 agios.nginx-unicorn                                     Nginx installation with Unicorn integration
 ahelal.concourse                                        Install Concourse CI
 ahharu.letsencrypt                                      Generate TLS certificates and get them signed
 alainvanhoof.alpine_nginx                               Nginx for Alpine Linux
 alban.andrieu.logstash-settings                         A role for installing logstash configuration
 AlbanAndrieu.ansible_role_ssl_certs                     Generate and/or deploy SSL certificate
 aleguedes1983.web_balancer                              Instalacao e Configuracao do servidor Nginx L
 alessfg.nginx                                           Official Ansible role for NGINX
 alexandresvieira.web-balancer                           Instalacao e Configuracao do servidor Nginx L
 alexey-medvedchikov.php5                                Install and manage PHP5 environment using php
 alexfeig.guacamole                                      Ansible role for installing Apache Guacamole 
 alikins.certbot                                         Installs and configures Certbot (for Let's En
 alikins.collectd_signalfx                               SignalFx Collectd installation for Linux.
 alikins.drupal                                          Deploy or install Drupal on your servers.
 alikins.gitlab                                          GitLab Git web interface
 alikins.htpasswd                                        htpasswd installation and helper role for Lin
 alikins.munin                                           Munin monitoring server for RedHat/CentOS or 
 alikins.nginx                                           Nginx installation for Linux, FreeBSD and Ope
 alikins.passenger                                       Passenger installation for Linux/UNIX.
 alikins.php                                             PHP for RedHat/CentOS/Fedora/Debian/Ubuntu.
 alikins.pimpmylog                                       Pimp my Log installation for Linux
 alikins.varnish                                         Varnish for Linux.
 alisio.web_balancer                                     Instalacao e Configuracao do servidor Nginx L
 alonisser.fail2ban_nginx                                Ansible role that nginx specifc jails for fai
 alvarobacelar.ansible_role_consul                       Consul and Consul Template for Linux.
 alvistack.kubernetes_ingress_nginx                      Ansible Role for NGINX Ingress Controller on 
 alxrem.puppetmaster                                     Install and configure puppetmaster, unicorn a
 amaabca.nginx                                           Base Nginx Configuration for Ubuntu
 amanbolat.ansible_role_certbot                          Installs and configures Certbot (for Let's En
 anasbouzid.systemd                                      Ansible role to manage systemd units
 andpupilo0182.web_balancer                              Instalacao e Configuracao do servidor Nginx L
 andreaswolf.letsencrypt                                 Installs and configures acme-tiny, a lightwei
 andrelohmann.letsencrypt                                ansible galaxy role to install letsencrypt
 andrewrothstein.coreos-bootstrap                        bootstrap coreos hosts to run ansible
 andyceo.nginx                                           Install nginx web server (nginx-naxsi), manag
 Anon0511.goaccess                                       Goaccess Web Logfile analyzer
 ansible.django-gulp-nginx                               Ansible Container Django demo
 ansible.django-template                                 An Ansible Container project template for Dja
 ansible.nginx-container                                 nginx for Ansible Container
 ansiblebit.nginx                                        Configure nginx
 ansible-city.nginx                                      nginx instalation
 ansible-users.nginx                                     Install nginx from official release.
 antarctica.monolith-core                                Core components for provisioning a Monolith i
 antarctica.monolith-python                              System setup for a Python Monolith instance
 Anthony25.kubernetes-ampache                            Install Ampache on Kubernetes
 Anthony25.kubernetes-kube-lego                          Install kube-lego on Kubernetes
 Anthony25.kubernetes-netbox                             Install Netbox on Kubernetes
 Anthony25.kubernetes-nextcloud                          Install Nextcloud on Kubernetes
 Anthony25.kubernetes_nginx_l4_lb                        Install nginx as a L4 load balancer on Kubern
 Anthony25.letsencrypt                                   Generate TLS certificates and get them signed
 antonchernik.nginx                                      Install nginx from nginx.org official reposit
 antongorkovenko.nginx                                   Nginx server installation
 antoniobarbaro.nextcloud                                install or upgrade nextcloud
 antoniobarbaro.nginx                                    Install nginx with fpm-php and essential modu
 ANTS-Framework.linux_defaultsoftware                    Install software using yum or apt
 ANXS.nginx                                              Install and configure Nginx
 aorfanos.drupal                                         Install Drupal 7.63 on Ubuntu
 Aplyca.Nginx                                            Nginx for Debian/Ubuntu.
 arBmind.ansible-rails                                   Out sink-tank for modules and playbooks that 
 arc-ts.consul-agent                                     Installs and manages most aspects of consul i
 arc-ts.docker                                           Installs and Manages the Docker Engine. Has s
 arnobirchler.nginx                                      quick and easy account creater
 arnobirchler.nginx-new-vhost                            quick and easy account creater
 aruhier.ansible_letsencrypt                             Generate TLS certificates and get them signed
 aruhier.ansible_role_kubernetes_ampache                 Install Ampache on Kubernetes
 aruhier.ansible_role_kubernetes_kube_lego               Install kube-lego on Kubernetes
 aruhier.ansible_role_kubernetes_netbox                  Install Netbox on Kubernetes
 aruhier.ansible_role_kubernetes_nextcloud               Install Nextcloud on Kubernetes
 aruhier.kubernetes_nginx_l4_lb                          Install nginx as a L4 load balancer on Kubern
 ashokgelal.mysql                                        Installs MySQL or MariaDB
 atb00ker.ansible_openwisp2                              Official role to install and upgrade openwisp
 atb00ker.matrix-synapse                                 Install matrix-synapse homeserver (Setup Pers
 auciomar.4linux_web_balancer                            Instalacao e Configuracao do servidor Nginx L
 AustinCloudGuru.splunk-forwarder                        Installs the Splunk Forwarder
 auxilincom.drone                                        Drone CI deployment with Github integration a
 avidsapp.ansible_role_containerized_wordpress           Deploy & run Docker Compose project for WordP
 axelitus.nginx                                          An ansible role to provision Nginx in a serve
 aya.docker                                              An ansible role to install docker
 azavea.letsencrypt                                      Installs and configures acme-tiny, a lightwei
 azavea.nginx                                            An Ansible role to install Nginx.
 azumakuniyuki.ar-munin-cron-pkg                         Build and install munin-cron from rpm
 barbarabranco.webbalancer_ansible                       Instalacao e Configuracao do servidor Nginx L
 barm0leykin.goaccess                                    Visual web log analizer for nginx goaccess
 barm0leykin.iptables                                    Visual web log analizer for nginx goaccess
 barm0leykin.nginx                                       simple nginx role
 bas-ansible-roles-collection.nginx                      Installs and configures Nginx web-server
 bas-ansible-roles-collection.php5-nginx                 Bridging role to use PHP 5 with Nginx using P
 bas-ansible-roles-collection.php7-nginx                 Bridging role to use PHP 7 with Nginx using P
 bas-ansible-roles-collection.tomcat8                    Downloads, installs and configures Apache Tom
 bassinator.nginx                                        Role to setup nginx server
 bastly.nginx                                            Nginx installation for Linux/UNIX.
 bbaassssiiee.ansible_role_gitlab                        GitLab Git web interface
 bbaassssiiee.ansible_role_nginx_1                       Ansible role to install and manage nginx conf
 bbatsche.nginx                                          Install and configure Nginx and Phusion Passe
 bbatsche.Node                                           Install Node.js through NVM and set up an Ngi
 bbatsche.PHP                                            Install Phpenv, PHP, and set up a site in Ngi
 bbatsche.Python                                         Create an Nginx site running either Python 2.
 bbatsche.Ruby                                           Install Rbenv, Ruby, and create an Nginx site
 bbranco89.web_balancer_ansible                          Instalacao e Configuracao do servidor Nginx L
 bdellegrazie.ansible_role_owasp_dependency_check_mirror Role to manage an OWASP Dependency Check serv
 bdellegrazie.nginx_exporter                             Role to install Prometheus Nginx Exporter
 bearandgiraffe.nginx                                    Installs and configures nginx
 bearandgiraffe.postgresql                               Installs and configures PostgreSQL
 bearandgiraffe.redis                                    Installs and configures Redis
 ben-le.awx                                              Quick and easy to deployment AWX on Debian an
 ben-le.awx_nginx                                        Install Nginx with SSL for AWX
 bennojoy.nginx                                          ansible role nginx 
 bernhardf1.ansible_openwisp2                            Official role to install and upgrade openwisp
 bery.ghost                                              Role for installing Ghost, a blogging platfor
 betrcode.aws_asg                                        This role creates a AWS AutoScalingGroup and 
 bihealth.nginx                                          This Ansible role performs an NGINX setup wit
 binaryplease.ansible_nginx                              your role description
 biomancer.letsencrypt-webroot                           Letsencrypt installation and config with web-
 bjoas.letsencrypt                                       A role to automate LetsEncrypt certificates.
 bjoernalbers.gollum                                     Install and manage Gollum Wikis on macOS
 blazingbarons.nginx                                     Ansible Nginx Role
 bluestar.nginx                                          Ansible role for NGINX Open Source
 bngsudheer.redmine                                      Install Redmine on CentOS
 bpresles.nginx                                          Nginx installation for Linux, FreeBSD and Ope
 bpresles.php                                            PHP for RedHat/CentOS/Fedora/Debian/Ubuntu.
 bpresles.varnish                                        Varnish for Linux.
 brachetti.ansible_drone                                 Drone CI deployment with Github integration a
 bradtreloar.ansible_role_drupal                         Deploy or install Drupal on your servers.
 brunopisca.web_balancer                                 Instalacao e Configuracao do servidor Nginx L
 brunosoareswl.web_balancer                              Instalacao e Configuracao do servidor Nginx L
 buluma.ansible-role-certbot                             Installs and configures Certbot (for Let's En
 buluma.logrotate                                        Installs and configures logrotate
 buluma.matrix-synapse-auto-deploy                       Ansible playbook for managing a matrix node w
 bytepark.dehydrated                                     Ansible Role to install dehydrated
 bytepark.nginx                                          Ansible Role to install and configure nginx
 caktus.tequila-nginx                                    Django project deployment -- nginx
 calvinchengx.nginx                                      A simple nginx ansible role
 calvinchengx.nginx-apps                                 Ansible role for creating nginx apps
 cans.nginx_site_manage                                  A Role to manage nginx "sites" (virtual hosts
 carlos22.nginx                                          This ansible role manages installation and co
 CarlosLongarela.nginx                                   Nginx install and vhosts configuration with h
 cchurch.letsencrypt                                     Create SSL certificates with Let's Encrypt us
 cdosborn.tls-cert                                       deploys TLS certificate, optionally creates s
 cdriehuys.nginx                                         Install and configure NGINX.
 cel8029.web-balancer                                    Instalacao e Configuracao do servidor Nginx L
 chalasr.ansible-role-apt                                Handle apt
 chasinglogic.podman                                     Manage services and containers with podman
 chauanhtuandl.graylog                                   Install and configure Graylog log management.
 chauanhtuandl.nginx                                     Nginx installation for Linux, FreeBSD and Ope
 ChengLong.nginx-passenger                               Install nginx with passenger on Debian/Ubuntu
 china-awifi.playbooks                                   Ansible playbook collection that have been wr
 chrisdodds.sumologic-agent                              Installs the Sumo Logic collector agent on RH
 chrisro89.ansible_role_docker_nginx_reverse_proxy       Install docker NGINX-Reverse-Proxy with autom
 chrisro89.galaxywebuirole                               Install docker NGINX-Reverse-Proxy with autom
 ChristopherDavenport.ansible-role-nginx                 
 christophershoemaker.grafana                            Installs and setup Grafana metrics dashboard
 chusiang.php7                                           Deploy PHP 7 (php-fpm) for nginx on Ubuntu, D
 chusiang.testlink                                       Deploy TestLink with Nginx, PHP 7 (php-fpm) a
 cimon-io.nginx                                          Install and configure nginx
 cleberjsantos.varnish                                   Varnish for Linux
 clouddrove.ansible_role_docker_nginx                    This ansible role is used to install Nginx Se
 clouddrove.ansible_role_nginx                           This ansible role is used to install Nginx Se
 cloudify.nginx                                          Install and configure Nginx
 cloudposse.datadog                                      Install Datadog agent and configure checks
 cloudweeb.alerta                                        Ansible role to install Alerta
 cloudweeb.librenms                                      LibreNMS Installation Role
 cloudweeb.nginx_exporter                                Install Nginx Exporter Prometheus
 cloudweeb.php                                           Install PHP on Linux server
 clusterapps.gitlab                                      GitLab
 clusterfrak.nginx                                       Role to install Nginx
 clutterbox.dehydrated                                   Install, confgure and run dehydrated to get L
 coaxial.docker-proxy                                    Docker reverse proxy for Docker containers
 coaxial.healthchecks                                    deploy your own healthchecks.io
 CoffeeITWorks.burpui_server                             ansible role to deploy and maintain burpui wi
 coglinev3.ansible_bender                                Installs ansible-bender, a tool which bends c
 colstrom.nginx                                          nginx is an HTTP and reverse proxy server, a 
 colybri.php                                             Deploy for install or configure any php versi
 computerlyrik.nginx                                     NGinx as easy dockerized proxy
 consensus.matomo                                        Installs Matomo for Web site analytics.
 constrict0r.basik                                       Setup basic Debian-like systems.
 constrict0r.constructor                                 Setup Debian systems.
 constrict0r.desktop                                     Debian-like systems desktop configuration.
 constrict0r.develbase                                   Apply basic developer configuration.
 constrict0r.develmicro                                  Apply microcontroller developer configuration
 constrict0r.develpy                                     Apply python developer configuration.
 constrict0r.devels                                      Apply developer configuration.
 constrict0r.madvillain                                  Apply ultimate madvillain configuration.
 constrict0r.servicez                                    Enable and start services.
 coopdevs.certbot_nginx                                  free software for Social and Solidarity Econo
 coopdevs.monitoring_role                                Install Prometheus and Loki exporters to moni
 CorbanR.letsencrypt                                     Generated certificates via lets encrypt (Stan
 coregen.ircstack                                        This role is used to install Weechat, and use
 cornfeedhobo.nginx                                      Install and configure nginx
 cowops.debian-nginx                                     Install Nginx for debian system
 craigmj.nginxproxy                                      A role to configure a proxy on nginx
 criecm.netmagis                                         netmagis DHCP/DNS/... web frontend
 criecm.nginx                                            nginx webserver and sites
 criecm.php-fpm                                          php-fpm server and webapps
 crisp.aws_cloudformation_asg                            This role creates a AWS AutoScalingGroup and 
 crushlovely.nginx                                       NGINX for Ubuntu 12.04LTS or greater
 ctorgalson.nextcloud_docker                             An Ansible role for installing Nextcloud usin
 cw-ansible.cw-letsencrypt                               Full automated Let's Encrypt certificate gene
 cypreess.nginx                                          Installing nginx role
 CyVerse-Ansible.gateone-server                          GateOne Server
 CyVerse-Ansible.tls-cert                                deploys TLS certificate, optionally creates s
 dagman62.nginx_lb                                       nginx load balancer for ubuntu bionic
 dalbani.coreos-bootstrap                                CoreOS bootstrap
 Dalee.bootstrap                                         Bootstrap vagrant machine, install nginx, som
 Dalee.bootstrap-docker                                  Bootstrap docker machine, install nginx, some
 damko.nginx-debian                                      Install and configure (optionally) Nginx on D
 danie1cohen.nginx                                       An ansible ready nginx config
 daniel_serpro.web_balancer                              Instalacao e Configuracao do servidor Nginx L
 daniloc26.web_balancer                                  Instalacao e Configuracao do servidor Nginx L
 danvaida.letsencrypt                                    Obtains TLS certificates through ACME from Le
 DataDog.datadog                                         Install Datadog agent and configure checks
 datadog-galaxy.nginx                                    Nginx provision role
 datadog-galaxy.nodejs                                   Nginx provision role
 davidalger.certbot                                      Installs Certbot (Let's Encrypt) for RHEL/Cen
 davidalger.nginx                                        Installs nginx service from EPEL RPMs on RHEL
 davidalger.stackdriver                                  Install the Stackdriver agent and configure i
 dblencowe.nginx-php7                                    Install a basic Nginx / PHP7 setup
 decayofmind.bluegreen-docker                            Blue-green deployment concept with Docker con
 deekayen.jira_software                                  Install Atlassian Jira software.
 deimosfr.graphite                                       graphite
 deimosfr.kibana                                         Ansible playbook for Kibana
 deimosfr.nginx                                          Ansible playbook for Nginx
 deimosfr.sendy                                          Ansible role to deploy Sendy
 delphix.package-caching-proxy                           Install a collection of caching proxy solutio
 derekmerck.nginx_docker                                 Configure and run a [Nginx](https://https://w
 devgateway.pacemaker                                    Configure Pacemaker cluster
 devops.nginx                                            Installs and Configures Nginx.
 devopsstore.nginx                                       Nginx installation for Linux, FreeBSD and Ope
 devopsstore.php                                         PHP (5.4, 5.5, 5.6, 7.0, 7.1) using repositor
 dev-sec.nginx-hardening                                 This Ansible role provides secure nginx confi
 dgnest.nginx                                            Ansible role to install nginx
 didaktikm.ansible_nginx                                 Role for Nginx on custom port 80:80
 diegorodrigues87.graylog_ansible_role                   Install and configure Graylog log management.
 dieswaytoofast.nginx                                    Install and use nginx in docker
 DigitalBackstage.munin-fcgi                             Setup munin dynazoom graphs with spawn-fcgi.
 dinesh-izap.nginx                                       Install Nginx package from source.
 diodonfrost.logrotate                                   Ansible role for manage logrotate
 djangoxv.awx_debian                                     Bypass docker to install AWX on Debian hosts
 djzager.nginx_k8s                                       Manage nginx application in Kubernetes|OpenSh
 dkalamkar.testrole                                      Nginx installation for Linux, FreeBSD and Ope
 dlcoder.nginx                                           Ansible role for installing and configure ngi
 dmitrybelyakov.localcloud-nginx                         This role will install nginx and allow you to
 dmitryromanenko.certbot_dns                             Make certificates with certbot and DNS challe
 dokku_bot.ansible_dokku                                 This Ansible role helps install Dokku on Debi
from installing Dokku, it also provides various modules that can be
used to interface with dokku from your own Ansible playbooks.
 Dolbager.elk                                            ELK configuration
 donat-b.nginx                                           NGiNX
 dorianpula.nginx-uwsgi-supervisor                       An elegant NGINX, UWSGI and supervisor Ansibl
 douglasmsi.webbalance_ansible                           Instalacao e Configuracao do servidor Nginx L
[devops@app1 project]$ ansible-galaxy search jenkins

Found 318 roles matching your search:

 Name                                                                  Description
 ----                                                                  -----------
 AAROC.CODE-RADE-build-containers                                      Describe your awesome applicati
 AAROC.CODE-RADE-container                                             CODE-RADE build containers
 AAROC.CODE-RADE-jenkins-role                                          Role to deploy and configure Je
 acceleanu.jenkins                                                     Jenkins CI
 aem_design.jenkins                                                    Setup jenkins in your environme
 AerisCloud.repos                                                      Manage CentOS yum and Debian ap
 afonsog.k8s_jenkins                                                   your description
 ajeleznov.install-jenkins                                             Installs the Jenkins automation
 akry.jenkins                                                          jenkins installer
 alban.andrieu.jenkins-swarm                                           A role for installing jenkins-s
 alban.andrieu.logstash-settings                                       A role for installing logstash 
 alban.andrieu.zap                                                     A role for installing zap
 alban.andrieu.zfs                                                     A role for installing zfs
 AlbanAndrieu.ansible-jenkins-slave-docker                             A role for creating docker imag
 AlbanAndrieu.ansible-nabla                                            A role for gathering nabla infr
 AlbanAndrieu.ansible-workstation                                      A role for installing workstati
 AlbanAndrieu.jenkins_slave                                            A role for installing jenkins-s
 AlbanAndrieu.selenium                                                 A role for installing selenium
 AlbanAndrieu.xvbf                                                     A role for installing xvbf
 aldavud.ansible-role-jenkins2                                         Jenkins2
 alexagranov.jenkins-oracle-java                                       Jenkins CI
 alikins.jenkins                                                       Jenkins CI
 AlphaNodes.backup                                                     Run daily backups for files, My
 amitpatole.ansible_jenkins                                            Jenkins Installation using Ansi
 amtega.artifact                                                       Download several kinds or artif
 anmolnagpal.ansible_jenkins                                           An Ansible role for deploy Jenk
 ansible-ThoTeam.nexus3-oss                                            Nexus Repository Manager 3.x (S
 antonchernik.jenkins                                                  Install Jenkins
 arjunkapur95.jenkinsrole                                              Jenkins CI
 AsianChris.jenkins                                                    jenkins installation
 avanov.jenkins                                                        Ansible role for Jenkins CI
 avinash6784.jenkins                                                   Ansible role to install Jenkins
 awasilyev.jenkins-container                                           Ansible Container role that cre
 azavea.jenkins                                                        An Ansible role for installing 
 Azulinho.azulinho-jenkins-fully-baked                                 Ansible role for deploying a fu
 Azulinho.azulinho-jenkins-job-builder                                 Ansible role for install the py
[devops@app1 project]$ ll
total 128
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
-rw-rw-r--. 1 devops devops  215 Feb  5 08:55 inventory
drwxrwxrwx. 2 devops devops   20 Feb  5 09:43 dynamic
-rw-rw-r--. 1 devops devops 1842 Feb  5 10:18 static.yml
-rw-rw-r--. 1 devops devops   49 Feb  5 10:40 http_vars.yml
-rw-rw-r--. 1 devops devops  286 Feb  5 10:44 http_tasks.yml
-rw-rw-r--. 1 devops devops   40 Feb  5 10:47 fw_vars.yml
-rw-rw-r--. 1 devops devops  170 Feb  5 10:49 fw_tasks.yml
-rw-rw-r--. 1 devops devops  208 Feb  5 10:54 master.yml
-rw-rw-r--. 1 devops devops   98 Feb  5 11:06 app.yml
-rw-rw-r--. 1 devops devops   73 Feb  6 03:17 r.yml
drwxrwxr-x. 3 devops devops   19 Feb  6 03:17 get_facts
-rw-rw-r--. 1 devops devops   93 Feb  6 03:37 1.yml
-rw-rw-r--. 1 devops devops  250 Feb  6 04:38 hosts.j2
-rw-rw-r--. 1 devops devops  181 Feb  6 05:09 hosts.yml
-rw-rw-r--. 1 devops devops  242 Feb  6 05:11 ansible.cfg
drwxrwxr-x. 3 devops devops   25 Feb  6 05:25 roles
-rw-rw-r--. 1 devops devops  387 Feb  6 06:48 azmysql.yml
[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
#inventory=dynamic
remote_user=devops
ask_pass=False
vault_password_file=.myvaultpassword.txt
forks=1
roles_path=roles

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ ansible-galaxy install geerlingguy.nginx
- downloading role 'nginx', owned by geerlingguy
- downloading role from https://github.com/geerlingguy/ansible-role-nginx/archive/2.7.0.tar.gz
- extracting geerlingguy.nginx to /home/devops/project/roles/geerlingguy.nginx
- geerlingguy.nginx (2.7.0) was installed successfully
[devops@app1 project]$ ansible-galaxy list
# /home/devops/project/roles
- azher.mysql, (unknown version)
- geerlingguy.nginx, 2.7.0
[devops@app1 project]$ ll roles/
total 0
drwxrwxr-x. 10 devops devops 154 Feb  6 05:16 azher.mysql
drwxrwxr-x.  9 devops devops 177 Feb  6 07:26 geerlingguy.nginx
[devops@app1 project]$ cd roles/geerlingguy.nginx/
[devops@app1 geerlingguy.nginx]$ tree
.
|-- defaults
|   `-- main.yml
|-- handlers
|   `-- main.yml
|-- LICENSE
|-- meta
|   `-- main.yml
|-- molecule
|   `-- default
|       |-- molecule.yml
|       |-- playbook.yml
|       `-- yaml-lint.yml
|-- README.md
|-- tasks
|   |-- main.yml
|   |-- setup-Archlinux.yml
|   |-- setup-Debian.yml
|   |-- setup-FreeBSD.yml
|   |-- setup-OpenBSD.yml
|   |-- setup-RedHat.yml
|   |-- setup-Ubuntu.yml
|   `-- vhosts.yml
|-- templates
|   |-- nginx.conf.j2
|   |-- nginx.repo.j2
|   `-- vhost.j2
`-- vars
    |-- Archlinux.yml
    |-- Debian.yml
    |-- FreeBSD.yml
    |-- OpenBSD.yml
    `-- RedHat.yml

8 directories, 24 files
[devops@app1 geerlingguy.nginx]$ 
[devops@app1 geerlingguy.nginx]$ vi tasks/main.yml 
[devops@app1 geerlingguy.nginx]$ vi tasks/setup-RedHat.yml 
[devops@app1 geerlingguy.nginx]$ vi vars/RedHat.yml 
[devops@app1 geerlingguy.nginx]$ vi defaults/main.yml 
[devops@app1 geerlingguy.nginx]$ vi meta/
.galaxy_install_info  main.yml              
[devops@app1 geerlingguy.nginx]$ vi meta/
.galaxy_install_info  main.yml              
[devops@app1 geerlingguy.nginx]$ vi meta/main.yml 
[devops@app1 geerlingguy.nginx]$ vi README.md 
[devops@app1 geerlingguy.nginx]$ cd ../..
[devops@app1 project]$ vi nginx.yml
[devops@app1 project]$ cat nginx.yml
---
- name: Play for NGINX from Ansible Galaxy
  hosts: webserver
  become: true
  pre_task:
    - service: name=httpd state=stopped

  roles:
    - geerlingguy.nginx

  post_tasks:
    - debug: msg="NGINX Installed Successfully"
[devops@app1 project]$ ansible-playbook -C nginx.yml
ERROR! 'pre_task' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/nginx.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: Play for NGINX from Ansible Galaxy
  ^ here

[devops@app1 project]$ vi nginx.yml
[devops@app1 project]$ ansible-playbook nginx.yml --syntax-check

playbook: nginx.yml
[devops@app1 project]$ ansible-playbook nginx.yml 

PLAY [Play for NGINX from Ansible Galaxy] ************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [service] ***************************************************************************************
changed: [app2]

TASK [geerlingguy.nginx : Include OS-specific variables.] ********************************************
ok: [app2]

TASK [geerlingguy.nginx : Define nginx_user.] ********************************************************
ok: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
included: /home/devops/project/roles/geerlingguy.nginx/tasks/setup-RedHat.yml for app2

TASK [geerlingguy.nginx : Enable nginx repo.] ********************************************************
changed: [app2]

TASK [geerlingguy.nginx : Ensure nginx is installed.] ************************************************
changed: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : Remove default nginx vhost config file (if configured).] *******************
skipping: [app2]

TASK [geerlingguy.nginx : Ensure nginx_vhost_path exists.] *******************************************
ok: [app2]

TASK [geerlingguy.nginx : Add managed vhost config files.] *******************************************

TASK [geerlingguy.nginx : Remove managed vhost config files.] ****************************************

TASK [geerlingguy.nginx : Remove legacy vhosts.conf file.] *******************************************
ok: [app2]

TASK [geerlingguy.nginx : Copy nginx configuration in place.] ****************************************
changed: [app2]

TASK [geerlingguy.nginx : Ensure nginx service is running as configured.] ****************************
changed: [app2]

RUNNING HANDLER [geerlingguy.nginx : reload nginx] ***************************************************
changed: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "msg": "NGINX Installed Successfully"
}

PLAY RECAP *******************************************************************************************
app2                       : ok=13   changed=6    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   

[devops@app1 project]$ cat nginx.yml
---
- name: Play for NGINX from Ansible Galaxy
  hosts: webserver
  become: true
  pre_tasks:
    - service: name=httpd state=stopped

  roles:
    - geerlingguy.nginx

  post_tasks:
    - debug: msg="NGINX Installed Successfully"
[devops@app1 project]$ vi git.yml
[devops@app1 project]$ cat git.yml
---
- src: https://github.com/harpreetsingh123/role2.git
  name: azher.role1
  scm: git
  version: master
[devops@app1 project]$ ansible-playbook git.yml --syntax-check
ERROR! 'scm' is not a valid attribute for a Play

The error appears to be in '/home/devops/project/git.yml': line 2, column 3, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- src: https://github.com/harpreetsingh123/role2.git
  ^ here

[devops@app1 project]$ #ansible-galaxy install geerlingguy.nginx
[devops@app1 project]$ ##ansible-galaxy install -r g
[devops@app1 project]$ mv git.yml req.yml
[devops@app1 project]$ #ansible-galaxy install -r req.yml -p roles/
[devops@app1 project]$ git --version
-bash: git: command not found
[devops@app1 project]$ yum install -y git
Failed to set locale, defaulting to C
Loaded plugins: fastestmirror
You need to be root to perform this command.
[devops@app1 project]$ sudo yum install -y git
Failed to set locale, defaulting to C
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
epel/x86_64/metalink                                                           | 6.4 kB  00:00:00     
 * base: centos.excellmedia.net
 * epel: ftp.jaist.ac.jp
 * extras: centos.excellmedia.net
 * updates: centos.excellmedia.net
base                                                                           | 3.6 kB  00:00:00     
epel                                                                           | 5.4 kB  00:00:00     
extras                                                                         | 2.9 kB  00:00:00     
updates                                                                        | 2.9 kB  00:00:00     
(1/3): epel/x86_64/updateinfo                                                  | 1.0 MB  00:00:00     
(2/3): updates/7/x86_64/primary_db                                             | 6.7 MB  00:00:01     
(3/3): epel/x86_64/primary_db                                                  | 6.9 MB  00:00:02     
Resolving Dependencies
--> Running transaction check
---> Package git.x86_64 0:1.8.3.1-21.el7_7 will be installed
--> Processing Dependency: perl-Git = 1.8.3.1-21.el7_7 for package: git-1.8.3.1-21.el7_7.x86_64
--> Processing Dependency: perl(Term::ReadKey) for package: git-1.8.3.1-21.el7_7.x86_64
--> Processing Dependency: perl(Git) for package: git-1.8.3.1-21.el7_7.x86_64
--> Processing Dependency: perl(Error) for package: git-1.8.3.1-21.el7_7.x86_64
--> Running transaction check
---> Package perl-Error.noarch 1:0.17020-2.el7 will be installed
---> Package perl-Git.noarch 0:1.8.3.1-21.el7_7 will be installed
---> Package perl-TermReadKey.x86_64 0:2.30-20.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

======================================================================================================
 Package                     Arch              Version                       Repository          Size
======================================================================================================
Installing:
 git                         x86_64            1.8.3.1-21.el7_7              updates            4.4 M
Installing for dependencies:
 perl-Error                  noarch            1:0.17020-2.el7               base                32 k
 perl-Git                    noarch            1.8.3.1-21.el7_7              updates             55 k
 perl-TermReadKey            x86_64            2.30-20.el7                   base                31 k

Transaction Summary
======================================================================================================
Install  1 Package (+3 Dependent packages)

Total download size: 4.5 M
Installed size: 22 M
Downloading packages:
(1/4): perl-TermReadKey-2.30-20.el7.x86_64.rpm                                 |  31 kB  00:00:00     
(2/4): perl-Error-0.17020-2.el7.noarch.rpm                                     |  32 kB  00:00:00     
(3/4): perl-Git-1.8.3.1-21.el7_7.noarch.rpm                                    |  55 kB  00:00:00     
(4/4): git-1.8.3.1-21.el7_7.x86_64.rpm                                         | 4.4 MB  00:00:01     
------------------------------------------------------------------------------------------------------
Total                                                                 3.6 MB/s | 4.5 MB  00:00:01     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : 1:perl-Error-0.17020-2.el7.noarch                                                  1/4 
  Installing : perl-TermReadKey-2.30-20.el7.x86_64                                                2/4 
  Installing : perl-Git-1.8.3.1-21.el7_7.noarch                                                   3/4 
  Installing : git-1.8.3.1-21.el7_7.x86_64                                                        4/4 
  Verifying  : git-1.8.3.1-21.el7_7.x86_64                                                        1/4 
  Verifying  : 1:perl-Error-0.17020-2.el7.noarch                                                  2/4 
  Verifying  : perl-Git-1.8.3.1-21.el7_7.noarch                                                   3/4 
  Verifying  : perl-TermReadKey-2.30-20.el7.x86_64                                                4/4 

Installed:
  git.x86_64 0:1.8.3.1-21.el7_7                                                                       

Dependency Installed:
  perl-Error.noarch 1:0.17020-2.el7                   perl-Git.noarch 0:1.8.3.1-21.el7_7              
  perl-TermReadKey.x86_64 0:2.30-20.el7              

Complete!
[devops@app1 project]$ git --version
git version 1.8.3.1
[devops@app1 project]$ #
[devops@app1 project]$ 
[devops@app1 project]$ ansible-galaxy install -r req.yml -p roles/
- extracting azher.role1 to /home/devops/project/roles/azher.role1
- azher.role1 (master) was installed successfully
[devops@app1 project]$ ll roles/azher.*
roles/azher.mysql:
total 4
drwxrwxr-x. 2 devops devops    6 Feb  6 05:16 files
-rw-rw-r--. 1 devops devops 1328 Feb  6 05:16 README.md
drwxrwxr-x. 2 devops devops   22 Feb  6 05:16 defaults
drwxrwxr-x. 2 devops devops   22 Feb  6 06:25 handlers
drwxrwxr-x. 2 devops devops   22 Feb  6 06:27 tasks
drwxrwxr-x. 2 devops devops   21 Feb  6 06:30 templates
drwxrwxr-x. 2 devops devops   22 Feb  6 06:30 vars
drwxrwxr-x. 2 devops devops   22 Feb  6 06:34 meta
drwxrwxr-x. 2 devops devops   39 Feb  6 06:39 tests

roles/azher.role1:
total 4
-rw-rw-r--. 1 devops devops 1328 Aug 28 04:13 README.md
drwxrwxr-x. 2 devops devops   22 Feb  6 09:09 handlers
drwxrwxr-x. 2 devops devops   22 Feb  6 09:09 defaults
drwxrwxr-x. 2 devops devops   22 Feb  6 09:09 vars
drwxrwxr-x. 2 devops devops   39 Feb  6 09:09 tests
drwxrwxr-x. 2 devops devops   22 Feb  6 09:09 tasks
drwxrwxr-x. 2 devops devops   50 Feb  6 09:09 meta
[devops@app1 project]$ ansible-galaxy list
# /home/devops/project/roles
- azher.mysql, (unknown version)
- geerlingguy.nginx, 2.7.0
- azher.role1, master
[devops@app1 project]$ cat req.yml 
---
- src: https://github.com/harpreetsingh123/role2.git
  name: azher.role1
  scm: git
  version: master
[devops@app1 project]$ tree roles/azher.role1/
roles/azher.role1/
|-- defaults
|   `-- main.yml
|-- handlers
|   `-- main.yml
|-- meta
|   `-- main.yml
|-- README.md
|-- tasks
|   `-- main.yml
|-- tests
|   |-- inventory
|   `-- test.yml
`-- vars
    `-- main.yml

6 directories, 8 files
[devops@app1 project]$ ls /usr/share/ansible/roles/
[devops@app1 project]$ sudo yum install rhel-system-roles -y
Failed to set locale, defaulting to C
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: centos.excellmedia.net
 * epel: mirrors.aliyun.com
 * extras: centos.excellmedia.net
 * updates: centos.excellmedia.net
Resolving Dependencies
--> Running transaction check
---> Package rhel-system-roles.noarch 0:1.0-8.el7 will be installed
--> Finished Dependency Resolution

Dependencies Resolved

======================================================================================================
 Package                        Arch                Version                 Repository           Size
======================================================================================================
Installing:
 rhel-system-roles              noarch              1.0-8.el7               extras              115 k

Transaction Summary
======================================================================================================
Install  1 Package

Total download size: 115 k
Installed size: 542 k
Downloading packages:
rhel-system-roles-1.0-8.el7.noarch.rpm                                         | 115 kB  00:00:00     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Installing : rhel-system-roles-1.0-8.el7.noarch                                                 1/1 
  Verifying  : rhel-system-roles-1.0-8.el7.noarch                                                 1/1 

Installed:
  rhel-system-roles.noarch 0:1.0-8.el7                                                                

Complete!
[devops@app1 project]$ #sudo yum install rhel-system-roles -y
[devops@app1 project]$ ls /usr/share/ansible/roles/
linux-system-roles.kdump    linux-system-roles.timesync  rhel-system-roles.selinux
linux-system-roles.network  rhel-system-roles.kdump      rhel-system-roles.timesync
linux-system-roles.postfix  rhel-system-roles.network
linux-system-roles.selinux  rhel-system-roles.postfix
[devops@app1 project]$ ll /usr/share/ansible/roles/
total 0
lrwxrwxrwx.  1 root root  25 Feb  6 09:27 linux-system-roles.postfix -> rhel-system-roles.postfix
lrwxrwxrwx.  1 root root  25 Feb  6 09:27 linux-system-roles.network -> rhel-system-roles.network
lrwxrwxrwx.  1 root root  23 Feb  6 09:27 linux-system-roles.kdump -> rhel-system-roles.kdump
lrwxrwxrwx.  1 root root  26 Feb  6 09:27 linux-system-roles.timesync -> rhel-system-roles.timesync
lrwxrwxrwx.  1 root root  25 Feb  6 09:27 linux-system-roles.selinux -> rhel-system-roles.selinux
drwxr-xr-x.  9 root root 137 Feb  6 09:27 rhel-system-roles.kdump
drwxr-xr-x.  8 root root 158 Feb  6 09:27 rhel-system-roles.network
drwxr-xr-x.  6 root root  95 Feb  6 09:27 rhel-system-roles.postfix
drwxr-xr-x.  8 root root 119 Feb  6 09:27 rhel-system-roles.selinux
drwxr-xr-x. 11 root root 168 Feb  6 09:27 rhel-system-roles.timesync
[devops@app1 project]$ ll /usr/share/ansible/roles/rhel-system-roles.timesync/
COPYING    examples/  library/   README.md  templates/ vars/      
defaults/  handlers/  meta/      tasks/     tests/     
[devops@app1 project]$ ll /usr/share/ansible/roles/rhel-system-roles.timesync/
total 16
-rw-r--r--. 1 root root 1057 Jun  3  2019 COPYING
drwxr-xr-x. 2 root root    6 Sep 15 14:06 examples
-rw-r--r--. 1 root root 4320 Sep 15 14:06 README.md
drwxr-xr-x. 2 root root   22 Feb  6 09:27 defaults
drwxr-xr-x. 2 root root   22 Feb  6 09:27 handlers
drwxr-xr-x. 2 root root   22 Feb  6 09:27 meta
drwxr-xr-x. 2 root root   34 Feb  6 09:27 library
drwxr-xr-x. 2 root root   22 Feb  6 09:27 tasks
drwxr-xr-x. 2 root root  201 Feb  6 09:27 templates
drwxr-xr-x. 2 root root   22 Feb  6 09:27 vars
drwxr-xr-x. 4 root root 4096 Feb  6 09:27 tests
[devops@app1 project]$ ll /usr/share/ansible/roles/rhel-system-roles.timesync/tasks/
total 8
-rw-r--r--. 1 root root 5976 Jun  3  2019 main.yml
[devops@app1 project]$ vi /usr/share/ansible/roles/rhel-system-roles.timesync/tasks/main.yml 
[devops@app1 project]$ ansible-galaxy list
# /home/devops/project/roles
- azher.mysql, (unknown version)
- geerlingguy.nginx, 2.7.0
- azher.role1, master
[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ cat ansible.cfg | grep roles
roles_path=roles:/usr/share/ansible/roles
[devops@app1 project]$ ansible-galaxy list
# /home/devops/project/roles
- azher.mysql, (unknown version)
- geerlingguy.nginx, 2.7.0
- azher.role1, master
# /usr/share/ansible/roles
- linux-system-roles.kdump, (unknown version)
- linux-system-roles.network, (unknown version)
- linux-system-roles.postfix, (unknown version)
- linux-system-roles.selinux, (unknown version)
- linux-system-roles.timesync, (unknown version)
- rhel-system-roles.kdump, (unknown version)
- rhel-system-roles.network, (unknown version)
- rhel-system-roles.postfix, (unknown version)
- rhel-system-roles.selinux, (unknown version)
- rhel-system-roles.timesync, (unknown version)
[devops@app1 project]$ vi /usr/share/ansible/roles/rhel-system-roles.timesync/tasks/main.yml 
[devops@app1 project]$ 
[devops@app1 project]$ vi /usr/share/ansible/roles/rhel-system-roles.timesync/
COPYING    examples/  library/   README.md  templates/ vars/      
defaults/  handlers/  meta/      tasks/     tests/     
[devops@app1 project]$ vi /usr/share/ansible/roles/rhel-system-roles.timesync/README.md 
[devops@app1 project]$ vi ntp.yml
[devops@app1 project]$ nano ntp.yml
-bash: nano: command not found
[devops@app1 project]$ vi ntp.yml
[devops@app1 project]$ #ansible-gala ntp.yml
[devops@app1 project]$ #ansible-galaxy install -r req.yml -p roles/
[devops@app1 project]$ cat req.yml 
---
- src: https://github.com/harpreetsingh123/role2.git
  name: azher.role1
  scm: git
  version: master
[devops@app1 project]$ #cat req.yml 
[devops@app1 project]$ ls -ltr
total 140
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
-rw-rw-r--. 1 devops devops  215 Feb  5 08:55 inventory
drwxrwxrwx. 2 devops devops   20 Feb  5 09:43 dynamic
-rw-rw-r--. 1 devops devops 1842 Feb  5 10:18 static.yml
-rw-rw-r--. 1 devops devops   49 Feb  5 10:40 http_vars.yml
-rw-rw-r--. 1 devops devops  286 Feb  5 10:44 http_tasks.yml
-rw-rw-r--. 1 devops devops   40 Feb  5 10:47 fw_vars.yml
-rw-rw-r--. 1 devops devops  170 Feb  5 10:49 fw_tasks.yml
-rw-rw-r--. 1 devops devops  208 Feb  5 10:54 master.yml
-rw-rw-r--. 1 devops devops   98 Feb  5 11:06 app.yml
-rw-rw-r--. 1 devops devops   73 Feb  6 03:17 r.yml
drwxrwxr-x. 3 devops devops   19 Feb  6 03:17 get_facts
-rw-rw-r--. 1 devops devops   93 Feb  6 03:37 1.yml
-rw-rw-r--. 1 devops devops  250 Feb  6 04:38 hosts.j2
-rw-rw-r--. 1 devops devops  181 Feb  6 05:09 hosts.yml
-rw-rw-r--. 1 devops devops  387 Feb  6 06:48 azmysql.yml
-rw-rw-r--. 1 devops devops  231 Feb  6 07:36 nginx.yml
-rw-rw-r--. 1 devops devops  106 Feb  6 09:05 req.yml
drwxrwxr-x. 5 devops devops   69 Feb  6 09:09 roles
-rw-rw-r--. 1 devops devops  267 Feb  6 09:30 ansible.cfg
-rw-rw-r--. 1 devops devops  223 Feb  6 09:35 ntp.yml
[devops@app1 project]$ cat nginx.yml 
---
- name: Play for NGINX from Ansible Galaxy
  hosts: webserver
  become: true
  pre_tasks:
    - service: name=httpd state=stopped

  roles:
    - geerlingguy.nginx

  post_tasks:
    - debug: msg="NGINX Installed Successfully"
[devops@app1 project]$ cat ntp.yml 
---
- hosts: all
  vars:
    timesync_ntp_servers:
      - hostname: app1
        iburst: yes
      - hostname: app2
        iburst: yes
      - hostname: app3
        iburst: yes
  roles:
    - rhel-system-roles.timesyncs
[devops@app1 project]$ ansible-playbook ntp.yml 
ERROR! the role 'rhel-system-roles.timesyncs' was not found in /home/devops/project/roles:/home/devops/project/roles:/usr/share/ansible/roles:/home/devops/project

The error appears to be in '/home/devops/project/ntp.yml': line 12, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

  roles:
    - rhel-system-roles.timesyncs
      ^ here

[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ cat ansible.cfg  | grep log
log_path=/var/log/ansible.log
[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ ansible-playbook nginx.yml 

PLAY [Play for NGINX from Ansible Galaxy] ************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [service] ***************************************************************************************
ok: [app2]

TASK [geerlingguy.nginx : Include OS-specific variables.] ********************************************
ok: [app2]

TASK [geerlingguy.nginx : Define nginx_user.] ********************************************************
ok: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
included: /home/devops/project/roles/geerlingguy.nginx/tasks/setup-RedHat.yml for app2

TASK [geerlingguy.nginx : Enable nginx repo.] ********************************************************
ok: [app2]

TASK [geerlingguy.nginx : Ensure nginx is installed.] ************************************************
ok: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : Remove default nginx vhost config file (if configured).] *******************
skipping: [app2]

TASK [geerlingguy.nginx : Ensure nginx_vhost_path exists.] *******************************************
ok: [app2]

TASK [geerlingguy.nginx : Add managed vhost config files.] *******************************************

TASK [geerlingguy.nginx : Remove managed vhost config files.] ****************************************

TASK [geerlingguy.nginx : Remove legacy vhosts.conf file.] *******************************************
ok: [app2]

TASK [geerlingguy.nginx : Copy nginx configuration in place.] ****************************************
ok: [app2]

TASK [geerlingguy.nginx : Ensure nginx service is running as configured.] ****************************
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "msg": "NGINX Installed Successfully"
}

PLAY RECAP *******************************************************************************************
app2                       : ok=12   changed=0    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   

[devops@app1 project]$ ls -ltr
total 148
-rw-rw-r--. 1 devops devops   91 Feb  3 11:40 index.html
-rw-rw-r--. 1 devops devops  819 Feb  3 11:42 playbook.yml
-rw-rw-r--. 1 devops devops   83 Feb  4 05:12 var_file.yml
drwxrwxr-x. 2 devops devops   23 Feb  4 06:20 group_vars
drwxrwxr-x. 2 devops devops   25 Feb  4 06:38 host_vars
-rw-rw-r--. 1 devops devops  357 Feb  4 07:23 facts.yml
-rw-rw-r--. 1 devops devops  799 Feb  4 07:39 vars.yml
-rw-rw-r--. 1 devops devops  274 Feb  4 09:00 copy_facts.yml
-rw-------. 1 devops devops  419 Feb  4 09:14 pass.yml
-rw-rw-r--. 1 devops devops  504 Feb  4 09:48 users.yml
-rw-rw-r--. 1 devops devops  557 Feb  4 10:48 loops.yml
-rw-rw-r--. 1 devops devops  123 Feb  4 11:17 hosts
-rw-rw-r--. 1 devops devops 1012 Feb  4 23:31 conditions.yml
-rw-rw-r--. 1 devops devops  221 Feb  4 23:34 test.yml
-rw-rw-r--. 1 devops devops 1496 Feb  5 05:44 apache.yml
-rw-rw-r--. 1 devops devops   22 Feb  5 06:07 file.txt
-rw-rw-r--. 1 devops devops  193 Feb  5 06:25 network.yml
-rw-rw-r--. 1 devops devops  367 Feb  5 06:35 file.j2
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app3.txt
-rw-rw-r--. 1 devops devops  322 Feb  5 07:27 app2.txt
-rw-rw-r--. 1 devops devops  215 Feb  5 08:55 inventory
drwxrwxrwx. 2 devops devops   20 Feb  5 09:43 dynamic
-rw-rw-r--. 1 devops devops 1842 Feb  5 10:18 static.yml
-rw-rw-r--. 1 devops devops   49 Feb  5 10:40 http_vars.yml
-rw-rw-r--. 1 devops devops  286 Feb  5 10:44 http_tasks.yml
-rw-rw-r--. 1 devops devops   40 Feb  5 10:47 fw_vars.yml
-rw-rw-r--. 1 devops devops  170 Feb  5 10:49 fw_tasks.yml
-rw-rw-r--. 1 devops devops  208 Feb  5 10:54 master.yml
-rw-rw-r--. 1 devops devops   98 Feb  5 11:06 app.yml
-rw-rw-r--. 1 devops devops   73 Feb  6 03:17 r.yml
drwxrwxr-x. 3 devops devops   19 Feb  6 03:17 get_facts
-rw-rw-r--. 1 devops devops   93 Feb  6 03:37 1.yml
-rw-rw-r--. 1 devops devops  250 Feb  6 04:38 hosts.j2
-rw-rw-r--. 1 devops devops  181 Feb  6 05:09 hosts.yml
-rw-rw-r--. 1 devops devops  387 Feb  6 06:48 azmysql.yml
-rw-rw-r--. 1 devops devops  231 Feb  6 07:36 nginx.yml
-rw-rw-r--. 1 devops devops  106 Feb  6 09:05 req.yml
drwxrwxr-x. 5 devops devops   69 Feb  6 09:09 roles
-rw-rw-r--. 1 devops devops  223 Feb  6 09:35 ntp.yml
-rw-rw-r--. 1 devops devops  292 Feb  6 09:40 ansible.cfg
-rw-rw-r--. 1 devops devops 4465 Feb  6 09:41 ansible_$$.log
[devops@app1 project]$ vi ansible.cfg 
[devops@app1 project]$ vi ansible_\$\$.log 
[devops@app1 project]$ #vi ansible_\$\$.log 
[devops@app1 project]$ ## logrotation
[devops@app1 project]$ #Service (process)
[devops@app1 project]$ #Troubleshooting
[devops@app1 project]$ ##Debug mode
[devops@app1 project]$ cat ansible.cfg  | grep log
log_path=ansible.log 
[devops@app1 project]$ ansible-playbook nginx.yml  -vvvv
ansible-playbook 2.9.2
  config file = /home/devops/project/ansible.cfg
  configured module search path = [u'/home/devops/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']
  ansible python module location = /usr/lib/python2.7/site-packages/ansible
  executable location = /bin/ansible-playbook
  python version = 2.7.5 (default, Apr  9 2019, 14:30:50) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]
Using /home/devops/project/ansible.cfg as config file
setting up inventory plugins
host_list declined parsing /home/devops/project/hosts as it did not pass its verify_file() method
script declined parsing /home/devops/project/hosts as it did not pass its verify_file() method
auto declined parsing /home/devops/project/hosts as it did not pass its verify_file() method
Parsed /home/devops/project/hosts inventory source with ini plugin
statically imported: /home/devops/project/roles/geerlingguy.nginx/tasks/vhosts.yml
Loading callback plugin default of type stdout, v2.0 from /usr/lib/python2.7/site-packages/ansible/plugins/callback/default.pyc

PLAYBOOK: nginx.yml **********************************************************************************
Positional arguments: nginx.yml
remote_user: devops
become_method: sudo
inventory: (u'/home/devops/project/hosts',)
forks: 1
tags: (u'all',)
verbosity: 4
connection: smart
timeout: 10
become: True
1 plays in nginx.yml

PLAY [Play for NGINX from Ansible Galaxy] ************************************************************

TASK [Gathering Facts] *******************************************************************************
task path: /home/devops/project/nginx.yml:2
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug1: Control socket "/home/devops/.ansible/cp/661fd496dc" does not exist\r\ndebug2: resolving "192.168.3.6" port 22\r\ndebug2: ssh_connect_direct: needpriv 0\r\ndebug1: Connecting to 192.168.3.6 [192.168.3.6] port 22.\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: fd 3 clearing O_NONBLOCK\r\ndebug1: Connection established.\r\ndebug3: timeout: 9999 ms remain after connect\r\ndebug1: identity file /home/devops/.ssh/id_rsa type 1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /home/devops/.ssh/id_rsa-cert type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /home/devops/.ssh/id_dsa type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /home/devops/.ssh/id_dsa-cert type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /home/devops/.ssh/id_ecdsa type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /home/devops/.ssh/id_ecdsa-cert type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /home/devops/.ssh/id_ed25519 type -1\r\ndebug1: key_load_public: No such file or directory\r\ndebug1: identity file /home/devops/.ssh/id_ed25519-cert type -1\r\ndebug1: Enabling compatibility mode for protocol 2.0\r\ndebug1: Local version string SSH-2.0-OpenSSH_7.4\r\ndebug1: Remote protocol version 2.0, remote software version OpenSSH_7.4\r\ndebug1: match: OpenSSH_7.4 pat OpenSSH* compat 0x04000000\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug1: Authenticating to 192.168.3.6:22 as \'devops\'\r\ndebug3: hostkeys_foreach: reading file "/home/devops/.ssh/known_hosts"\r\ndebug3: record_hostkey: found key type ECDSA in file /home/devops/.ssh/known_hosts:1\r\ndebug3: load_hostkeys: loaded 1 keys from 192.168.3.6\r\ndebug3: order_hostkeyalgs: prefer hostkeyalgs: ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521\r\ndebug3: send packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT sent\r\ndebug3: receive packet: type 20\r\ndebug1: SSH2_MSG_KEXINIT received\r\ndebug2: local client KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha256,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1,ext-info-c\r\ndebug2: host key algorithms: ecdsa-sha2-nistp256-cert-v01@openssh.com,ecdsa-sha2-nistp384-cert-v01@openssh.com,ecdsa-sha2-nistp521-cert-v01@openssh.com,ecdsa-sha2-nistp256,ecdsa-sha2-nistp384,ecdsa-sha2-nistp521,ssh-ed25519-cert-v01@openssh.com,ssh-rsa-cert-v01@openssh.com,ssh-dss-cert-v01@openssh.com,ssh-ed25519,rsa-sha2-512,rsa-sha2-256,ssh-rsa,ssh-dss\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,aes128-cbc,aes192-cbc,aes256-cbc\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,aes128-cbc,aes192-cbc,aes256-cbc\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: zlib@openssh.com,zlib,none\r\ndebug2: compression stoc: zlib@openssh.com,zlib,none\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug2: peer server KEXINIT proposal\r\ndebug2: KEX algorithms: curve25519-sha256,curve25519-sha256@libssh.org,ecdh-sha2-nistp256,ecdh-sha2-nistp384,ecdh-sha2-nistp521,diffie-hellman-group-exchange-sha256,diffie-hellman-group16-sha512,diffie-hellman-group18-sha512,diffie-hellman-group-exchange-sha1,diffie-hellman-group14-sha256,diffie-hellman-group14-sha1,diffie-hellman-group1-sha1\r\ndebug2: host key algorithms: ssh-rsa,rsa-sha2-512,rsa-sha2-256,ecdsa-sha2-nistp256,ssh-ed25519\r\ndebug2: ciphers ctos: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,aes128-cbc,aes192-cbc,aes256-cbc,blowfish-cbc,cast128-cbc,3des-cbc\r\ndebug2: ciphers stoc: chacha20-poly1305@openssh.com,aes128-ctr,aes192-ctr,aes256-ctr,aes128-gcm@openssh.com,aes256-gcm@openssh.com,aes128-cbc,aes192-cbc,aes256-cbc,blowfish-cbc,cast128-cbc,3des-cbc\r\ndebug2: MACs ctos: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: MACs stoc: umac-64-etm@openssh.com,umac-128-etm@openssh.com,hmac-sha2-256-etm@openssh.com,hmac-sha2-512-etm@openssh.com,hmac-sha1-etm@openssh.com,umac-64@openssh.com,umac-128@openssh.com,hmac-sha2-256,hmac-sha2-512,hmac-sha1\r\ndebug2: compression ctos: none,zlib@openssh.com\r\ndebug2: compression stoc: none,zlib@openssh.com\r\ndebug2: languages ctos: \r\ndebug2: languages stoc: \r\ndebug2: first_kex_follows 0 \r\ndebug2: reserved 0 \r\ndebug1: kex: algorithm: curve25519-sha256\r\ndebug1: kex: host key algorithm: ecdsa-sha2-nistp256\r\ndebug1: kex: server->client cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug1: kex: client->server cipher: chacha20-poly1305@openssh.com MAC: <implicit> compression: zlib@openssh.com\r\ndebug1: kex: curve25519-sha256 need=64 dh_need=64\r\ndebug1: kex: curve25519-sha256 need=64 dh_need=64\r\ndebug3: send packet: type 30\r\ndebug1: expecting SSH2_MSG_KEX_ECDH_REPLY\r\ndebug3: receive packet: type 31\r\ndebug1: Server host key: ecdsa-sha2-nistp256 SHA256:yd5Av2FjGJLVvw32XJ6zhCYtQVMHbs2MEuAK8jxv2g0\r\ndebug3: hostkeys_foreach: reading file "/home/devops/.ssh/known_hosts"\r\ndebug3: record_hostkey: found key type ECDSA in file /home/devops/.ssh/known_hosts:1\r\ndebug3: load_hostkeys: loaded 1 keys from 192.168.3.6\r\ndebug1: Host \'192.168.3.6\' is known and matches the ECDSA host key.\r\ndebug1: Found key in /home/devops/.ssh/known_hosts:1\r\ndebug3: send packet: type 21\r\ndebug2: set_newkeys: mode 1\r\ndebug1: rekey after 134217728 blocks\r\ndebug1: SSH2_MSG_NEWKEYS sent\r\ndebug1: expecting SSH2_MSG_NEWKEYS\r\ndebug3: receive packet: type 21\r\ndebug1: SSH2_MSG_NEWKEYS received\r\ndebug2: set_newkeys: mode 0\r\ndebug1: rekey after 134217728 blocks\r\ndebug2: key: /home/devops/.ssh/id_rsa (0x559c2ac25050)\r\ndebug2: key: /home/devops/.ssh/id_dsa ((nil))\r\ndebug2: key: /home/devops/.ssh/id_ecdsa ((nil))\r\ndebug2: key: /home/devops/.ssh/id_ed25519 ((nil))\r\ndebug3: send packet: type 5\r\ndebug3: receive packet: type 7\r\ndebug1: SSH2_MSG_EXT_INFO received\r\ndebug1: kex_input_ext_info: server-sig-algs=<rsa-sha2-256,rsa-sha2-512>\r\ndebug3: receive packet: type 6\r\ndebug2: service_accept: ssh-userauth\r\ndebug1: SSH2_MSG_SERVICE_ACCEPT received\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 51\r\ndebug1: Authentications that can continue: publickey,gssapi-keyex,gssapi-with-mic\r\ndebug3: start over, passed a different list publickey,gssapi-keyex,gssapi-with-mic\r\ndebug3: preferred gssapi-with-mic,gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_lookup gssapi-with-mic\r\ndebug3: remaining preferred: gssapi-keyex,hostbased,publickey\r\ndebug3: authmethod_is_enabled gssapi-with-mic\r\ndebug1: Next authentication method: gssapi-with-mic\r\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo Kerberos credentials available (default cache: KEYRING:persistent:1001)\n\r\ndebug1: Unspecified GSS failure.  Minor code may provide more information\nNo Kerberos credentials available (default cache: KEYRING:persistent:1001)\n\r\ndebug2: we did not send a packet, disable method\r\ndebug3: authmethod_lookup gssapi-keyex\r\ndebug3: remaining preferred: hostbased,publickey\r\ndebug3: authmethod_is_enabled gssapi-keyex\r\ndebug1: Next authentication method: gssapi-keyex\r\ndebug1: No valid Key exchange context\r\ndebug2: we did not send a packet, disable method\r\ndebug3: authmethod_lookup publickey\r\ndebug3: remaining preferred: ,publickey\r\ndebug3: authmethod_is_enabled publickey\r\ndebug1: Next authentication method: publickey\r\ndebug1: Offering RSA public key: /home/devops/.ssh/id_rsa\r\ndebug3: send_pubkey_test\r\ndebug3: send packet: type 50\r\ndebug2: we sent a publickey packet, wait for reply\r\ndebug3: receive packet: type 60\r\ndebug1: Server accepts key: pkalg rsa-sha2-512 blen 279\r\ndebug2: input_userauth_pk_ok: fp SHA256:JKLgA16kmopbIn/CQbcoe4VbfUUtpdHtUOSLduzoWUc\r\ndebug3: sign_and_send_pubkey: RSA SHA256:JKLgA16kmopbIn/CQbcoe4VbfUUtpdHtUOSLduzoWUc\r\ndebug3: send packet: type 50\r\ndebug3: receive packet: type 52\r\ndebug1: Enabling compression at level 6.\r\ndebug1: Authentication succeeded (publickey).\r\nAuthenticated to 192.168.3.6 ([192.168.3.6]:22).\r\ndebug1: setting up multiplex master socket\r\ndebug3: muxserver_listen: temporary control path /home/devops/.ansible/cp/661fd496dc.T9noid4EyHl241sc\r\ndebug2: fd 4 setting O_NONBLOCK\r\ndebug3: fd 4 is O_NONBLOCK\r\ndebug3: fd 4 is O_NONBLOCK\r\ndebug1: channel 0: new [/home/devops/.ansible/cp/661fd496dc]\r\ndebug3: muxserver_listen: mux listener channel 0 fd 4\r\ndebug2: fd 3 setting TCP_NODELAY\r\ndebug3: ssh_packet_set_tos: set IP_TOS 0x08\r\ndebug1: control_persist_detach: backgrounding master process\r\ndebug2: control_persist_detach: background process is 4755\r\ndebug2: fd 4 setting O_NONBLOCK\r\ndebug1: forking to background\r\ndebug1: Entering interactive session.\r\ndebug1: pledge: id\r\ndebug2: set_control_persist_exit_time: schedule exit in 60 seconds\r\ndebug1: multiplexing control connection\r\ndebug2: fd 5 setting O_NONBLOCK\r\ndebug3: fd 5 is O_NONBLOCK\r\ndebug1: channel 1: new [mux-control]\r\ndebug3: channel_post_mux_listener: new mux channel 1 fd 5\r\ndebug3: mux_master_read_cb: channel 1: hello sent\r\ndebug2: set_control_persist_exit_time: cancel scheduled exit\r\ndebug3: mux_master_read_cb: channel 1 packet type 0x00000001 len 4\r\ndebug2: process_mux_master_hello: channel 1 slave version 4\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_master_read_cb: channel 1 packet type 0x10000004 len 4\r\ndebug2: process_mux_alive_check: channel 1: alive check\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug3: mux_master_read_cb: channel 1 packet type 0x10000002 len 124\r\ndebug2: process_mux_new_session: channel 1: request tty 0, X 0, agent 0, subsys 0, term "xterm-256color", cmd "/bin/sh -c \'echo ~devops && sleep 0\'", env 2\r\ndebug3: process_mux_new_session: got fds stdin 6, stdout 7, stderr 8\r\ndebug2: fd 7 setting O_NONBLOCK\r\ndebug2: fd 8 setting O_NONBLOCK\r\ndebug1: channel 2: new [client-session]\r\ndebug2: process_mux_new_session: channel_new: 2 linked to control channel 1\r\ndebug2: channel 2: send open\r\ndebug3: send packet: type 90\r\ndebug3: receive packet: type 80\r\ndebug1: client_input_global_request: rtype hostkeys-00@openssh.com want_reply 0\r\ndebug3: receive packet: type 91\r\ndebug2: callback start\r\ndebug2: client_session2_setup: id 2\r\ndebug1: Sending environment.\r\ndebug1: Sending env LANG = en_US.UTF-8\r\ndebug2: channel 2: request env confirm 0\r\ndebug3: send packet: type 98\r\ndebug1: Sending env LC_CTYPE = UTF-8\r\ndebug2: channel 2: request env confirm 0\r\ndebug3: send packet: type 98\r\ndebug1: Sending command: /bin/sh -c \'echo ~devops && sleep 0\'\r\ndebug2: channel 2: request exec confirm 1\r\ndebug3: send packet: type 98\r\ndebug3: mux_session_confirm: sending success reply\r\ndebug2: callback done\r\ndebug2: channel 2: open confirm rwindow 0 rmax 32768\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: channel 2: rcvd adjust 2097152\r\ndebug3: receive packet: type 99\r\ndebug2: channel_input_status_confirm: type 99 id 2\r\ndebug2: exec request accepted on channel 2\r\ndebug3: receive packet: type 98\r\ndebug1: client_input_channel_req: channel 2 rtype exit-status reply 0\r\ndebug3: mux_exit_message: channel 2: exit message, exitval 0\r\ndebug3: receive packet: type 98\r\ndebug1: client_input_channel_req: channel 2 rtype eow@openssh.com reply 0\r\ndebug2: channel 2: rcvd eow\r\ndebug2: channel 2: close_read\r\ndebug2: channel 2: input open -> closed\r\ndebug3: receive packet: type 96\r\ndebug2: channel 2: rcvd eof\r\ndebug2: channel 2: output open -> drain\r\ndebug2: channel 2: obuf empty\r\ndebug2: channel 2: close_write\r\ndebug2: channel 2: output drain -> closed\r\ndebug3: receive packet: type 97\r\ndebug2: channel 2: rcvd close\r\ndebug3: channel 2: will not send data after close\r\ndebug2: channel 2: send close\r\ndebug3: send packet: type 97\r\ndebug2: channel 2: is dead\r\ndebug2: channel 2: gc: notify user\r\ndebug3: mux_master_session_cleanup_cb: entering for channel 2\r\ndebug2: channel 1: rcvd close\r\ndebug2: channel 1: output open -> drain\r\ndebug2: channel 1: close_read\r\ndebug2: channel 1: input open -> closed\r\ndebug2: channel 2: gc: user detached\r\ndebug2: channel 2: is dead\r\ndebug2: channel 2: garbage collecting\r\ndebug1: channel 2: free: client-session, nchannels 3\r\ndebug3: channel 2: status: The following connections are open:\r\n  #1 mux-control (t16 r-1 i3/0 o1/16 fd 5/5 cc -1)\r\n  #2 client-session (t4 r0 i3/0 o3/0 fd -1/-1 cc -1)\r\n\r\ndebug2: channel 1: obuf empty\r\ndebug2: channel 1: close_write\r\ndebug2: channel 1: output drain -> closed\r\ndebug2: channel 1: is dead (local)\r\ndebug2: channel 1: gc: notify user\r\ndebug3: mux_master_control_cleanup_cb: entering for channel 1\r\ndebug2: channel 1: gc: user detached\r\ndebug2: channel 1: is dead (local)\r\ndebug2: channel 1: garbage collecting\r\ndebug1: channel 1: free: mux-control, nchannels 2\r\ndebug3: channel 1: status: The following connections are open:\r\n  #1 mux-control (t16 r-1 i3/0 o3/0 fd 5/5 cc -1)\r\n\r\ndebug2: set_control_persist_exit_time: schedule exit in 60 seconds\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251 `" && echo ansible-tmp-1580982428.3-210104302683251="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982428.3-210104302683251=/home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<app2> Attempting python interpreter discovery
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo PLATFORM; uname; echo FOUND; command -v '"'"'"'"'"'"'"'"'/usr/bin/python'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.7'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.6'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python3.5'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python2.7'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python2.6'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'/usr/libexec/platform-python'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'/usr/bin/python3'"'"'"'"'"'"'"'"'; command -v '"'"'"'"'"'"'"'"'python'"'"'"'"'"'"'"'"'; echo ENDFOUND && sleep 0'"'"''
<192.168.3.6> (0, 'PLATFORM\nLinux\nFOUND\n/usr/bin/python\n/usr/bin/python2.7\n/usr/libexec/platform-python\n/usr/bin/python\nENDFOUND\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'/usr/bin/python && sleep 0'"'"''
<192.168.3.6> (0, '{"osrelease_content": "NAME=\\"CentOS Linux\\"\\nVERSION=\\"7 (Core)\\"\\nID=\\"centos\\"\\nID_LIKE=\\"rhel fedora\\"\\nVERSION_ID=\\"7\\"\\nPRETTY_NAME=\\"CentOS Linux 7 (Core)\\"\\nANSI_COLOR=\\"0;31\\"\\nCPE_NAME=\\"cpe:/o:centos:centos:7\\"\\nHOME_URL=\\"https://www.centos.org/\\"\\nBUG_REPORT_URL=\\"https://bugs.centos.org/\\"\\n\\nCENTOS_MANTISBT_PROJECT=\\"CentOS-7\\"\\nCENTOS_MANTISBT_PROJECT_VERSION=\\"7\\"\\nREDHAT_SUPPORT_PRODUCT=\\"centos\\"\\nREDHAT_SUPPORT_PRODUCT_VERSION=\\"7\\"\\n\\n", "platform_dist_result": ["centos", "7.7.1908", "Core"]}\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/system/setup.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmp0POz08 TO /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/AnsiballZ_setup.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmp0POz08 /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/AnsiballZ_setup.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmp0POz08\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/AnsiballZ_setup.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:8 O:131072 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:9 O:163840 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:10 O:196608 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:11 O:229376 S:25644\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 32768 bytes at 98304\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 8 32768 bytes at 131072\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 9 32768 bytes at 163840\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 10 32768 bytes at 196608\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 11 25644 bytes at 229376\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/ /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/AnsiballZ_setup.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-pwoklsrwdjfaralhprwppxbkeidrokkb ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/AnsiballZ_setup.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"invocation": {"module_args": {"filter": "*", "gather_subset": ["all"], "fact_path": "/etc/ansible/facts.d", "gather_timeout": 10}}, "ansible_facts": {"ansible_fibre_channel_wwn": [], "module_setup": true, "ansible_distribution_version": "7.7", "ansible_distribution_file_variety": "RedHat", "ansible_env": {"LANG": "C", "USERNAME": "root", "TERM": "xterm-256color", "SHELL": "/bin/bash", "LC_MESSAGES": "C", "LC_ALL": "C", "SUDO_COMMAND": "/bin/sh -c echo BECOME-SUCCESS-pwoklsrwdjfaralhprwppxbkeidrokkb ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/AnsiballZ_setup.py", "SHLVL": "1", "SUDO_UID": "1001", "LC_CTYPE": "UTF-8", "PATH": "/sbin:/bin:/usr/sbin:/usr/bin", "PWD": "/home/devops", "LOGNAME": "root", "USER": "root", "HOME": "/root", "MAIL": "/var/mail/devops", "SUDO_USER": "devops", "LS_COLORS": "rs=0:di=38;5;27:ln=38;5;51:mh=44;38;5;15:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=05;48;5;232;38;5;15:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;34:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.Z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.axv=38;5;13:*.anx=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.axa=38;5;45:*.oga=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:", "XDG_SESSION_ID": "13", "SUDO_GID": "1001", "_": "/usr/bin/python"}, "ansible_userspace_bits": "64", "ansible_architecture": "x86_64", "ansible_default_ipv4": {"macaddress": "52:54:00:8a:fe:e6", "network": "10.0.2.0", "mtu": 1500, "broadcast": "10.0.2.255", "alias": "eth0", "netmask": "255.255.255.0", "address": "10.0.2.15", "interface": "eth0", "type": "ether", "gateway": "10.0.2.2"}, "ansible_swapfree_mb": 1961, "ansible_default_ipv6": {}, "ansible_cmdline": {"no_timer_check": true, "LANG": "en_US.UTF-8", "BOOT_IMAGE": "/boot/vmlinuz-3.10.0-957.12.2.el7.x86_64", "elevator": "noop", "net.ifnames": "0", "biosdevname": "0", "crashkernel": "auto", "console": "ttyS0,115200n8", "ro": true, "root": "UUID=8ac075e3-1124-4bb6-bef7-a6811bf8b870"}, "ansible_machine_id": "e6367a4627964527b496be84d8dfee8e", "ansible_userspace_architecture": "x86_64", "ansible_product_uuid": "E6367A46-2796-4527-B496-BE84D8DFEE8E", "ansible_pkg_mgr": "yum", "ansible_distribution": "CentOS", "ansible_iscsi_iqn": "", "ansible_all_ipv6_addresses": ["fe80::a00:27ff:fea5:5993", "fe80::5054:ff:fe8a:fee6"], "ansible_uptime_seconds": 23915, "ansible_kernel": "3.10.0-957.12.2.el7.x86_64", "ansible_system_capabilities_enforced": "True", "ansible_python": {"executable": "/usr/bin/python", "version": {"micro": 5, "major": 2, "releaselevel": "final", "serial": 0, "minor": 7}, "type": "CPython", "has_sslcontext": true, "version_info": [2, 7, 5, "final", 0]}, "ansible_is_chroot": false, "ansible_hostnqn": "", "ansible_user_shell": "/bin/bash", "ansible_product_serial": "0", "ansible_form_factor": "Other", "ansible_distribution_file_parsed": true, "ansible_fips": false, "ansible_user_id": "root", "ansible_selinux_python_present": true, "ansible_kernel_version": "#1 SMP Tue May 14 21:24:32 UTC 2019", "ansible_local": {}, "ansible_processor_vcpus": 1, "ansible_processor": ["0", "GenuineIntel", "Intel(R) Core(TM) i7-7660U CPU @ 2.50GHz"], "ansible_ssh_host_key_ecdsa_public": "AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYAAABBBEcyvbBleOp3D3QoqJj/KV1/Q/0QAfYu8NVf8GTNgZNvcrZA7QNLbZd9y9I33dLUOMD24rO46dLsYHBYLk37HLE=", "ansible_user_gid": 0, "ansible_system_vendor": "innotek GmbH", "ansible_swaptotal_mb": 2047, "ansible_distribution_major_version": "7", "ansible_real_group_id": 0, "ansible_lsb": {}, "ansible_machine": "x86_64", "ansible_ssh_host_key_rsa_public": "AAAAB3NzaC1yc2EAAAADAQABAAABAQCrmoxK5bXSl1JqTmbo6gKDqZekpjj3cuENHoZSUvtEBiQ06Y2VqkwSxsCXYTdjPIcbeNmPtwyiRk+S3hWMxTatmi1kDDGYjg2G3AnBGZlTSEGFE515JNojZ547LZI3JWMGCorcOGrDayRjNOp3tuI1CTT/UXl9+fJzxKO1Ca3qSTzDZevu7Arp4JTe8F7rEvS0mGghZ1oMDC2mggB2BYYCtiiHpFNLX0euPoUtxnjiH6gxjRU9dhpL/+DOf7lqu83uJadzM4lrcq5IeJivVjsv3W+ua/YO1B3SQ8g+WDuieAf83TM2qvhedwvbB3z31zdEfkmIZDyi2PnFX68dmqxT", "ansible_user_gecos": "root", "ansible_processor_threads_per_core": 1, "ansible_eth0": {"macaddress": "52:54:00:8a:fe:e6", "features": {"tx_checksum_ipv4": "off [fixed]", "generic_receive_offload": "on", "tx_checksum_ipv6": "off [fixed]", "tx_scatter_gather_fraglist": "off [fixed]", "rx_all": "off", "highdma": "off [fixed]", "rx_fcs": "off", "tx_lockless": "off [fixed]", "tx_tcp_ecn_segmentation": "off [fixed]", "rx_udp_tunnel_port_offload": "off [fixed]", "tx_tcp6_segmentation": "off [fixed]", "tx_gso_robust": "off [fixed]", "tx_ipip_segmentation": "off [fixed]", "tx_tcp_mangleid_segmentation": "off", "tx_checksumming": "on", "vlan_challenged": "off [fixed]", "loopback": "off [fixed]", "fcoe_mtu": "off [fixed]", "scatter_gather": "on", "tx_checksum_sctp": "off [fixed]", "tx_vlan_stag_hw_insert": "off [fixed]", "rx_vlan_stag_hw_parse": "off [fixed]", "tx_gso_partial": "off [fixed]", "rx_gro_hw": "off [fixed]", "rx_vlan_stag_filter": "off [fixed]", "large_receive_offload": "off [fixed]", "tx_scatter_gather": "on", "rx_checksumming": "off", "tx_tcp_segmentation": "on", "netns_local": "off [fixed]", "busy_poll": "off [fixed]", "generic_segmentation_offload": "on", "tx_udp_tnl_segmentation": "off [fixed]", "tcp_segmentation_offload": "on", "l2_fwd_offload": "off [fixed]", "rx_vlan_offload": "on", "ntuple_filters": "off [fixed]", "tx_gre_csum_segmentation": "off [fixed]", "tx_nocache_copy": "off", "tx_udp_tnl_csum_segmentation": "off [fixed]", "udp_fragmentation_offload": "off [fixed]", "tx_sctp_segmentation": "off [fixed]", "tx_sit_segmentation": "off [fixed]", "tx_checksum_fcoe_crc": "off [fixed]", "hw_tc_offload": "off [fixed]", "tx_checksum_ip_generic": "on", "tx_fcoe_segmentation": "off [fixed]", "rx_vlan_filter": "on [fixed]", "tx_vlan_offload": "on [fixed]", "receive_hashing": "off [fixed]", "tx_gre_segmentation": "off [fixed]"}, "type": "ether", "pciid": "0000:00:03.0", "module": "e1000", "mtu": 1500, "device": "eth0", "promisc": false, "timestamping": ["tx_software", "rx_software", "software"], "ipv4": {"broadcast": "10.0.2.255", "netmask": "255.255.255.0", "network": "10.0.2.0", "address": "10.0.2.15"}, "ipv6": [{"scope": "link", "prefix": "64", "address": "fe80::5054:ff:fe8a:fee6"}], "active": true, "speed": 1000, "hw_timestamp_filters": []}, "ansible_eth1": {"macaddress": "08:00:27:a5:59:93", "features": {"tx_checksum_ipv4": "off [fixed]", "generic_receive_offload": "on", "tx_checksum_ipv6": "off [fixed]", "tx_scatter_gather_fraglist": "off [fixed]", "rx_all": "off", "highdma": "off [fixed]", "rx_fcs": "off", "tx_lockless": "off [fixed]", "tx_tcp_ecn_segmentation": "off [fixed]", "rx_udp_tunnel_port_offload": "off [fixed]", "tx_tcp6_segmentation": "off [fixed]", "tx_gso_robust": "off [fixed]", "tx_ipip_segmentation": "off [fixed]", "tx_tcp_mangleid_segmentation": "off", "tx_checksumming": "on", "vlan_challenged": "off [fixed]", "loopback": "off [fixed]", "fcoe_mtu": "off [fixed]", "scatter_gather": "on", "tx_checksum_sctp": "off [fixed]", "tx_vlan_stag_hw_insert": "off [fixed]", "rx_vlan_stag_hw_parse": "off [fixed]", "tx_gso_partial": "off [fixed]", "rx_gro_hw": "off [fixed]", "rx_vlan_stag_filter": "off [fixed]", "large_receive_offload": "off [fixed]", "tx_scatter_gather": "on", "rx_checksumming": "off", "tx_tcp_segmentation": "on", "netns_local": "off [fixed]", "busy_poll": "off [fixed]", "generic_segmentation_offload": "on", "tx_udp_tnl_segmentation": "off [fixed]", "tcp_segmentation_offload": "on", "l2_fwd_offload": "off [fixed]", "rx_vlan_offload": "on", "ntuple_filters": "off [fixed]", "tx_gre_csum_segmentation": "off [fixed]", "tx_nocache_copy": "off", "tx_udp_tnl_csum_segmentation": "off [fixed]", "udp_fragmentation_offload": "off [fixed]", "tx_sctp_segmentation": "off [fixed]", "tx_sit_segmentation": "off [fixed]", "tx_checksum_fcoe_crc": "off [fixed]", "hw_tc_offload": "off [fixed]", "tx_checksum_ip_generic": "on", "tx_fcoe_segmentation": "off [fixed]", "rx_vlan_filter": "on [fixed]", "tx_vlan_offload": "on [fixed]", "receive_hashing": "off [fixed]", "tx_gre_segmentation": "off [fixed]"}, "type": "ether", "pciid": "0000:00:08.0", "module": "e1000", "mtu": 1500, "device": "eth1", "promisc": false, "timestamping": ["tx_software", "rx_software", "software"], "ipv4": {"broadcast": "192.168.3.255", "netmask": "255.255.255.0", "network": "192.168.3.0", "address": "192.168.3.6"}, "ipv6": [{"scope": "link", "prefix": "64", "address": "fe80::a00:27ff:fea5:5993"}], "active": true, "speed": 1000, "hw_timestamp_filters": []}, "ansible_product_name": "VirtualBox", "ansible_all_ipv4_addresses": ["192.168.3.6", "10.0.2.15"], "ansible_python_version": "2.7.5", "ansible_product_version": "1.2", "ansible_service_mgr": "systemd", "ansible_memory_mb": {"real": {"total": 235, "used": 210, "free": 25}, "swap": {"cached": 4, "total": 2047, "free": 1961, "used": 86}, "nocache": {"used": 133, "free": 102}}, "ansible_user_dir": "/root", "gather_subset": ["all"], "ansible_real_user_id": 0, "ansible_virtualization_role": "guest", "ansible_dns": {"nameservers": ["10.0.2.3"], "search": ["dev"]}, "ansible_effective_group_id": 0, "ansible_lo": {"features": {"tx_checksum_ipv4": "off [fixed]", "generic_receive_offload": "on", "tx_checksum_ipv6": "off [fixed]", "tx_scatter_gather_fraglist": "on [fixed]", "rx_all": "off [fixed]", "highdma": "on [fixed]", "rx_fcs": "off [fixed]", "tx_lockless": "on [fixed]", "tx_tcp_ecn_segmentation": "on", "rx_udp_tunnel_port_offload": "off [fixed]", "tx_tcp6_segmentation": "on", "tx_gso_robust": "off [fixed]", "tx_ipip_segmentation": "off [fixed]", "tx_tcp_mangleid_segmentation": "on", "tx_checksumming": "on", "vlan_challenged": "on [fixed]", "loopback": "on [fixed]", "fcoe_mtu": "off [fixed]", "scatter_gather": "on", "tx_checksum_sctp": "on [fixed]", "tx_vlan_stag_hw_insert": "off [fixed]", "rx_vlan_stag_hw_parse": "off [fixed]", "tx_gso_partial": "off [fixed]", "rx_gro_hw": "off [fixed]", "rx_vlan_stag_filter": "off [fixed]", "large_receive_offload": "off [fixed]", "tx_scatter_gather": "on [fixed]", "rx_checksumming": "on [fixed]", "tx_tcp_segmentation": "on", "netns_local": "on [fixed]", "busy_poll": "off [fixed]", "generic_segmentation_offload": "on", "tx_udp_tnl_segmentation": "off [fixed]", "tcp_segmentation_offload": "on", "l2_fwd_offload": "off [fixed]", "rx_vlan_offload": "off [fixed]", "ntuple_filters": "off [fixed]", "tx_gre_csum_segmentation": "off [fixed]", "tx_nocache_copy": "off [fixed]", "tx_udp_tnl_csum_segmentation": "off [fixed]", "udp_fragmentation_offload": "on", "tx_sctp_segmentation": "on", "tx_sit_segmentation": "off [fixed]", "tx_checksum_fcoe_crc": "off [fixed]", "hw_tc_offload": "off [fixed]", "tx_checksum_ip_generic": "on [fixed]", "tx_fcoe_segmentation": "off [fixed]", "rx_vlan_filter": "off [fixed]", "tx_vlan_offload": "off [fixed]", "receive_hashing": "off [fixed]", "tx_gre_segmentation": "off [fixed]"}, "hw_timestamp_filters": [], "mtu": 65536, "device": "lo", "promisc": false, "timestamping": ["rx_software", "software"], "ipv4": {"broadcast": "host", "netmask": "255.0.0.0", "network": "127.0.0.0", "address": "127.0.0.1"}, "ipv6": [{"scope": "host", "prefix": "128", "address": "::1"}], "active": true, "type": "loopback"}, "ansible_memtotal_mb": 235, "ansible_device_links": {"masters": {}, "labels": {}, "ids": {"sda": ["ata-VBOX_HARDDISK_VBc13e6a8e-842ed4a4"], "sda1": ["ata-VBOX_HARDDISK_VBc13e6a8e-842ed4a4-part1"]}, "uuids": {"sda1": ["8ac075e3-1124-4bb6-bef7-a6811bf8b870"]}}, "ansible_apparmor": {"status": "disabled"}, "ansible_proc_cmdline": {"no_timer_check": true, "LANG": "en_US.UTF-8", "BOOT_IMAGE": "/boot/vmlinuz-3.10.0-957.12.2.el7.x86_64", "elevator": "noop", "net.ifnames": "0", "biosdevname": "0", "crashkernel": "auto", "console": ["tty0", "ttyS0,115200n8"], "ro": true, "root": "UUID=8ac075e3-1124-4bb6-bef7-a6811bf8b870"}, "ansible_memfree_mb": 25, "ansible_processor_count": 1, "ansible_hostname": "app2", "ansible_interfaces": ["lo", "eth1", "eth0"], "ansible_selinux": {"status": "enabled", "policyvers": 31, "type": "targeted", "mode": "enforcing", "config_mode": "enforcing"}, "ansible_fqdn": "app2.dev", "ansible_mounts": [{"block_used": 1056604, "uuid": "8ac075e3-1124-4bb6-bef7-a6811bf8b870", "size_total": 42927656960, "block_total": 10480385, "mount": "/", "block_available": 9423781, "size_available": 38599806976, "fstype": "xfs", "inode_total": 20971008, "options": "rw,seclabel,relatime,attr2,inode64,noquota", "device": "/dev/sda1", "inode_used": 53200, "block_size": 4096, "inode_available": 20917808}], "ansible_nodename": "app2.dev", "ansible_domain": "dev", "ansible_distribution_file_path": "/etc/redhat-release", "ansible_virtualization_type": "virtualbox", "ansible_ssh_host_key_ed25519_public": "AAAAC3NzaC1lZDI1NTE5AAAAIJSVpAsu6xcTzFKhA4WmTdQj70wWJnHD7ZF7Gxhfe8Ea", "ansible_processor_cores": 1, "ansible_bios_version": "VirtualBox", "ansible_date_time": {"weekday_number": "4", "iso8601_basic_short": "20200206T094711", "tz": "UTC", "weeknumber": "05", "hour": "09", "year": "2020", "minute": "47", "tz_offset": "+0000", "month": "02", "epoch": "1580982431", "iso8601_micro": "2020-02-06T09:47:11.271384Z", "weekday": "Thursday", "time": "09:47:11", "date": "2020-02-06", "iso8601": "2020-02-06T09:47:11Z", "day": "06", "iso8601_basic": "20200206T094711271246", "second": "11"}, "ansible_distribution_release": "Core", "ansible_os_family": "RedHat", "ansible_effective_user_id": 0, "ansible_system": "Linux", "ansible_devices": {"sda": {"scheduler_mode": "noop", "rotational": "1", "vendor": "ATA", "sectors": "83886080", "links": {"masters": [], "labels": [], "ids": ["ata-VBOX_HARDDISK_VBc13e6a8e-842ed4a4"], "uuids": []}, "sas_device_handle": null, "sas_address": null, "virtual": 1, "host": "IDE interface: Intel Corporation 82371AB/EB/MB PIIX4 IDE (rev 01)", "sectorsize": "512", "removable": "0", "support_discard": "0", "holders": [], "partitions": {"sda1": {"sectorsize": 512, "uuid": "8ac075e3-1124-4bb6-bef7-a6811bf8b870", "links": {"masters": [], "labels": [], "ids": ["ata-VBOX_HARDDISK_VBc13e6a8e-842ed4a4-part1"], "uuids": ["8ac075e3-1124-4bb6-bef7-a6811bf8b870"]}, "sectors": "83884032", "start": "2048", "holders": [], "size": "40.00 GB"}}, "model": "VBOX HARDDISK", "serial": "VBc13e6a8e", "size": "40.00 GB"}}, "ansible_user_uid": 0, "ansible_bios_date": "12/01/2006", "ansible_system_capabilities": ["cap_chown", "cap_dac_override", "cap_dac_read_search", "cap_fowner", "cap_fsetid", "cap_kill", "cap_setgid", "cap_setuid", "cap_setpcap", "cap_linux_immutable", "cap_net_bind_service", "cap_net_broadcast", "cap_net_admin", "cap_net_raw", "cap_ipc_lock", "cap_ipc_owner", "cap_sys_module", "cap_sys_rawio", "cap_sys_chroot", "cap_sys_ptrace", "cap_sys_pacct", "cap_sys_admin", "cap_sys_boot", "cap_sys_nice", "cap_sys_resource", "cap_sys_time", "cap_sys_tty_config", "cap_mknod", "cap_lease", "cap_audit_write", "cap_audit_control", "cap_setfcap", "cap_mac_override", "cap_mac_admin", "cap_syslog", "35", "36+ep"]}}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982428.3-210104302683251/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2]

TASK [service] ***************************************************************************************
task path: /home/devops/project/nginx.yml:6
Running systemd
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291 `" && echo ansible-tmp-1580982431.46-102273853685291="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982431.46-102273853685291=/home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/system/systemd.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpIojWrV TO /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291/AnsiballZ_systemd.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpIojWrV /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291/AnsiballZ_systemd.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpIojWrV\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291/AnsiballZ_systemd.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:8 O:131072 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:9 O:163840 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:10 O:196608 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:11 O:229376 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:12 O:262144 S:2296\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 32768 bytes at 98304\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 8 32768 bytes at 131072\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 9 32768 bytes at 163840\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 10 32768 bytes at 196608\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 11 32768 bytes at 229376\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 12 2296 bytes at 262144\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291/ /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291/AnsiballZ_systemd.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-zdzrwopaypopzvfnyboraucxemfscqlc ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291/AnsiballZ_systemd.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"status": {"ExecStart": "{ path=/usr/sbin/httpd ; argv[]=/usr/sbin/httpd $OPTIONS -DFOREGROUND ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "TimeoutStopUSec": "1min 30s", "RuntimeDirectoryMode": "0755", "GuessMainPID": "yes", "ActiveExitTimestamp": "Thu 2020-02-06 07:36:28 UTC", "ExecMainCode": "1", "UnitFileState": "enabled", "ExecMainPID": "2751", "LimitSIGPENDING": "882", "FileDescriptorStoreMax": "0", "LoadState": "loaded", "ProtectHome": "no", "TTYVTDisallocate": "no", "TTYVHangup": "no", "WatchdogTimestampMonotonic": "0", "LimitSTACK": "18446744073709551615", "ActiveEnterTimestampMonotonic": "21926866", "StandardError": "inherit", "AssertTimestamp": "Thu 2020-02-06 03:08:53 UTC", "IgnoreOnSnapshot": "no", "StartLimitAction": "none", "EnvironmentFile": "/etc/sysconfig/httpd (ignore_errors=no)", "CPUSchedulingPriority": "0", "KillSignal": "18", "LimitFSIZE": "18446744073709551615", "IgnoreOnIsolate": "no", "LimitCPU": "18446744073709551615", "InactiveExitTimestamp": "Thu 2020-02-06 03:08:53 UTC", "NoNewPrivileges": "no", "MemoryLimit": "18446744073709551615", "CanStart": "yes", "JobTimeoutAction": "none", "Before": "shutdown.target multi-user.target", "LimitAS": "18446744073709551615", "RootDirectoryStartOnly": "no", "InactiveExitTimestampMonotonic": "21193225", "SendSIGHUP": "no", "TimeoutStartUSec": "1min 30s", "Type": "notify", "SyslogPriority": "30", "SameProcessGroup": "no", "LimitNPROC": "882", "UMask": "0022", "NonBlocking": "no", "DevicePolicy": "auto", "ExecMainStartTimestamp": "Thu 2020-02-06 03:08:53 UTC", "CapabilityBoundingSet": "18446744073709551615", "TTYReset": "no", "OOMScoreAdjust": "0", "Documentation": "man:httpd(8) man:apachectl(8)", "StartLimitBurst": "5", "RefuseManualStart": "no", "KillMode": "control-group", "SyslogLevelPrefix": "yes", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "Delegate": "no", "ExecReload": "{ path=/usr/sbin/httpd ; argv[]=/usr/sbin/httpd $OPTIONS -k graceful ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "ExecStop": "{ path=/bin/kill ; argv[]=/bin/kill -WINCH ${MAINPID} ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "SecureBits": "0", "LimitCORE": "18446744073709551615", "JobTimeoutUSec": "0", "TimerSlackNSec": "50000", "SubState": "dead", "CPUSchedulingResetOnFork": "no", "Result": "success", "CPUShares": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestampMonotonic": "21182615", "MainPID": "0", "StartupBlockIOWeight": "18446744073709551615", "ActiveEnterTimestamp": "Thu 2020-02-06 03:08:54 UTC", "FragmentPath": "/usr/lib/systemd/system/httpd.service", "StartupCPUShares": "18446744073709551615", "WatchdogUSec": "0", "ActiveState": "inactive", "Nice": "0", "LimitDATA": "18446744073709551615", "UnitFilePreset": "disabled", "MemoryCurrent": "18446744073709551615", "LimitRTTIME": "18446744073709551615", "WantedBy": "multi-user.target", "TasksCurrent": "18446744073709551615", "RestartUSec": "100ms", "ConditionTimestamp": "Thu 2020-02-06 03:08:53 UTC", "CPUAccounting": "no", "RemainAfterExit": "no", "RequiresMountsFor": "/var/tmp", "PrivateNetwork": "no", "Restart": "no", "CPUSchedulingPolicy": "0", "LimitNOFILE": "4096", "SendSIGKILL": "yes", "StatusErrno": "0", "RefuseManualStop": "no", "SystemCallErrorNumber": "0", "TasksAccounting": "no", "NeedDaemonReload": "no", "StartLimitInterval": "10000000", "InactiveEnterTimestamp": "Thu 2020-02-06 07:36:29 UTC", "StandardInput": "null", "AssertTimestampMonotonic": "21182615", "DefaultDependencies": "yes", "Requires": "basic.target -.mount", "TasksMax": "18446744073709551615", "CPUQuotaPerSecUSec": "infinity", "ExecMainStatus": "0", "LimitMEMLOCK": "65536", "StopWhenUnneeded": "no", "LimitMSGQUEUE": "819200", "AmbientCapabilities": "0", "Slice": "system.slice", "ExecMainExitTimestampMonotonic": "16074092641", "NotifyAccess": "main", "PermissionsStartOnly": "no", "BlockIOAccounting": "no", "CanStop": "yes", "PrivateTmp": "yes", "OnFailureJobMode": "replace", "AssertResult": "yes", "LimitLOCKS": "18446744073709551615", "ExecMainStartTimestampMonotonic": "21186088", "AllowIsolate": "no", "Wants": "system.slice", "After": "nss-lookup.target system.slice -.mount tmp.mount remote-fs.target basic.target systemd-journald.socket network.target", "FailureAction": "none", "CanIsolate": "no", "Conflicts": "shutdown.target", "StandardOutput": "journal", "MountFlags": "0", "InactiveEnterTimestampMonotonic": "16074092816", "StatusText": "Total requests: 0; Current requests/sec: 0; Current traffic:   0 B/sec", "MemoryAccounting": "no", "IgnoreSIGPIPE": "yes", "Transient": "no", "IOScheduling": "0", "Description": "The Apache HTTP Server", "ActiveExitTimestampMonotonic": "16073035310", "ExecMainExitTimestamp": "Thu 2020-02-06 07:36:29 UTC", "CanReload": "yes", "ControlPID": "0", "LimitNICE": "0", "BlockIOWeight": "18446744073709551615", "Names": "httpd.service", "ProtectSystem": "no", "PrivateDevices": "no", "Id": "httpd.service"}, "invocation": {"module_args": {"no_block": false, "force": null, "name": "httpd", "daemon_reexec": false, "enabled": null, "daemon_reload": false, "state": "stopped", "masked": null, "scope": null, "user": null}}, "state": "stopped", "changed": false, "name": "httpd"}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982431.46-102273853685291/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2] => {
    "changed": false, 
    "invocation": {
        "module_args": {
            "daemon_reexec": false, 
            "daemon_reload": false, 
            "enabled": null, 
            "force": null, 
            "masked": null, 
            "name": "httpd", 
            "no_block": false, 
            "scope": null, 
            "state": "stopped", 
            "user": null
        }
    }, 
    "name": "httpd", 
    "state": "stopped", 
    "status": {
        "ActiveEnterTimestamp": "Thu 2020-02-06 03:08:54 UTC", 
        "ActiveEnterTimestampMonotonic": "21926866", 
        "ActiveExitTimestamp": "Thu 2020-02-06 07:36:28 UTC", 
        "ActiveExitTimestampMonotonic": "16073035310", 
        "ActiveState": "inactive", 
        "After": "nss-lookup.target system.slice -.mount tmp.mount remote-fs.target basic.target systemd-journald.socket network.target", 
        "AllowIsolate": "no", 
        "AmbientCapabilities": "0", 
        "AssertResult": "yes", 
        "AssertTimestamp": "Thu 2020-02-06 03:08:53 UTC", 
        "AssertTimestampMonotonic": "21182615", 
        "Before": "shutdown.target multi-user.target", 
        "BlockIOAccounting": "no", 
        "BlockIOWeight": "18446744073709551615", 
        "CPUAccounting": "no", 
        "CPUQuotaPerSecUSec": "infinity", 
        "CPUSchedulingPolicy": "0", 
        "CPUSchedulingPriority": "0", 
        "CPUSchedulingResetOnFork": "no", 
        "CPUShares": "18446744073709551615", 
        "CanIsolate": "no", 
        "CanReload": "yes", 
        "CanStart": "yes", 
        "CanStop": "yes", 
        "CapabilityBoundingSet": "18446744073709551615", 
        "ConditionResult": "yes", 
        "ConditionTimestamp": "Thu 2020-02-06 03:08:53 UTC", 
        "ConditionTimestampMonotonic": "21182615", 
        "Conflicts": "shutdown.target", 
        "ControlPID": "0", 
        "DefaultDependencies": "yes", 
        "Delegate": "no", 
        "Description": "The Apache HTTP Server", 
        "DevicePolicy": "auto", 
        "Documentation": "man:httpd(8) man:apachectl(8)", 
        "EnvironmentFile": "/etc/sysconfig/httpd (ignore_errors=no)", 
        "ExecMainCode": "1", 
        "ExecMainExitTimestamp": "Thu 2020-02-06 07:36:29 UTC", 
        "ExecMainExitTimestampMonotonic": "16074092641", 
        "ExecMainPID": "2751", 
        "ExecMainStartTimestamp": "Thu 2020-02-06 03:08:53 UTC", 
        "ExecMainStartTimestampMonotonic": "21186088", 
        "ExecMainStatus": "0", 
        "ExecReload": "{ path=/usr/sbin/httpd ; argv[]=/usr/sbin/httpd $OPTIONS -k graceful ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", 
        "ExecStart": "{ path=/usr/sbin/httpd ; argv[]=/usr/sbin/httpd $OPTIONS -DFOREGROUND ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", 
        "ExecStop": "{ path=/bin/kill ; argv[]=/bin/kill -WINCH ${MAINPID} ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", 
        "FailureAction": "none", 
        "FileDescriptorStoreMax": "0", 
        "FragmentPath": "/usr/lib/systemd/system/httpd.service", 
        "GuessMainPID": "yes", 
        "IOScheduling": "0", 
        "Id": "httpd.service", 
        "IgnoreOnIsolate": "no", 
        "IgnoreOnSnapshot": "no", 
        "IgnoreSIGPIPE": "yes", 
        "InactiveEnterTimestamp": "Thu 2020-02-06 07:36:29 UTC", 
        "InactiveEnterTimestampMonotonic": "16074092816", 
        "InactiveExitTimestamp": "Thu 2020-02-06 03:08:53 UTC", 
        "InactiveExitTimestampMonotonic": "21193225", 
        "JobTimeoutAction": "none", 
        "JobTimeoutUSec": "0", 
        "KillMode": "control-group", 
        "KillSignal": "18", 
        "LimitAS": "18446744073709551615", 
        "LimitCORE": "18446744073709551615", 
        "LimitCPU": "18446744073709551615", 
        "LimitDATA": "18446744073709551615", 
        "LimitFSIZE": "18446744073709551615", 
        "LimitLOCKS": "18446744073709551615", 
        "LimitMEMLOCK": "65536", 
        "LimitMSGQUEUE": "819200", 
        "LimitNICE": "0", 
        "LimitNOFILE": "4096", 
        "LimitNPROC": "882", 
        "LimitRSS": "18446744073709551615", 
        "LimitRTPRIO": "0", 
        "LimitRTTIME": "18446744073709551615", 
        "LimitSIGPENDING": "882", 
        "LimitSTACK": "18446744073709551615", 
        "LoadState": "loaded", 
        "MainPID": "0", 
        "MemoryAccounting": "no", 
        "MemoryCurrent": "18446744073709551615", 
        "MemoryLimit": "18446744073709551615", 
        "MountFlags": "0", 
        "Names": "httpd.service", 
        "NeedDaemonReload": "no", 
        "Nice": "0", 
        "NoNewPrivileges": "no", 
        "NonBlocking": "no", 
        "NotifyAccess": "main", 
        "OOMScoreAdjust": "0", 
        "OnFailureJobMode": "replace", 
        "PermissionsStartOnly": "no", 
        "PrivateDevices": "no", 
        "PrivateNetwork": "no", 
        "PrivateTmp": "yes", 
        "ProtectHome": "no", 
        "ProtectSystem": "no", 
        "RefuseManualStart": "no", 
        "RefuseManualStop": "no", 
        "RemainAfterExit": "no", 
        "Requires": "basic.target -.mount", 
        "RequiresMountsFor": "/var/tmp", 
        "Restart": "no", 
        "RestartUSec": "100ms", 
        "Result": "success", 
        "RootDirectoryStartOnly": "no", 
        "RuntimeDirectoryMode": "0755", 
        "SameProcessGroup": "no", 
        "SecureBits": "0", 
        "SendSIGHUP": "no", 
        "SendSIGKILL": "yes", 
        "Slice": "system.slice", 
        "StandardError": "inherit", 
        "StandardInput": "null", 
        "StandardOutput": "journal", 
        "StartLimitAction": "none", 
        "StartLimitBurst": "5", 
        "StartLimitInterval": "10000000", 
        "StartupBlockIOWeight": "18446744073709551615", 
        "StartupCPUShares": "18446744073709551615", 
        "StatusErrno": "0", 
        "StatusText": "Total requests: 0; Current requests/sec: 0; Current traffic:   0 B/sec", 
        "StopWhenUnneeded": "no", 
        "SubState": "dead", 
        "SyslogLevelPrefix": "yes", 
        "SyslogPriority": "30", 
        "SystemCallErrorNumber": "0", 
        "TTYReset": "no", 
        "TTYVHangup": "no", 
        "TTYVTDisallocate": "no", 
        "TasksAccounting": "no", 
        "TasksCurrent": "18446744073709551615", 
        "TasksMax": "18446744073709551615", 
        "TimeoutStartUSec": "1min 30s", 
        "TimeoutStopUSec": "1min 30s", 
        "TimerSlackNSec": "50000", 
        "Transient": "no", 
        "Type": "notify", 
        "UMask": "0022", 
        "UnitFilePreset": "disabled", 
        "UnitFileState": "enabled", 
        "WantedBy": "multi-user.target", 
        "Wants": "system.slice", 
        "WatchdogTimestampMonotonic": "0", 
        "WatchdogUSec": "0"
    }
}
META: ran handlers

TASK [geerlingguy.nginx : Include OS-specific variables.] ********************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:3
ok: [app2] => {
    "ansible_facts": {
        "__nginx_user": "nginx", 
        "nginx_conf_file_path": "/etc/nginx/nginx.conf", 
        "nginx_conf_path": "/etc/nginx/conf.d", 
        "nginx_default_vhost_path": "/etc/nginx/conf.d/default.conf", 
        "nginx_mime_file_path": "/etc/nginx/mime.types", 
        "nginx_pidfile": "/var/run/nginx.pid", 
        "nginx_vhost_path": "/etc/nginx/conf.d", 
        "root_group": "root"
    }, 
    "ansible_included_var_files": [
        "/home/devops/project/roles/geerlingguy.nginx/vars/RedHat.yml"
    ], 
    "changed": false
}

TASK [geerlingguy.nginx : Define nginx_user.] ********************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:6
ok: [app2] => {
    "ansible_facts": {
        "nginx_user": "nginx"
    }, 
    "changed": false
}

TASK [geerlingguy.nginx : include_tasks] *************************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:12
included: /home/devops/project/roles/geerlingguy.nginx/tasks/setup-RedHat.yml for app2

TASK [geerlingguy.nginx : Enable nginx repo.] ********************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/setup-RedHat.yml:2
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991 `" && echo ansible-tmp-1580982432.89-161400838725991="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982432.89-161400838725991=/home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/files/stat.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpEFDcBb TO /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_stat.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpEFDcBb /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_stat.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpEFDcBb\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_stat.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:10178\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 10178 bytes at 98304\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/ /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_stat.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-bshosfkimbrmycucsfpqtojfzmjxfphs ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_stat.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"invocation": {"module_args": {"checksum_algorithm": "sha1", "get_checksum": true, "follow": false, "path": "/etc/yum.repos.d/nginx.repo", "get_md5": false, "get_mime": true, "get_attributes": true}}, "stat": {"charset": "us-ascii", "uid": 0, "exists": true, "attr_flags": "", "woth": false, "isreg": true, "device_type": 0, "mtime": 1580974590.8526993, "block_size": 4096, "inode": 100817500, "isgid": false, "size": 99, "executable": false, "isuid": false, "readable": true, "version": "18446744072538258389", "pw_name": "root", "gid": 0, "ischr": false, "wusr": true, "writeable": true, "mimetype": "text/plain", "blocks": 8, "xoth": false, "islnk": false, "nlink": 1, "issock": false, "rgrp": true, "gr_name": "root", "path": "/etc/yum.repos.d/nginx.repo", "xusr": false, "atime": 1580974592.4477112, "isdir": false, "ctime": 1580974591.2967026, "isblk": false, "wgrp": false, "checksum": "bff0bd4df6b8bccfb86c1b03fc1f1bc93fb7a0f2", "dev": 2049, "roth": true, "isfifo": false, "mode": "0644", "xgrp": false, "rusr": true, "attributes": []}, "changed": false}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/files/file.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpskuqJA TO /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_file.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpskuqJA /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_file.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpskuqJA\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_file.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:15539\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 15539 bytes at 98304\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/ /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_file.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-kusziljrpmszpalrbgostgobolgycguj ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/AnsiballZ_file.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"group": "root", "uid": 0, "changed": false, "owner": "root", "state": "file", "gid": 0, "secontext": "system_u:object_r:system_conf_t:s0", "mode": "0644", "path": "/etc/yum.repos.d/nginx.repo", "invocation": {"module_args": {"directory_mode": null, "force": false, "remote_src": null, "_original_basename": "nginx.repo.j2", "path": "/etc/yum.repos.d/nginx.repo", "owner": "root", "follow": false, "group": "root", "unsafe_writes": null, "state": "file", "content": null, "serole": null, "access_time": null, "setype": null, "dest": "/etc/yum.repos.d/nginx.repo", "selevel": null, "access_time_format": "%Y%m%d%H%M.%S", "modification_time": null, "regexp": null, "src": null, "seuser": null, "recurse": false, "_diff_peek": null, "delimiter": null, "mode": 420, "modification_time_format": "%Y%m%d%H%M.%S", "attributes": null, "backup": null}}, "diff": {"after": {"path": "/etc/yum.repos.d/nginx.repo"}, "before": {"path": "/etc/yum.repos.d/nginx.repo"}}, "size": 99}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982432.89-161400838725991/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2] => {
    "changed": false, 
    "checksum": "bff0bd4df6b8bccfb86c1b03fc1f1bc93fb7a0f2", 
    "dest": "/etc/yum.repos.d/nginx.repo", 
    "diff": {
        "after": {
            "path": "/etc/yum.repos.d/nginx.repo"
        }, 
        "before": {
            "path": "/etc/yum.repos.d/nginx.repo"
        }
    }, 
    "gid": 0, 
    "group": "root", 
    "invocation": {
        "module_args": {
            "_diff_peek": null, 
            "_original_basename": "nginx.repo.j2", 
            "access_time": null, 
            "access_time_format": "%Y%m%d%H%M.%S", 
            "attributes": null, 
            "backup": null, 
            "content": null, 
            "delimiter": null, 
            "dest": "/etc/yum.repos.d/nginx.repo", 
            "directory_mode": null, 
            "follow": false, 
            "force": false, 
            "group": "root", 
            "mode": 420, 
            "modification_time": null, 
            "modification_time_format": "%Y%m%d%H%M.%S", 
            "owner": "root", 
            "path": "/etc/yum.repos.d/nginx.repo", 
            "recurse": false, 
            "regexp": null, 
            "remote_src": null, 
            "selevel": null, 
            "serole": null, 
            "setype": null, 
            "seuser": null, 
            "src": null, 
            "state": "file", 
            "unsafe_writes": null
        }
    }, 
    "mode": "0644", 
    "owner": "root", 
    "path": "/etc/yum.repos.d/nginx.repo", 
    "secontext": "system_u:object_r:system_conf_t:s0", 
    "size": 99, 
    "state": "file", 
    "uid": 0
}

TASK [geerlingguy.nginx : Ensure nginx is installed.] ************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/setup-RedHat.yml:11
Running yum
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287 `" && echo ansible-tmp-1580982434.59-14083286177287="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982434.59-14083286177287=/home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/packaging/os/yum.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpzlgrtm TO /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287/AnsiballZ_yum.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpzlgrtm /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287/AnsiballZ_yum.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpzlgrtm\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287/AnsiballZ_yum.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:8 O:131072 S:20223\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 32768 bytes at 98304\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 8 20223 bytes at 131072\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287/ /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287/AnsiballZ_yum.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-wzvjusmlmzxdratldqznoqlaxpyrohlq ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287/AnsiballZ_yum.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"msg": "", "invocation": {"module_args": {"lock_timeout": 30, "update_cache": false, "disable_excludes": null, "exclude": [], "allow_downgrade": false, "disable_gpg_check": false, "conf_file": null, "use_backend": "auto", "state": "present", "disablerepo": [], "releasever": null, "skip_broken": false, "autoremove": false, "download_dir": null, "enable_plugin": [], "installroot": "/", "install_weak_deps": true, "name": ["nginx"], "download_only": false, "bugfix": false, "list": null, "install_repoquery": true, "update_only": false, "disable_plugin": [], "enablerepo": [], "security": false, "validate_certs": true}}, "changed": false, "results": ["1:nginx-1.16.1-1.el7.ngx.x86_64 providing nginx is already installed"], "rc": 0}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982434.59-14083286177287/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2] => {
    "changed": false, 
    "invocation": {
        "module_args": {
            "allow_downgrade": false, 
            "autoremove": false, 
            "bugfix": false, 
            "conf_file": null, 
            "disable_excludes": null, 
            "disable_gpg_check": false, 
            "disable_plugin": [], 
            "disablerepo": [], 
            "download_dir": null, 
            "download_only": false, 
            "enable_plugin": [], 
            "enablerepo": [], 
            "exclude": [], 
            "install_repoquery": true, 
            "install_weak_deps": true, 
            "installroot": "/", 
            "list": null, 
            "lock_timeout": 30, 
            "name": [
                "nginx"
            ], 
            "releasever": null, 
            "security": false, 
            "skip_broken": false, 
            "state": "present", 
            "update_cache": false, 
            "update_only": false, 
            "use_backend": "auto", 
            "validate_certs": true
        }
    }, 
    "msg": "", 
    "rc": 0, 
    "results": [
        "1:nginx-1.16.1-1.el7.ngx.x86_64 providing nginx is already installed"
    ]
}

TASK [geerlingguy.nginx : include_tasks] *************************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:15
skipping: [app2] => {
    "changed": false, 
    "skip_reason": "Conditional result was False"
}

TASK [geerlingguy.nginx : include_tasks] *************************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:18
skipping: [app2] => {
    "changed": false, 
    "skip_reason": "Conditional result was False"
}

TASK [geerlingguy.nginx : include_tasks] *************************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:21
skipping: [app2] => {
    "changed": false, 
    "skip_reason": "Conditional result was False"
}

TASK [geerlingguy.nginx : include_tasks] *************************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:24
skipping: [app2] => {
    "changed": false, 
    "skip_reason": "Conditional result was False"
}

TASK [geerlingguy.nginx : include_tasks] *************************************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:27
skipping: [app2] => {
    "changed": false, 
    "skip_reason": "Conditional result was False"
}

TASK [geerlingguy.nginx : Remove default nginx vhost config file (if configured).] *******************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/vhosts.yml:2
skipping: [app2] => {
    "changed": false, 
    "skip_reason": "Conditional result was False"
}

TASK [geerlingguy.nginx : Ensure nginx_vhost_path exists.] *******************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/vhosts.yml:9
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099 `" && echo ansible-tmp-1580982436.33-51158895892099="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982436.33-51158895892099=/home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/files/file.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpXVNHLn TO /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099/AnsiballZ_file.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpXVNHLn /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099/AnsiballZ_file.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpXVNHLn\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099/AnsiballZ_file.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:15412\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 15412 bytes at 98304\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099/ /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099/AnsiballZ_file.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-hiodigkfztlxrjotvjopxaisujjltscs ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099/AnsiballZ_file.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"group": "root", "uid": 0, "changed": false, "owner": "root", "state": "directory", "gid": 0, "secontext": "system_u:object_r:httpd_config_t:s0", "mode": "0755", "path": "/etc/nginx/conf.d", "invocation": {"module_args": {"directory_mode": null, "force": false, "remote_src": null, "_original_basename": null, "path": "/etc/nginx/conf.d", "owner": null, "follow": true, "group": null, "unsafe_writes": null, "state": "directory", "content": null, "serole": null, "selevel": null, "setype": null, "access_time": null, "access_time_format": "%Y%m%d%H%M.%S", "modification_time": null, "regexp": null, "src": null, "seuser": null, "recurse": false, "_diff_peek": null, "delimiter": null, "mode": null, "modification_time_format": "%Y%m%d%H%M.%S", "attributes": null, "backup": null}}, "diff": {"after": {"path": "/etc/nginx/conf.d"}, "before": {"path": "/etc/nginx/conf.d"}}, "size": 26}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982436.33-51158895892099/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2] => {
    "changed": false, 
    "diff": {
        "after": {
            "path": "/etc/nginx/conf.d"
        }, 
        "before": {
            "path": "/etc/nginx/conf.d"
        }
    }, 
    "gid": 0, 
    "group": "root", 
    "invocation": {
        "module_args": {
            "_diff_peek": null, 
            "_original_basename": null, 
            "access_time": null, 
            "access_time_format": "%Y%m%d%H%M.%S", 
            "attributes": null, 
            "backup": null, 
            "content": null, 
            "delimiter": null, 
            "directory_mode": null, 
            "follow": true, 
            "force": false, 
            "group": null, 
            "mode": null, 
            "modification_time": null, 
            "modification_time_format": "%Y%m%d%H%M.%S", 
            "owner": null, 
            "path": "/etc/nginx/conf.d", 
            "recurse": false, 
            "regexp": null, 
            "remote_src": null, 
            "selevel": null, 
            "serole": null, 
            "setype": null, 
            "seuser": null, 
            "src": null, 
            "state": "directory", 
            "unsafe_writes": null
        }
    }, 
    "mode": "0755", 
    "owner": "root", 
    "path": "/etc/nginx/conf.d", 
    "secontext": "system_u:object_r:httpd_config_t:s0", 
    "size": 26, 
    "state": "directory", 
    "uid": 0
}

TASK [geerlingguy.nginx : Add managed vhost config files.] *******************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/vhosts.yml:15

TASK [geerlingguy.nginx : Remove managed vhost config files.] ****************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/vhosts.yml:29

TASK [geerlingguy.nginx : Remove legacy vhosts.conf file.] *******************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/vhosts.yml:39
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628 `" && echo ansible-tmp-1580982437.08-116597284484628="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982437.08-116597284484628=/home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/files/file.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpcYLb2W TO /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628/AnsiballZ_file.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpcYLb2W /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628/AnsiballZ_file.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpcYLb2W\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628/AnsiballZ_file.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:15422\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 15422 bytes at 98304\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628/ /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628/AnsiballZ_file.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-hpobmdagxyoanaopcrmgfglvpscblvtu ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628/AnsiballZ_file.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"invocation": {"module_args": {"directory_mode": null, "force": false, "remote_src": null, "_original_basename": null, "path": "/etc/nginx/conf.d/vhosts.conf", "owner": null, "follow": true, "group": null, "unsafe_writes": null, "state": "absent", "content": null, "serole": null, "selevel": null, "setype": null, "access_time": null, "access_time_format": "%Y%m%d%H%M.%S", "modification_time": null, "regexp": null, "src": null, "seuser": null, "recurse": false, "_diff_peek": null, "delimiter": null, "mode": null, "modification_time_format": "%Y%m%d%H%M.%S", "attributes": null, "backup": null}}, "path": "/etc/nginx/conf.d/vhosts.conf", "state": "absent", "changed": false}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982437.08-116597284484628/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2] => {
    "changed": false, 
    "invocation": {
        "module_args": {
            "_diff_peek": null, 
            "_original_basename": null, 
            "access_time": null, 
            "access_time_format": "%Y%m%d%H%M.%S", 
            "attributes": null, 
            "backup": null, 
            "content": null, 
            "delimiter": null, 
            "directory_mode": null, 
            "follow": true, 
            "force": false, 
            "group": null, 
            "mode": null, 
            "modification_time": null, 
            "modification_time_format": "%Y%m%d%H%M.%S", 
            "owner": null, 
            "path": "/etc/nginx/conf.d/vhosts.conf", 
            "recurse": false, 
            "regexp": null, 
            "remote_src": null, 
            "selevel": null, 
            "serole": null, 
            "setype": null, 
            "seuser": null, 
            "src": null, 
            "state": "absent", 
            "unsafe_writes": null
        }
    }, 
    "path": "/etc/nginx/conf.d/vhosts.conf", 
    "state": "absent"
}

TASK [geerlingguy.nginx : Copy nginx configuration in place.] ****************************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:34
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321 `" && echo ansible-tmp-1580982437.62-96438717220321="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982437.62-96438717220321=/home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/files/stat.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpoWS0AU TO /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_stat.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpoWS0AU /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_stat.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpoWS0AU\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_stat.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:10171\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 10171 bytes at 98304\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/ /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_stat.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-fyrbcvksevclyjdxysmmymmzrqppeovs ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_stat.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"invocation": {"module_args": {"checksum_algorithm": "sha1", "get_checksum": true, "follow": false, "path": "/etc/nginx/nginx.conf", "get_md5": false, "get_mime": true, "get_attributes": true}}, "stat": {"charset": "us-ascii", "uid": 0, "exists": true, "attr_flags": "", "woth": false, "isreg": true, "device_type": 0, "mtime": 1580974629.9869955, "block_size": 4096, "inode": 6020878, "isgid": false, "size": 844, "executable": false, "isuid": false, "readable": true, "version": "18446744072480723161", "pw_name": "root", "gid": 0, "ischr": false, "wusr": true, "writeable": true, "mimetype": "text/plain", "blocks": 8, "xoth": false, "islnk": false, "nlink": 1, "issock": false, "rgrp": true, "gr_name": "root", "path": "/etc/nginx/nginx.conf", "xusr": false, "atime": 1580974631.1500044, "isdir": false, "ctime": 1580974630.2329974, "isblk": false, "wgrp": false, "checksum": "842374f2254ce888534c30c2e3e82310ba3f3c7f", "dev": 2049, "roth": true, "isfifo": false, "mode": "0644", "xgrp": false, "rusr": true, "attributes": []}, "changed": false}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/files/file.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpYyImWP TO /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_file.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpYyImWP /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_file.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmpYyImWP\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_file.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:15532\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 15532 bytes at 98304\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/ /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_file.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-twwlusyndejfiehhcvnwtztbuffzysln ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/AnsiballZ_file.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"group": "root", "uid": 0, "changed": false, "owner": "root", "state": "file", "gid": 0, "secontext": "system_u:object_r:httpd_config_t:s0", "mode": "0644", "path": "/etc/nginx/nginx.conf", "invocation": {"module_args": {"directory_mode": null, "force": false, "remote_src": null, "_original_basename": "nginx.conf.j2", "path": "/etc/nginx/nginx.conf", "owner": "root", "follow": false, "group": "root", "unsafe_writes": null, "state": "file", "content": null, "serole": null, "access_time": null, "setype": null, "dest": "/etc/nginx/nginx.conf", "selevel": null, "access_time_format": "%Y%m%d%H%M.%S", "modification_time": null, "regexp": null, "src": null, "seuser": null, "recurse": false, "_diff_peek": null, "delimiter": null, "mode": 420, "modification_time_format": "%Y%m%d%H%M.%S", "attributes": null, "backup": null}}, "diff": {"after": {"path": "/etc/nginx/nginx.conf"}, "before": {"path": "/etc/nginx/nginx.conf"}}, "size": 844}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982437.62-96438717220321/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2] => {
    "changed": false, 
    "checksum": "842374f2254ce888534c30c2e3e82310ba3f3c7f", 
    "dest": "/etc/nginx/nginx.conf", 
    "diff": {
        "after": {
            "path": "/etc/nginx/nginx.conf"
        }, 
        "before": {
            "path": "/etc/nginx/nginx.conf"
        }
    }, 
    "gid": 0, 
    "group": "root", 
    "invocation": {
        "module_args": {
            "_diff_peek": null, 
            "_original_basename": "nginx.conf.j2", 
            "access_time": null, 
            "access_time_format": "%Y%m%d%H%M.%S", 
            "attributes": null, 
            "backup": null, 
            "content": null, 
            "delimiter": null, 
            "dest": "/etc/nginx/nginx.conf", 
            "directory_mode": null, 
            "follow": false, 
            "force": false, 
            "group": "root", 
            "mode": 420, 
            "modification_time": null, 
            "modification_time_format": "%Y%m%d%H%M.%S", 
            "owner": "root", 
            "path": "/etc/nginx/nginx.conf", 
            "recurse": false, 
            "regexp": null, 
            "remote_src": null, 
            "selevel": null, 
            "serole": null, 
            "setype": null, 
            "seuser": null, 
            "src": null, 
            "state": "file", 
            "unsafe_writes": null
        }
    }, 
    "mode": "0644", 
    "owner": "root", 
    "path": "/etc/nginx/nginx.conf", 
    "secontext": "system_u:object_r:httpd_config_t:s0", 
    "size": 844, 
    "state": "file", 
    "uid": 0
}

TASK [geerlingguy.nginx : Ensure nginx service is running as configured.] ****************************
task path: /home/devops/project/roles/geerlingguy.nginx/tasks/main.yml:44
Running systemd
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'echo ~devops && sleep 0'"'"''
<192.168.3.6> (0, '/home/devops\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'( umask 77 && mkdir -p "` echo /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524 `" && echo ansible-tmp-1580982438.65-193034021912524="` echo /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524 `" ) && sleep 0'"'"''
<192.168.3.6> (0, 'ansible-tmp-1580982438.65-193034021912524=/home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
Using module file /usr/lib/python2.7/site-packages/ansible/modules/system/systemd.py
<192.168.3.6> PUT /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmp9_IUPJ TO /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524/AnsiballZ_systemd.py
<192.168.3.6> SSH: EXEC sftp -b - -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc '[192.168.3.6]'
<192.168.3.6> (0, 'sftp> put /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmp9_IUPJ /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524/AnsiballZ_systemd.py\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug2: Remote version: 3\r\ndebug2: Server supports extension "posix-rename@openssh.com" revision 1\r\ndebug2: Server supports extension "statvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "fstatvfs@openssh.com" revision 2\r\ndebug2: Server supports extension "hardlink@openssh.com" revision 1\r\ndebug2: Server supports extension "fsync@openssh.com" revision 1\r\ndebug3: Sent message fd 6 T:16 I:1\r\ndebug3: SSH_FXP_REALPATH . -> /home/devops size 0\r\ndebug3: Looking up /home/devops/.ansible/tmp/ansible-local-47441I0FYU/tmp9_IUPJ\r\ndebug3: Sent message fd 6 T:17 I:2\r\ndebug3: Received stat reply T:101 I:2\r\ndebug1: Couldn\'t stat remote file: No such file or directory\r\ndebug3: Sent message SSH2_FXP_OPEN I:3 P:/home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524/AnsiballZ_systemd.py\r\ndebug3: Sent message SSH2_FXP_WRITE I:4 O:0 S:32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 4 32768 bytes at 0\r\ndebug3: Sent message SSH2_FXP_WRITE I:5 O:32768 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:6 O:65536 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:7 O:98304 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:8 O:131072 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:9 O:163840 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:10 O:196608 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:11 O:229376 S:32768\r\ndebug3: Sent message SSH2_FXP_WRITE I:12 O:262144 S:2313\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 5 32768 bytes at 32768\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 6 32768 bytes at 65536\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 7 32768 bytes at 98304\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 8 32768 bytes at 131072\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 9 32768 bytes at 163840\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 10 32768 bytes at 196608\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 11 32768 bytes at 229376\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: In write loop, ack for 12 2313 bytes at 262144\r\ndebug3: Sent message SSH2_FXP_CLOSE I:4\r\ndebug3: SSH2_FXP_STATUS 0\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'chmod u+x /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524/ /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524/AnsiballZ_systemd.py && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc -tt 192.168.3.6 '/bin/sh -c '"'"'sudo -H -S -n  -u root /bin/sh -c '"'"'"'"'"'"'"'"'echo BECOME-SUCCESS-kqoyimgnqpnbmyhtmmormqfwzhrpftpv ; /usr/bin/python /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524/AnsiballZ_systemd.py'"'"'"'"'"'"'"'"' && sleep 0'"'"''
Escalation succeeded
<192.168.3.6> (0, '\r\n{"status": {"ExecStart": "{ path=/usr/sbin/nginx ; argv[]=/usr/sbin/nginx -c /etc/nginx/nginx.conf ; ignore_errors=no ; start_time=[Thu 2020-02-06 07:37:11 UTC] ; stop_time=[Thu 2020-02-06 07:37:11 UTC] ; pid=4847 ; code=exited ; status=0 }", "TimeoutStopUSec": "1min 30s", "ControlGroup": "/system.slice/nginx.service", "RuntimeDirectoryMode": "0755", "GuessMainPID": "yes", "ExecMainCode": "0", "UnitFileState": "enabled", "ExecMainPID": "4848", "LimitSIGPENDING": "882", "FileDescriptorStoreMax": "0", "LoadState": "loaded", "ProtectHome": "no", "TTYVTDisallocate": "no", "StartLimitInterval": "10000000", "WatchdogTimestampMonotonic": "0", "LimitSTACK": "18446744073709551615", "ActiveEnterTimestampMonotonic": "16115357988", "AllowIsolate": "no", "AssertTimestamp": "Thu 2020-02-06 07:37:11 UTC", "IgnoreOnSnapshot": "no", "StartLimitAction": "none", "CPUSchedulingPriority": "0", "KillSignal": "15", "LimitFSIZE": "18446744073709551615", "IgnoreOnIsolate": "no", "LimitCPU": "18446744073709551615", "InactiveExitTimestamp": "Thu 2020-02-06 07:37:11 UTC", "NoNewPrivileges": "no", "MemoryLimit": "18446744073709551615", "TTYReset": "no", "CanStart": "yes", "JobTimeoutAction": "none", "Before": "shutdown.target multi-user.target", "LimitAS": "18446744073709551615", "RootDirectoryStartOnly": "no", "InactiveExitTimestampMonotonic": "16115332628", "SendSIGHUP": "no", "TimeoutStartUSec": "1min 30s", "Type": "forking", "SyslogPriority": "30", "SameProcessGroup": "no", "LimitNPROC": "882", "UMask": "0022", "NonBlocking": "no", "DevicePolicy": "auto", "ExecMainStartTimestamp": "Thu 2020-02-06 07:37:11 UTC", "CapabilityBoundingSet": "18446744073709551615", "PIDFile": "/var/run/nginx.pid", "OOMScoreAdjust": "0", "Documentation": "http://nginx.org/en/docs/", "StartLimitBurst": "5", "RefuseManualStart": "no", "KillMode": "control-group", "SyslogLevelPrefix": "yes", "LimitRSS": "18446744073709551615", "LimitRTPRIO": "0", "Delegate": "no", "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[Thu 2020-02-06 07:37:11 UTC] ; stop_time=[Thu 2020-02-06 07:37:11 UTC] ; pid=4934 ; code=exited ; status=0 }", "ExecStop": "{ path=/bin/kill ; argv[]=/bin/kill -s TERM $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", "TasksCurrent": "18446744073709551615", "LimitCORE": "18446744073709551615", "JobTimeoutUSec": "0", "TimerSlackNSec": "50000", "SubState": "running", "CPUSchedulingResetOnFork": "no", "Result": "success", "CPUShares": "18446744073709551615", "ConditionResult": "yes", "ConditionTimestampMonotonic": "16115331585", "MainPID": "4848", "StartupBlockIOWeight": "18446744073709551615", "ActiveEnterTimestamp": "Thu 2020-02-06 07:37:11 UTC", "FragmentPath": "/usr/lib/systemd/system/nginx.service", "StartupCPUShares": "18446744073709551615", "WatchdogUSec": "0", "ActiveState": "active", "Nice": "0", "LimitDATA": "18446744073709551615", "UnitFilePreset": "disabled", "MemoryCurrent": "18446744073709551615", "LimitRTTIME": "18446744073709551615", "WantedBy": "multi-user.target", "SecureBits": "0", "RestartUSec": "100ms", "ConditionTimestamp": "Thu 2020-02-06 07:37:11 UTC", "CPUAccounting": "no", "RemainAfterExit": "no", "PrivateNetwork": "no", "Restart": "no", "CPUSchedulingPolicy": "0", "LimitNOFILE": "4096", "SendSIGKILL": "yes", "StatusErrno": "0", "RefuseManualStop": "no", "SystemCallErrorNumber": "0", "TasksAccounting": "no", "NeedDaemonReload": "no", "TTYVHangup": "no", "StandardInput": "null", "AssertTimestampMonotonic": "16115331585", "DefaultDependencies": "yes", "Requires": "basic.target", "TasksMax": "18446744073709551615", "CPUQuotaPerSecUSec": "infinity", "ExecMainStatus": "0", "LimitMEMLOCK": "65536", "StopWhenUnneeded": "no", "LimitMSGQUEUE": "819200", "AmbientCapabilities": "0", "Slice": "system.slice", "ExecMainExitTimestampMonotonic": "0", "NotifyAccess": "none", "PermissionsStartOnly": "no", "BlockIOAccounting": "no", "CanStop": "yes", "PrivateTmp": "no", "OnFailureJobMode": "replace", "AssertResult": "yes", "LimitLOCKS": "18446744073709551615", "ExecMainStartTimestampMonotonic": "16115357801", "StandardError": "inherit", "Wants": "system.slice network-online.target", "After": "remote-fs.target network-online.target systemd-journald.socket basic.target system.slice nss-lookup.target", "FailureAction": "none", "CanIsolate": "no", "Conflicts": "shutdown.target", "StandardOutput": "journal", "MountFlags": "0", "InactiveEnterTimestampMonotonic": "0", "MemoryAccounting": "no", "IgnoreSIGPIPE": "yes", "Transient": "no", "IOScheduling": "0", "Description": "nginx - high performance web server", "ActiveExitTimestampMonotonic": "0", "CanReload": "yes", "ControlPID": "0", "LimitNICE": "0", "BlockIOWeight": "18446744073709551615", "Names": "nginx.service", "ProtectSystem": "no", "PrivateDevices": "no", "Id": "nginx.service"}, "name": "nginx", "changed": false, "enabled": true, "state": "started", "invocation": {"module_args": {"no_block": false, "force": null, "name": "nginx", "daemon_reexec": false, "enabled": true, "daemon_reload": false, "state": "started", "masked": null, "scope": null, "user": null}}}\r\n', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\nShared connection to 192.168.3.6 closed.\r\n')
<192.168.3.6> ESTABLISH SSH CONNECTION FOR USER: devops
<192.168.3.6> SSH: EXEC ssh -vvv -C -o ControlMaster=auto -o ControlPersist=60s -o KbdInteractiveAuthentication=no -o PreferredAuthentications=gssapi-with-mic,gssapi-keyex,hostbased,publickey -o PasswordAuthentication=no -o 'User="devops"' -o ConnectTimeout=10 -o ControlPath=/home/devops/.ansible/cp/661fd496dc 192.168.3.6 '/bin/sh -c '"'"'rm -f -r /home/devops/.ansible/tmp/ansible-tmp-1580982438.65-193034021912524/ > /dev/null 2>&1 && sleep 0'"'"''
<192.168.3.6> (0, '', 'OpenSSH_7.4p1, OpenSSL 1.0.2k-fips  26 Jan 2017\r\ndebug1: Reading configuration data /etc/ssh/ssh_config\r\ndebug1: /etc/ssh/ssh_config line 58: Applying options for *\r\ndebug1: auto-mux: Trying existing master\r\ndebug2: fd 3 setting O_NONBLOCK\r\ndebug2: mux_client_hello_exchange: master version 4\r\ndebug3: mux_client_forwards: request forwardings: 0 local, 0 remote\r\ndebug3: mux_client_request_session: entering\r\ndebug3: mux_client_request_alive: entering\r\ndebug3: mux_client_request_alive: done pid = 4757\r\ndebug3: mux_client_request_session: session request sent\r\ndebug1: mux_client_request_session: master session id: 2\r\ndebug3: mux_client_read_packet: read header failed: Broken pipe\r\ndebug2: Received exit status from master 0\r\n')
ok: [app2] => {
    "changed": false, 
    "enabled": true, 
    "invocation": {
        "module_args": {
            "daemon_reexec": false, 
            "daemon_reload": false, 
            "enabled": true, 
            "force": null, 
            "masked": null, 
            "name": "nginx", 
            "no_block": false, 
            "scope": null, 
            "state": "started", 
            "user": null
        }
    }, 
    "name": "nginx", 
    "state": "started", 
    "status": {
        "ActiveEnterTimestamp": "Thu 2020-02-06 07:37:11 UTC", 
        "ActiveEnterTimestampMonotonic": "16115357988", 
        "ActiveExitTimestampMonotonic": "0", 
        "ActiveState": "active", 
        "After": "remote-fs.target network-online.target systemd-journald.socket basic.target system.slice nss-lookup.target", 
        "AllowIsolate": "no", 
        "AmbientCapabilities": "0", 
        "AssertResult": "yes", 
        "AssertTimestamp": "Thu 2020-02-06 07:37:11 UTC", 
        "AssertTimestampMonotonic": "16115331585", 
        "Before": "shutdown.target multi-user.target", 
        "BlockIOAccounting": "no", 
        "BlockIOWeight": "18446744073709551615", 
        "CPUAccounting": "no", 
        "CPUQuotaPerSecUSec": "infinity", 
        "CPUSchedulingPolicy": "0", 
        "CPUSchedulingPriority": "0", 
        "CPUSchedulingResetOnFork": "no", 
        "CPUShares": "18446744073709551615", 
        "CanIsolate": "no", 
        "CanReload": "yes", 
        "CanStart": "yes", 
        "CanStop": "yes", 
        "CapabilityBoundingSet": "18446744073709551615", 
        "ConditionResult": "yes", 
        "ConditionTimestamp": "Thu 2020-02-06 07:37:11 UTC", 
        "ConditionTimestampMonotonic": "16115331585", 
        "Conflicts": "shutdown.target", 
        "ControlGroup": "/system.slice/nginx.service", 
        "ControlPID": "0", 
        "DefaultDependencies": "yes", 
        "Delegate": "no", 
        "Description": "nginx - high performance web server", 
        "DevicePolicy": "auto", 
        "Documentation": "http://nginx.org/en/docs/", 
        "ExecMainCode": "0", 
        "ExecMainExitTimestampMonotonic": "0", 
        "ExecMainPID": "4848", 
        "ExecMainStartTimestamp": "Thu 2020-02-06 07:37:11 UTC", 
        "ExecMainStartTimestampMonotonic": "16115357801", 
        "ExecMainStatus": "0", 
        "ExecReload": "{ path=/bin/kill ; argv[]=/bin/kill -s HUP $MAINPID ; ignore_errors=no ; start_time=[Thu 2020-02-06 07:37:11 UTC] ; stop_time=[Thu 2020-02-06 07:37:11 UTC] ; pid=4934 ; code=exited ; status=0 }", 
        "ExecStart": "{ path=/usr/sbin/nginx ; argv[]=/usr/sbin/nginx -c /etc/nginx/nginx.conf ; ignore_errors=no ; start_time=[Thu 2020-02-06 07:37:11 UTC] ; stop_time=[Thu 2020-02-06 07:37:11 UTC] ; pid=4847 ; code=exited ; status=0 }", 
        "ExecStop": "{ path=/bin/kill ; argv[]=/bin/kill -s TERM $MAINPID ; ignore_errors=no ; start_time=[n/a] ; stop_time=[n/a] ; pid=0 ; code=(null) ; status=0/0 }", 
        "FailureAction": "none", 
        "FileDescriptorStoreMax": "0", 
        "FragmentPath": "/usr/lib/systemd/system/nginx.service", 
        "GuessMainPID": "yes", 
        "IOScheduling": "0", 
        "Id": "nginx.service", 
        "IgnoreOnIsolate": "no", 
        "IgnoreOnSnapshot": "no", 
        "IgnoreSIGPIPE": "yes", 
        "InactiveEnterTimestampMonotonic": "0", 
        "InactiveExitTimestamp": "Thu 2020-02-06 07:37:11 UTC", 
        "InactiveExitTimestampMonotonic": "16115332628", 
        "JobTimeoutAction": "none", 
        "JobTimeoutUSec": "0", 
        "KillMode": "control-group", 
        "KillSignal": "15", 
        "LimitAS": "18446744073709551615", 
        "LimitCORE": "18446744073709551615", 
        "LimitCPU": "18446744073709551615", 
        "LimitDATA": "18446744073709551615", 
        "LimitFSIZE": "18446744073709551615", 
        "LimitLOCKS": "18446744073709551615", 
        "LimitMEMLOCK": "65536", 
        "LimitMSGQUEUE": "819200", 
        "LimitNICE": "0", 
        "LimitNOFILE": "4096", 
        "LimitNPROC": "882", 
        "LimitRSS": "18446744073709551615", 
        "LimitRTPRIO": "0", 
        "LimitRTTIME": "18446744073709551615", 
        "LimitSIGPENDING": "882", 
        "LimitSTACK": "18446744073709551615", 
        "LoadState": "loaded", 
        "MainPID": "4848", 
        "MemoryAccounting": "no", 
        "MemoryCurrent": "18446744073709551615", 
        "MemoryLimit": "18446744073709551615", 
        "MountFlags": "0", 
        "Names": "nginx.service", 
        "NeedDaemonReload": "no", 
        "Nice": "0", 
        "NoNewPrivileges": "no", 
        "NonBlocking": "no", 
        "NotifyAccess": "none", 
        "OOMScoreAdjust": "0", 
        "OnFailureJobMode": "replace", 
        "PIDFile": "/var/run/nginx.pid", 
        "PermissionsStartOnly": "no", 
        "PrivateDevices": "no", 
        "PrivateNetwork": "no", 
        "PrivateTmp": "no", 
        "ProtectHome": "no", 
        "ProtectSystem": "no", 
        "RefuseManualStart": "no", 
        "RefuseManualStop": "no", 
        "RemainAfterExit": "no", 
        "Requires": "basic.target", 
        "Restart": "no", 
        "RestartUSec": "100ms", 
        "Result": "success", 
        "RootDirectoryStartOnly": "no", 
        "RuntimeDirectoryMode": "0755", 
        "SameProcessGroup": "no", 
        "SecureBits": "0", 
        "SendSIGHUP": "no", 
        "SendSIGKILL": "yes", 
        "Slice": "system.slice", 
        "StandardError": "inherit", 
        "StandardInput": "null", 
        "StandardOutput": "journal", 
        "StartLimitAction": "none", 
        "StartLimitBurst": "5", 
        "StartLimitInterval": "10000000", 
        "StartupBlockIOWeight": "18446744073709551615", 
        "StartupCPUShares": "18446744073709551615", 
        "StatusErrno": "0", 
        "StopWhenUnneeded": "no", 
        "SubState": "running", 
        "SyslogLevelPrefix": "yes", 
        "SyslogPriority": "30", 
        "SystemCallErrorNumber": "0", 
        "TTYReset": "no", 
        "TTYVHangup": "no", 
        "TTYVTDisallocate": "no", 
        "TasksAccounting": "no", 
        "TasksCurrent": "18446744073709551615", 
        "TasksMax": "18446744073709551615", 
        "TimeoutStartUSec": "1min 30s", 
        "TimeoutStopUSec": "1min 30s", 
        "TimerSlackNSec": "50000", 
        "Transient": "no", 
        "Type": "forking", 
        "UMask": "0022", 
        "UnitFilePreset": "disabled", 
        "UnitFileState": "enabled", 
        "WantedBy": "multi-user.target", 
        "Wants": "system.slice network-online.target", 
        "WatchdogTimestampMonotonic": "0", 
        "WatchdogUSec": "0"
    }
}
META: ran handlers

TASK [debug] *****************************************************************************************
task path: /home/devops/project/nginx.yml:12
ok: [app2] => {
    "msg": "NGINX Installed Successfully"
}
META: ran handlers

PLAY RECAP *******************************************************************************************
app2                       : ok=12   changed=0    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   

[devops@app1 project]$ vi ansible.log 
[devops@app1 project]$ vi ansible.log 
[devops@app1 project]$ ansible-playbook nginx.yml  --list-tasks

playbook: nginx.yml

  play #1 (webserver): Play for NGINX from Ansible Galaxy   TAGS: []
    tasks:
      service   TAGS: []
      geerlingguy.nginx : Include OS-specific variables.    TAGS: []
      geerlingguy.nginx : Define nginx_user.    TAGS: []
      include_tasks TAGS: []
      include_tasks TAGS: []
      include_tasks TAGS: []
      include_tasks TAGS: []
      include_tasks TAGS: []
      include_tasks TAGS: []
      geerlingguy.nginx : Remove default nginx vhost config file (if configured).   TAGS: []
      geerlingguy.nginx : Ensure nginx_vhost_path exists.   TAGS: []
      geerlingguy.nginx : Add managed vhost config files.   TAGS: [skip_ansible_lint]
      geerlingguy.nginx : Remove managed vhost config files.    TAGS: [skip_ansible_lint]
      geerlingguy.nginx : Remove legacy vhosts.conf file.   TAGS: []
      geerlingguy.nginx : Copy nginx configuration in place.    TAGS: []
      geerlingguy.nginx : Ensure nginx service is running as configured.    TAGS: []
      debug TAGS: []
[devops@app1 project]$ ansible-playbook nginx.yml  --start-at-task="Copy nginx configuration in place"
 
PLAY [Play for NGINX from Ansible Galaxy] ************************************************************

PLAY RECAP *******************************************************************************************

 [ERROR]: No matching task "Copy nginx configuration in place" found. Note: --start-at-task can only
follow static includes.

[devops@app1 project]$ ansible-playbook nginx.yml  --start-at-task="Copy nginx configuration in place."

PLAY [Play for NGINX from Ansible Galaxy] ************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [geerlingguy.nginx : Copy nginx configuration in place.] ****************************************
fatal: [app2]: FAILED! => {"msg": "The task includes an option with an undefined variable. The error was: 'nginx_conf_file_path' is undefined\n\nThe error appears to be in '/home/devops/project/roles/geerlingguy.nginx/tasks/main.yml': line 34, column 3, but may\nbe elsewhere in the file depending on the exact syntax problem.\n\nThe offending line appears to be:\n\n# Nginx setup.\n- name: Copy nginx configuration in place.\n  ^ here\n"}

PLAY RECAP *******************************************************************************************
app2                       : ok=1    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible-playbook -C nginx.yml  

PLAY [Play for NGINX from Ansible Galaxy] ************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [service] ***************************************************************************************
ok: [app2]

TASK [geerlingguy.nginx : Include OS-specific variables.] ********************************************
ok: [app2]

TASK [geerlingguy.nginx : Define nginx_user.] ********************************************************
ok: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
included: /home/devops/project/roles/geerlingguy.nginx/tasks/setup-RedHat.yml for app2

TASK [geerlingguy.nginx : Enable nginx repo.] ********************************************************
ok: [app2]

TASK [geerlingguy.nginx : Ensure nginx is installed.] ************************************************
ok: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : include_tasks] *************************************************************
skipping: [app2]

TASK [geerlingguy.nginx : Remove default nginx vhost config file (if configured).] *******************
skipping: [app2]

TASK [geerlingguy.nginx : Ensure nginx_vhost_path exists.] *******************************************
ok: [app2]

TASK [geerlingguy.nginx : Add managed vhost config files.] *******************************************

TASK [geerlingguy.nginx : Remove managed vhost config files.] ****************************************

TASK [geerlingguy.nginx : Remove legacy vhosts.conf file.] *******************************************
ok: [app2]

TASK [geerlingguy.nginx : Copy nginx configuration in place.] ****************************************
ok: [app2]

TASK [geerlingguy.nginx : Ensure nginx service is running as configured.] ****************************
ok: [app2]

TASK [debug] *****************************************************************************************
ok: [app2] => {
    "msg": "NGINX Installed Successfully"
}

PLAY RECAP *******************************************************************************************
app2                       : ok=12   changed=0    unreachable=0    failed=0    skipped=8    rescued=0    ignored=0   

[devops@app1 project]$ ansible-playbook nginx.yml  --step

PLAY [Play for NGINX from Ansible Galaxy] ************************************************************
Perform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: n

Perform task: TASK: Gathering Facts (N)o/(y)es/(c)ontinue: *******************************************
Perform task: TASK: service (N)o/(y)es/(c)ontinue: n

Perform task: TASK: service (N)o/(y)es/(c)ontinue: ***************************************************
Perform task: TASK: geerlingguy.nginx : Include OS-specific variables. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Include OS-specific variables. (N)o/(y)es/(c)ontinue: ********
Perform task: TASK: geerlingguy.nginx : Define nginx_user. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Define nginx_user. (N)o/(y)es/(c)ontinue: ********************
Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: *************************
Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: *************************
Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: *************************
Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: *************************
Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: *************************
Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : include_tasks (N)o/(y)es/(c)ontinue: *************************
Perform task: TASK: geerlingguy.nginx : Remove default nginx vhost config file (if configured). (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Remove default nginx vhost config file (if configured). (N)o/(y)es/(c)ontinue: ***
Perform task: TASK: geerlingguy.nginx : Ensure nginx_vhost_path exists. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Ensure nginx_vhost_path exists. (N)o/(y)es/(c)ontinue: *******
Perform task: TASK: geerlingguy.nginx : Add managed vhost config files. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Add managed vhost config files. (N)o/(y)es/(c)ontinue: *******
Perform task: TASK: geerlingguy.nginx : Remove managed vhost config files. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Remove managed vhost config files. (N)o/(y)es/(c)ontinue: ****
Perform task: TASK: geerlingguy.nginx : Remove legacy vhosts.conf file. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Remove legacy vhosts.conf file. (N)o/(y)es/(c)ontinue: *******
Perform task: TASK: geerlingguy.nginx : Copy nginx configuration in place. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Copy nginx configuration in place. (N)o/(y)es/(c)ontinue: ****
Perform task: TASK: geerlingguy.nginx : Ensure nginx service is running as configured. (N)o/(y)es/(c)ontinue: n

Perform task: TASK: geerlingguy.nginx : Ensure nginx service is running as configured. (N)o/(y)es/(c)ontinue: ***
Perform task: TASK: debug (N)o/(y)es/(c)ontinue: n

Perform task: TASK: debug (N)o/(y)es/(c)ontinue: *****************************************************

PLAY RECAP *******************************************************************************************

[devops@app1 project]$ cat hosts.
hosts.j2   hosts.yml  
[devops@app1 project]$ cat hosts.yml 
---
- name: Play1
  hosts: all
  tasks:
    - template: src=hosts.j2 dest=/tmp/hosts

    #- template:
    #   src: hosts.j2
    #   dest: /tmp/hosts
    - command: hostname
      
[devops@app1 project]$ changed_when: false
-bash: changed_when:: command not found
[devops@app1 project]$ vi hosts.yml 
[devops@app1 project]$ ansible-playbook hosts.yml 

PLAY [Play1] *****************************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [template] **************************************************************************************
ok: [app2]
ok: [app3]

TASK [command] ***************************************************************************************
ok: [app2]
ok: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=3    changed=0    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ cat hosts.yml 
---
- name: Play1
  hosts: all
  tasks:
    - template: src=hosts.j2 dest=/tmp/hosts

    #- template:
    #   src: hosts.j2
    #   dest: /tmp/hosts
    - command: hostname
      changed_when: false
[devops@app1 project]$ vim hosts.yml 
[devops@app1 project]$ ansible-playbook hosts.yml 
ERROR! conflicting action statements: debug, msg

The error appears to be in '/home/devops/project/hosts.yml': line 13, column 7, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:


    - debug:
      ^ here

[devops@app1 project]$ vim hosts.yml 
[devops@app1 project]$ ansible-playbook hosts.yml 

PLAY [Play1] *****************************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [template] **************************************************************************************
ok: [app2]
ok: [app3]

TASK [command] ***************************************************************************************
ok: [app2]
ok: [app3]

TASK [debug] *****************************************************************************************
fatal: [app2]: FAILED! => {"msg": "Invalid options for debug: verbose"}
fatal: [app3]: FAILED! => {"msg": "Invalid options for debug: verbose"}

PLAY RECAP *******************************************************************************************
app2                       : ok=3    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   
app3                       : ok=3    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible-doc msg
[WARNING]: module msg not found in:
/home/devops/.ansible/plugins/modules:/usr/share/ansible/plugins/modules:/usr/lib/python2.7/site-
packages/ansible/modules

[devops@app1 project]$ ansible-doc debug
> DEBUG    (/usr/lib/python2.7/site-packages/ansible/modules/utilities/logic/debug.py)

        This module prints statements during execution and can be useful for
        debugging variables or expressions without necessarily halting the
        playbook. Useful for debugging together with the 'when:' directive. This
        module is also supported for Windows targets.

  * This module is maintained by The Ansible Core Team
  * note: This module has a corresponding action plugin.

OPTIONS (= is mandatory):

- msg
        The customized message that is printed. If omitted, prints a generic
        message.
        [Default: Hello world!]
        type: str

- var
        A variable name to debug.
        Mutually exclusive with the `msg' option.
        Be aware that this option already runs in Jinja2 context and has an
        implicit `{{ }}' wrapping, so you should not be using Jinja2 delimiters
        unless you are looking for double interpolation.
        [Default: (null)]
        type: str

- verbosity
        A number that controls when the debug is run, if you set to 3 it will
        only run debug when -vvv or above
        [Default: 0]
        type: int
        version_added: 2.1


NOTES:
      * This module is also supported for Windows targets.


SEE ALSO:
      * Module assert
           The official documentation on the assert module.
           https://docs.ansible.com/ansible/2.9/modules/assert_module.html
      * Module fail
           The official documentation on the fail module.
           https://docs.ansible.com/ansible/2.9/modules/fail_module.html


AUTHOR: Dag Wieers (@dagwieers), Michael DeHaan
        METADATA:
          status:
          - stableinterface
          supported_by: core
...skipping...
           The official documentation on the fail module.
           https://docs.ansible.com/ansible/2.9/modules/fail_module.html


AUTHOR: Dag Wieers (@dagwieers), Michael DeHaan
        METADATA:
          status:
          - stableinterface
          supported_by: core
        

EXAMPLES:

# Example that prints the loopback address and gateway for each host
- debug:
    msg: System {{ inventory_hostname }} has uuid {{ ansible_product_uuid }}

- debug:
    msg: System {{ inventory_hostname }} has gateway {{ ansible_default_ipv4.gateway }}
  when: ansible_default_ipv4.gateway is defined

# Example that prints return information from the previous task
- shell: /usr/bin/uptime
  register: result

- debug:
    var: result
    verbosity: 2

- name: Display all variables/facts known for a host
  debug:
    var: hostvars[inventory_hostname]
    verbosity: 4

# Example that prints two lines of messages, but only if there is an environment value set
- debug:
    msg:
    - "Provisioning based on YOUR_KEY which is: {{ lookup('env', 'YOUR_KEY') }}"
    - "These servers were built using the password of '{{ password_used }}'. Please retain this for la


[devops@app1 project]$ !
[devops@app1 project]$ vim hosts.yml 
[devops@app1 project]$ cat hosts.yml 
---
- name: Play1
  hosts: all
  tasks:
    - template: src=hosts.j2 dest=/tmp/hosts

    #- template:
    #   src: hosts.j2
    #   dest: /tmp/hosts
    - command: hostname
      changed_when: false

    - debug:
        msg: "Hello from Ansible"
        verbosity: 4
[devops@app1 project]$ ansible-playbook hosts.yml 

PLAY [Play1] *****************************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [template] **************************************************************************************
ok: [app2]
ok: [app3]

TASK [command] ***************************************************************************************
ok: [app2]
ok: [app3]

TASK [debug] *****************************************************************************************
skipping: [app2]
skipping: [app3]

PLAY RECAP *******************************************************************************************
app2                       : ok=3    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   
app3                       : ok=3    changed=0    unreachable=0    failed=0    skipped=1    rescued=0    ignored=0   

[devops@app1 project]$ vi tags.yml
[devops@app1 project]$ ansible-playbook tags.yml --list-tasks
ERROR! Syntax Error while loading YAML.
  mapping values are not allowed in this context

The error appears to be in '/home/devops/project/tags.yml': line 2, column 25, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

---
- name: playook for tags:
                        ^ here

[devops@app1 project]$ vi tags.yml
[devops@app1 project]$ ansible-playbook tags.yml --list-tasks

playbook: tags.yml

  play #1 (all): playook for tags   TAGS: []
    tasks:
      yum   TAGS: [web]
      service   TAGS: [web]
      service   TAGS: [web]
      yum   TAGS: [db]
      service   TAGS: [db]
[devops@app1 project]$ ansible-playbook tags.yml --tags web

PLAY [playook for tags] ******************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]
ok: [app3]

TASK [yum] *******************************************************************************************
ok: [app2]
ok: [app3]

TASK [service] ***************************************************************************************
changed: [app2]
fatal: [app3]: FAILED! => {"changed": false, "msg": "Could not find the requested service nginx: host"}

TASK [service] ***************************************************************************************
changed: [app2]

PLAY RECAP *******************************************************************************************
app2                       : ok=4    changed=2    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   
app3                       : ok=2    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible app2 -a "init 0"
app2 | UNREACHABLE! => {
    "changed": false, 
    "msg": "Failed to connect to the host via ssh: Shared connection to 192.168.3.6 closed.", 
    "unreachable": true
}
[devops@app1 project]$ ansible app2 -m ping
app2 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ ansible app2 -a lsblk
app2 | CHANGED | rc=0 >>
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0  40G  0 disk 
`-sda1   8:1    0  40G  0 part /

[devops@app1 project]$ ansible app2 -m ping
app2 | SUCCESS => {
    "ansible_facts": {
        "discovered_interpreter_python": "/usr/bin/python"
    }, 
    "changed": false, 
    "ping": "pong"
}
[devops@app1 project]$ ansible app2 -a lsblk
app2 | CHANGED | rc=0 >>
NAME   MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
sda      8:0    0  40G  0 disk 
`-sda1   8:1    0  40G  0 part /
sdb      8:16   0   2G  0 disk 

[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ ansible-playbook lsblk.yml --syntax-check

playbook: lsblk.yml
[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ ansible-playbook lsblk.yml 

PLAY [Play for LVM] **********************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Creating a Partition] **************************************************************************
changed: [app2]

TASK [Creating a Volume Group] ***********************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "Failed to find required executable pvs in paths: /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin"}

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=1    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ ll /dev/sdb
ls: cannot access /dev/sdb: No such file or directory
[devops@app1 project]$ ll /dev/
total 0
lrwxrwxrwx. 1 root    root          15 Feb  6 03:08 stdout -> /proc/self/fd/1
lrwxrwxrwx. 1 root    root          15 Feb  6 03:08 stdin -> /proc/self/fd/0
lrwxrwxrwx. 1 root    root          15 Feb  6 03:08 stderr -> /proc/self/fd/2
lrwxrwxrwx. 1 root    root          13 Feb  6 03:08 fd -> /proc/self/fd
lrwxrwxrwx. 1 root    root          11 Feb  6 03:08 core -> /proc/kcore
srw-rw-rw-. 1 root    root           0 Feb  6 03:08 log
drwxr-xr-x. 2 root    root          60 Feb  6 03:08 bsg
drwxr-xr-x. 5 root    root         100 Feb  6 03:08 disk
drwxr-xr-x. 2 root    root          80 Feb  6 03:08 block
lrwxrwxrwx. 1 root    root          25 Feb  6 03:08 initctl -> /run/systemd/initctl/fifo
drwxr-xr-x. 2 root    root           0 Feb  6 03:08 hugepages
crw-------. 1 root    root     10, 238 Feb  6 03:08 vhost-net
crw-------. 1 root    root     10, 137 Feb  6 03:08 vhci
drwxr-xr-x. 2 root    root          60 Feb  6 03:08 vfio
crw-------. 1 root    root     10, 223 Feb  6 03:08 uinput
crw-------. 1 root    root     10, 239 Feb  6 03:08 uhid
crw-------. 1 root    root    108,   0 Feb  6 03:08 ppp
drwxr-xr-x. 2 root    root          60 Feb  6 03:08 net
drwxr-xr-x. 2 root    root          60 Feb  6 03:08 mapper
crw-------. 1 root    root     10, 234 Feb  6 03:08 btrfs-control
crw-rw----. 1 root    disk     10, 237 Feb  6 03:08 loop-control
crw-rw-rw-. 1 root    root     10, 229 Feb  6 03:08 fuse
brw-rw----. 1 root    disk      8,   0 Feb  6 03:08 sda
crw-------. 1 root    root    252,   0 Feb  6 03:08 rtc0
lrwxrwxrwx. 1 root    root           4 Feb  6 03:08 rtc -> rtc0
brw-rw----. 1 root    disk      8,   1 Feb  6 03:08 sda1
crw-rw----. 1 root    dialout   4,  65 Feb  6 03:08 ttyS1
crw-rw----. 1 root    dialout   4,  66 Feb  6 03:08 ttyS2
crw-rw----. 1 root    dialout   4,  64 Feb  6 03:08 ttyS0
crw-rw----. 1 root    dialout   4,  67 Feb  6 03:08 ttyS3
crw-r--r--. 1 root    root      1,  11 Feb  6 03:08 kmsg
crw-rw-rw-. 1 root    root      1,   7 Feb  6 03:08 full
crw-r-----. 1 root    kmem      1,   1 Feb  6 03:08 mem
crw-r-----. 1 root    kmem      1,   4 Feb  6 03:08 port
crw-rw-rw-. 1 root    root      1,   3 Feb  6 03:08 null
crw-rw-rw-. 1 root    root      1,   9 Feb  6 03:08 urandom
crw-rw-rw-. 1 root    root      1,   8 Feb  6 03:08 random
crw-rw-rw-. 1 root    root      1,   5 Feb  6 03:08 zero
crw-------. 1 root    root     10,  61 Feb  6 03:08 cpu_dma_latency
crw-------. 1 root    root     10, 235 Feb  6 03:08 autofs
crw-------. 1 root    root     10, 228 Feb  6 03:08 hpet
crw-------. 1 root    root      1,  12 Feb  6 03:08 oldmem
crw-------. 1 root    root     10, 183 Feb  6 03:08 hwrng
crw-------. 1 root    root     10, 227 Feb  6 03:08 mcelog
crw-------. 1 root    root     10,  60 Feb  6 03:08 network_latency
crw-------. 1 root    root     10,  59 Feb  6 03:08 network_throughput
crw-------. 1 root    root     10, 231 Feb  6 03:08 snapshot
crw-------. 1 root    root     10,  63 Feb  6 03:08 vga_arbiter
crw-------. 1 root    root     10, 144 Feb  6 03:08 nvram
crw-------. 1 root    root     10,  62 Feb  6 03:08 crash
crw-------. 1 root    root      5,   1 Feb  6 03:08 console
crw-rw-rw-. 1 root    tty       5,   0 Feb  6 03:08 tty
crw--w----. 1 root    tty       4,   1 Feb  6 03:08 tty1
crw--w----. 1 root    tty       4,   0 Feb  6 03:08 tty0
drwxr-xr-x. 3 root    root          60 Feb  6 03:08 cpu
crw--w----. 1 root    tty       4,  12 Feb  6 03:08 tty12
crw--w----. 1 root    tty       4,  10 Feb  6 03:08 tty10
drwxr-xr-x. 2 root    root           0 Feb  6 03:08 pts
drwxrwxrwt. 2 root    root          40 Feb  6 03:08 mqueue
crw--w----. 1 root    tty       4,  14 Feb  6 03:08 tty14
drwxr-xr-x. 2 root    root          60 Feb  6 03:08 raw
crw--w----. 1 root    tty       4,  13 Feb  6 03:08 tty13
crw--w----. 1 root    tty       4,  11 Feb  6 03:08 tty11
crw--w----. 1 root    tty       4,  16 Feb  6 03:08 tty16
crw--w----. 1 root    tty       4,  17 Feb  6 03:08 tty17
crw--w----. 1 root    tty       4,  18 Feb  6 03:08 tty18
crw--w----. 1 root    tty       4,  19 Feb  6 03:08 tty19
crw--w----. 1 root    tty       4,  20 Feb  6 03:08 tty20
crw--w----. 1 root    tty       4,  15 Feb  6 03:08 tty15
crw--w----. 1 root    tty       4,  21 Feb  6 03:08 tty21
crw--w----. 1 root    tty       4,  22 Feb  6 03:08 tty22
crw--w----. 1 root    tty       4,  23 Feb  6 03:08 tty23
crw--w----. 1 root    tty       4,  25 Feb  6 03:08 tty25
crw--w----. 1 root    tty       4,  24 Feb  6 03:08 tty24
crw--w----. 1 root    tty       4,  26 Feb  6 03:08 tty26
crw--w----. 1 root    tty       4,  28 Feb  6 03:08 tty28
crw--w----. 1 root    tty       4,   2 Feb  6 03:08 tty2
crw--w----. 1 root    tty       4,  29 Feb  6 03:08 tty29
crw--w----. 1 root    tty       4,  27 Feb  6 03:08 tty27
crw--w----. 1 root    tty       4,  30 Feb  6 03:08 tty30
crw--w----. 1 root    tty       4,   3 Feb  6 03:08 tty3
crw--w----. 1 root    tty       4,  31 Feb  6 03:08 tty31
crw--w----. 1 root    tty       4,  32 Feb  6 03:08 tty32
crw--w----. 1 root    tty       4,  33 Feb  6 03:08 tty33
crw--w----. 1 root    tty       4,  36 Feb  6 03:08 tty36
crw--w----. 1 root    tty       4,  37 Feb  6 03:08 tty37
crw--w----. 1 root    tty       4,  38 Feb  6 03:08 tty38
crw--w----. 1 root    tty       4,  34 Feb  6 03:08 tty34
crw--w----. 1 root    tty       4,  39 Feb  6 03:08 tty39
crw--w----. 1 root    tty       4,  35 Feb  6 03:08 tty35
crw--w----. 1 root    tty       4,  41 Feb  6 03:08 tty41
crw--w----. 1 root    tty       4,   4 Feb  6 03:08 tty4
crw--w----. 1 root    tty       4,  40 Feb  6 03:08 tty40
crw--w----. 1 root    tty       4,  42 Feb  6 03:08 tty42
crw--w----. 1 root    tty       4,  43 Feb  6 03:08 tty43
crw--w----. 1 root    tty       4,  44 Feb  6 03:08 tty44
crw--w----. 1 root    tty       4,  45 Feb  6 03:08 tty45
crw--w----. 1 root    tty       4,  46 Feb  6 03:08 tty46
crw--w----. 1 root    tty       4,  47 Feb  6 03:08 tty47
crw--w----. 1 root    tty       4,  50 Feb  6 03:08 tty50
crw--w----. 1 root    tty       4,  49 Feb  6 03:08 tty49
crw--w----. 1 root    tty       4,   5 Feb  6 03:08 tty5
crw--w----. 1 root    tty       4,  48 Feb  6 03:08 tty48
crw--w----. 1 root    tty       4,  51 Feb  6 03:08 tty51
crw--w----. 1 root    tty       4,  53 Feb  6 03:08 tty53
crw--w----. 1 root    tty       4,  52 Feb  6 03:08 tty52
crw--w----. 1 root    tty       4,  54 Feb  6 03:08 tty54
crw--w----. 1 root    tty       4,  58 Feb  6 03:08 tty58
crw--w----. 1 root    tty       4,  59 Feb  6 03:08 tty59
crw--w----. 1 root    tty       4,  57 Feb  6 03:08 tty57
crw--w----. 1 root    tty       4,  56 Feb  6 03:08 tty56
crw--w----. 1 root    tty       4,   6 Feb  6 03:08 tty6
crw--w----. 1 root    tty       4,  62 Feb  6 03:08 tty62
crw--w----. 1 root    tty       4,  55 Feb  6 03:08 tty55
crw--w----. 1 root    tty       4,  61 Feb  6 03:08 tty61
crw--w----. 1 root    tty       4,  60 Feb  6 03:08 tty60
crw--w----. 1 root    tty       4,   7 Feb  6 03:08 tty7
crw--w----. 1 root    tty       4,   9 Feb  6 03:08 tty9
crw--w----. 1 root    tty       4,   8 Feb  6 03:08 tty8
crw--w----. 1 root    tty       4,  63 Feb  6 03:08 tty63
crw-------. 1 root    root    247,   0 Feb  6 03:08 usbmon0
crw-rw----. 1 root    tty       7,   1 Feb  6 03:08 vcs1
crw-rw----. 1 root    tty       7,   0 Feb  6 03:08 vcs
crw-rw----. 1 root    tty       7, 128 Feb  6 03:08 vcsa
crw-rw----. 1 root    tty       7, 129 Feb  6 03:08 vcsa1
crw-rw----. 1 root    disk     21,   0 Feb  6 03:08 sg0
drwxr-xr-x. 3 root    root         240 Feb  6 03:08 input
crw-rw----. 1 root    tty       7,   2 Feb  6 03:08 vcs2
crw-rw----. 1 root    tty       7, 130 Feb  6 03:08 vcsa2
crw-rw----. 1 root    tty       7, 134 Feb  6 03:08 vcsa6
crw-rw----. 1 root    tty       7,   3 Feb  6 03:08 vcs3
crw-rw----. 1 root    tty       7,   4 Feb  6 03:08 vcs4
crw-rw----. 1 root    tty       7, 131 Feb  6 03:08 vcsa3
crw-rw----. 1 root    tty       7, 132 Feb  6 03:08 vcsa4
crw-rw----. 1 root    tty       7,   5 Feb  6 03:08 vcs5
crw-rw----. 1 root    tty       7, 133 Feb  6 03:08 vcsa5
crw-rw----. 1 root    tty       7,   6 Feb  6 03:08 vcs6
crw-rw-rw-. 1 vboxadd root     10,  57 Feb  6 03:08 vboxuser
crw-rw----. 1 vboxadd root     10,  58 Feb  6 03:08 vboxguest
drwxr-xr-x. 2 root    root          60 Feb  6 03:08 dri
drwxr-xr-x. 3 root    root         180 Feb  6 03:08 snd
crw-rw----. 1 root    video    29,   0 Feb  6 03:08 fb0
drwxr-xr-x. 2 root    root        2640 Feb  6 03:08 char
drwxrwxrwt. 2 root    root          40 Feb  6 11:03 shm
crw-rw-rw-. 1 root    tty       5,   2 Feb  6  2020 ptmx
[devops@app1 project]$ ll /dev/sda
brw-rw----. 1 root disk 8, 0 Feb  6 03:08 /dev/sda
[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ ansible-playbook lsblk.yml 

PLAY [Play for LVM] **********************************************************************************

TASK [Gathering Facts] *******************************************************************************
ok: [app2]

TASK [Creating a Partition] **************************************************************************
ok: [app2]

TASK [Creating a Volume Group] ***********************************************************************
fatal: [app2]: FAILED! => {"changed": false, "msg": "Failed to find required executable pvs in paths: /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/sbin"}

PLAY RECAP *******************************************************************************************
app2                       : ok=2    changed=0    unreachable=0    failed=1    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ vi lsblk.yml
[devops@app1 project]$ cat ansible.cfg 
[defaults]
inventory=./hosts
#inventory=dynamic
remote_user=devops
ask_pass=False
vault_password_file=.myvaultpassword.txt
forks=1
roles_path=roles:/usr/share/ansible/roles
log_path=ansible.log 

[privilege_escalation]
become=True
become_method=sudo
become_user=root
become_ask_pass=False
[devops@app1 project]$ pvs
-bash: pvs: command not found
[devops@app1 project]$ sudo yum provides pvs
Failed to set locale, defaulting to C
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: centos.excellmedia.net
 * epel: ftp.jaist.ac.jp
 * extras: centos.excellmedia.net
 * updates: centos.excellmedia.net
base/7/x86_64/filelists_db                                                                      | 7.3 MB  00:00:00     
epel/x86_64/filelists_db                                                                        |  12 MB  00:00:01     
extras/7/x86_64/filelists_db                                                                    | 210 kB  00:00:00     
updates/7/x86_64/filelists_db                                                                   | 4.0 MB  00:00:00     
7:lvm2-2.02.185-2.el7.x86_64 : Userland logical volume management tools
Repo        : base
Matched from:
Filename    : /usr/sbin/pvs



7:lvm2-2.02.185-2.el7_7.2.x86_64 : Userland logical volume management tools
Repo        : updates
Matched from:
Filename    : /usr/sbin/pvs



[devops@app1 project]$ ansible app2 -a "sudo yum install -y lvm2 "
[WARNING]: Consider using 'become', 'become_method', and 'become_user' rather than running sudo

app2 | CHANGED | rc=0 >>
Loaded plugins: fastestmirror
Loading mirror speeds from cached hostfile
 * base: centos.excellmedia.net
 * extras: centos.excellmedia.net
 * updates: centos.excellmedia.net
Resolving Dependencies
--> Running transaction check
---> Package lvm2.x86_64 7:2.02.185-2.el7_7.2 will be installed
--> Processing Dependency: lvm2-libs = 7:2.02.185-2.el7_7.2 for package: 7:lvm2-2.02.185-2.el7_7.2.x86_64
--> Processing Dependency: device-mapper-persistent-data >= 0.7.0-0.1.rc6 for package: 7:lvm2-2.02.185-2.el7_7.2.x86_64
--> Processing Dependency: liblvm2app.so.2.2(Base)(64bit) for package: 7:lvm2-2.02.185-2.el7_7.2.x86_64
--> Processing Dependency: libdevmapper-event.so.1.02(Base)(64bit) for package: 7:lvm2-2.02.185-2.el7_7.2.x86_64
--> Processing Dependency: liblvm2app.so.2.2()(64bit) for package: 7:lvm2-2.02.185-2.el7_7.2.x86_64
--> Processing Dependency: libdevmapper-event.so.1.02()(64bit) for package: 7:lvm2-2.02.185-2.el7_7.2.x86_64
--> Running transaction check
---> Package device-mapper-event-libs.x86_64 7:1.02.158-2.el7_7.2 will be installed
---> Package device-mapper-persistent-data.x86_64 0:0.8.5-1.el7 will be installed
---> Package lvm2-libs.x86_64 7:2.02.185-2.el7_7.2 will be installed
--> Processing Dependency: device-mapper-event = 7:1.02.158-2.el7_7.2 for package: 7:lvm2-libs-2.02.185-2.el7_7.2.x86_64
--> Running transaction check
---> Package device-mapper-event.x86_64 7:1.02.158-2.el7_7.2 will be installed
--> Processing Dependency: device-mapper = 7:1.02.158-2.el7_7.2 for package: 7:device-mapper-event-1.02.158-2.el7_7.2.x86_64
--> Running transaction check
---> Package device-mapper.x86_64 7:1.02.149-10.el7_6.7 will be updated
--> Processing Dependency: device-mapper = 7:1.02.149-10.el7_6.7 for package: 7:device-mapper-libs-1.02.149-10.el7_6.7.x86_64
---> Package device-mapper.x86_64 7:1.02.158-2.el7_7.2 will be an update
--> Running transaction check
---> Package device-mapper-libs.x86_64 7:1.02.149-10.el7_6.7 will be updated
---> Package device-mapper-libs.x86_64 7:1.02.158-2.el7_7.2 will be an update
--> Finished Dependency Resolution

Dependencies Resolved

================================================================================
 Package                        Arch    Version                  Repository
                                                                           Size
================================================================================
Installing:
 lvm2                           x86_64  7:2.02.185-2.el7_7.2     updates  1.3 M
Installing for dependencies:
 device-mapper-event            x86_64  7:1.02.158-2.el7_7.2     updates  190 k
 device-mapper-event-libs       x86_64  7:1.02.158-2.el7_7.2     updates  189 k
 device-mapper-persistent-data  x86_64  0.8.5-1.el7              base     423 k
 lvm2-libs                      x86_64  7:2.02.185-2.el7_7.2     updates  1.1 M
Updating for dependencies:
 device-mapper                  x86_64  7:1.02.158-2.el7_7.2     updates  294 k
 device-mapper-libs             x86_64  7:1.02.158-2.el7_7.2     updates  322 k

Transaction Summary
================================================================================
Install  1 Package  (+4 Dependent packages)
Upgrade             ( 2 Dependent packages)

Total download size: 3.8 M
Downloading packages:
No Presto metadata available for updates
--------------------------------------------------------------------------------
Total                                              402 kB/s | 3.8 MB  00:09     
Running transaction check
Running transaction test
Transaction test succeeded
Running transaction
  Updating   : 7:device-mapper-libs-1.02.158-2.el7_7.2.x86_64               1/9 
  Updating   : 7:device-mapper-1.02.158-2.el7_7.2.x86_64                    2/9 
  Installing : 7:device-mapper-event-libs-1.02.158-2.el7_7.2.x86_64         3/9 
  Installing : 7:device-mapper-event-1.02.158-2.el7_7.2.x86_64              4/9 
  Installing : 7:lvm2-libs-2.02.185-2.el7_7.2.x86_64                        5/9 
  Installing : device-mapper-persistent-data-0.8.5-1.el7.x86_64             6/9 
  Installing : 7:lvm2-2.02.185-2.el7_7.2.x86_64                             7/9 
  Cleanup    : 7:device-mapper-libs-1.02.149-10.el7_6.7.x86_64              8/9 
  Cleanup    : 7:device-mapper-1.02.149-10.el7_6.7.x86_64                   9/9 
  Verifying  : 7:device-mapper-1.02.158-2.el7_7.2.x86_64                    1/9 
  Verifying  : device-mapper-persistent-data-0.8.5-1.el7.x86_64             2/9 
  Verifying  : 7:lvm2-2.02.185-2.el7_7.2.x86_64                             3/9 
  Verifying  : 7:lvm2-libs-2.02.185-2.el7_7.2.x86_64                        4/9 
  Verifying  : 7:device-mapper-event-1.02.158-2.el7_7.2.x86_64              5/9 
  Verifying  : 7:device-mapper-event-libs-1.02.158-2.el7_7.2.x86_64         6/9 
  Verifying  : 7:device-mapper-libs-1.02.158-2.el7_7.2.x86_64               7/9 
  Verifying  : 7:device-mapper-libs-1.02.149-10.el7_6.7.x86_64              8/9 
  Verifying  : 7:device-mapper-1.02.149-10.el7_6.7.x86_64                   9/9 

Installed:
  lvm2.x86_64 7:2.02.185-2.el7_7.2                                              

Dependency Installed:
  device-mapper-event.x86_64 7:1.02.158-2.el7_7.2                               
  device-mapper-event-libs.x86_64 7:1.02.158-2.el7_7.2                          
  device-mapper-persistent-data.x86_64 0:0.8.5-1.el7                            
  lvm2-libs.x86_64 7:2.02.185-2.el7_7.2                                         

Dependency Updated:
  device-mapper.x86_64 7:1.02.158-2.el7_7.2                                     
  device-mapper-libs.x86_64 7:1.02.158-2.el7_7.2                                

Complete!

[devops@app1 project]$ ansible-playbook lsblk.yml 

PLAY [Play for LVM] ***************************************************************************************************

TASK [Gathering Facts] ************************************************************************************************
ok: [app2]

TASK [Creating a Partition] *******************************************************************************************
ok: [app2]

TASK [Creating a Volume Group] ****************************************************************************************
changed: [app2]

TASK [Creating a Logical Volume from Volume Group] ********************************************************************
changed: [app2]

TASK [Assigning a File System to Logical Volume] **********************************************************************
changed: [app2]

TASK [Creating Mount Point] *******************************************************************************************
changed: [app2]

TASK [Mounting the Filesystem under /mnt/volume1] *********************************************************************
changed: [app2]

PLAY RECAP ************************************************************************************************************
app2                       : ok=7    changed=5    unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   

[devops@app1 project]$ ansible app2 -a lsblk
app2 | CHANGED | rc=0 >>
NAME              MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
sda                 8:0    0   40G  0 disk 
`-sda1              8:1    0   40G  0 part /
sdb                 8:16   0    2G  0 disk 
`-sdb1              8:17   0 1023M  0 part 
  `-testvg-testlv 253:0    0  500M  0 lvm  /mnt/volume1

[devops@app1 project]$ #ansible app2 -a "sudo yum install -y lvm2 "
[devops@app1 project]$ cat lsblk.yml 
---
- name: Play for LVM
  hosts: webserver
  become: true
  tasks:
  #Flow>Partition>VG(PV)>LV>FS>Mounting
    - name: Creating a Partition #SDB
      parted:
        device: /dev/sdb
        number: 1
        part_end: 1GiB
        state: present

    - name: Creating a Volume Group
      lvg:
        pvs: /dev/sdb1
        state: present
        vg: testvg

    - name: Creating a Logical Volume from Volume Group
      lvol:
        vg: testvg
        lv: testlv
        size: 500M
        state: present


    - name: Assigning a File System to Logical Volume
      filesystem:
        device: /dev/testvg/testlv
        fstype: ext4

    - name: Creating Mount Point
      file:
        path: /mnt/volume1
        state: directory

    - name: Mounting the Filesystem under /mnt/volume1
      mount: 
        path: /mnt/volume1
        src: /dev/testvg/testlv
        fstype: ext4
        state: mounted

        #/etc/fstab > /dev/testvg/testlv /mnt/volume1 ext4 defaults 0 0

        
[devops@app1 project]$ history | tail -50
  501  ansible-playbook nginx.yml  --list-tasks
  502  ansible-playbook nginx.yml  --start-at-task="Copy nginx configuration in place"
  503  ansible-playbook nginx.yml  --start-at-task="Copy nginx configuration in place."
  504  ansible-playbook -C nginx.yml  
  505  ansible-playbook nginx.yml  --step
  506  cat hosts.yml 
  507  changed_when: false
  508  vi hosts.yml 
  509  ansible-playbook hosts.yml 
  510  cat hosts.yml 
  511  vim hosts.yml 
  512  ansible-playbook hosts.yml 
  513  vim hosts.yml 
  514  ansible-playbook hosts.yml 
  515  ansible-doc msg
  516  ansible-doc debug
  517  !
  518  vim hosts.yml 
  519  cat hosts.yml 
  520  ansible-playbook hosts.yml 
  521  vi tags.yml
  522  ansible-playbook tags.yml --list-tasks
  523  vi tags.yml
  524  ansible-playbook tags.yml --list-tasks
  525  ansible-playbook tags.yml --tags web
  526  ansible app2 -a "init 0"
  527  ansible app2 -m ping
  528  ansible app2 -a lsblk
  529  ansible app2 -m ping
  530  ansible app2 -a lsblk
  531  vi lsblk.yml
  532  ansible-playbook lsblk.yml --syntax-check
  533  vi lsblk.yml
  534  ansible-playbook lsblk.yml 
  535  vi lsblk.yml
  536  ll /dev/sdb
  537  ll /dev/
  538  ll /dev/sda
  539  vi lsblk.yml
  540  ansible-playbook lsblk.yml 
  541  vi lsblk.yml
  542  cat ansible.cfg 
  543  pvs
  544  sudo yum provides pvs
  545  ansible app2 -a "sudo yum install -y lvm2 "
  546  ansible-playbook lsblk.yml 
  547  ansible app2 -a lsblk
  548  #ansible app2 -a "sudo yum install -y lvm2 "
  549  cat lsblk.yml 
  550  history | tail -50
[devops@app1 project]$ ansible app2 -a "cat /etc/fstab"
app2 | CHANGED | rc=0 >>

#
# /etc/fstab
# Created by anaconda on Sat Jun  1 17:13:31 2019
#
# Accessible filesystems, by reference, are maintained under '/dev/disk'
# See man pages fstab(5), findfs(8), mount(8) and/or blkid(8) for more info
#
UUID=8ac075e3-1124-4bb6-bef7-a6811bf8b870 /                       xfs     defaults        0 0
/swapfile none swap defaults 0 0
/dev/testvg/testlv /mnt/volume1 ext4 defaults 0 0